
== Vector Loads and Stores Segment Instructions

[[policy-variant-overloadedvector-unit-stride-segment-load]]
=== Vector Unit-Stride Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vlseg2e16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t vl);
vfloat16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, size_t *new_vl, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, size_t *new_vl, size_t vl);
```

[[policy-variant-overloadedvecrtor-unit-stride-segment-store]]
=== Vector Unit-Stride Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-strided-segment-load]]
=== Vector Strided Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vlsseg2e16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x2_t __riscv_vlsseg2e8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, ptrdiff_t bstride, size_t vl);
```

[[policy-variant-overloadedvector-strided-segment-store]]
=== Vector Strided Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-indexed-segment-load]]
=== Vector Indexed Segment Load Intrinsics

``` C
vfloat16mf4x2_t __riscv_vloxseg2ei8_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tu (vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tu (vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tu (vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tu (vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tu (vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tu (vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tu (vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tu (vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tu (vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tu (vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tu (vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tu (vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tu (vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tu (vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tu (vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tu (vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tu (vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tu (vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tu (vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tu (vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tu (vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tu (vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tu (vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tu (vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tu (vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tu (vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tu (vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tu (vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tu (vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tu (vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tu (vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tu (vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tu (vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tu (vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tu (vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tu (vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tu (vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tu (vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tu (vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tu (vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tu (vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tu (vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tu (vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tu (vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tu (vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tu (vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tu (vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tu (vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tu (vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tu (vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tu (vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tu (vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tu (vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tu (vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tu (vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tu (vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tu (vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tu (vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tu (vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tu (vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tu (vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tu (vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tu (vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tu (vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tu (vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tu (vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tu (vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tu (vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tu (vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tu (vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tu (vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tu (vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tu (vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tu (vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tu (vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tu (vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tu (vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tu (vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tu (vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tu (vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tu (vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tu (vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tu (vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tu (vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tu (vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tu (vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tu (vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tu (vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tu (vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tu (vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tu (vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tu (vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tu (vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tu (vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tu (vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tu (vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tu (vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tu (vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tu (vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tu (vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tu (vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tu (vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tu (vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tu (vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tu (vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tu (vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tu (vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tu (vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tu (vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tu (vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tu (vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tu (vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tu (vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tu (vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tu (vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tu (vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tu (vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tu (vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tu (vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tu (vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tu (vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tu (vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tu (vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tu (vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tu (vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tu (vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tu (vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tu (vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tu (vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tu (vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tu (vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tu (vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tu (vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tu (vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tu (vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tu (vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tu (vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tu (vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tu (vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tu (vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tu (vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tu (vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tu (vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tu (vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tu (vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tu (vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tu (vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tu (vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tu (vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tu (vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tu (vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tu (vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tu (vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tu (vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tu (vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tu (vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tu (vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tu (vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tu (vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tu (vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tu (vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tu (vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tu (vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tu (vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tu (vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tu (vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tu (vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tu (vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tu (vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tu (vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tu (vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tu (vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tu (vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tu (vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tu (vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tu (vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tu (vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tu (vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tu (vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tu (vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tu (vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tu (vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tu (vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tu (vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tu (vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tu (vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tu (vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tu (vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tu (vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tu (vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tu (vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tu (vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tu (vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tu (vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tu (vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tu (vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tu (vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tu (vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tu (vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tu (vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tu (vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tu (vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tu (vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tu (vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tu (vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tu (vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tu (vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tu (vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tu (vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tu (vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tu (vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tu (vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tu (vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tu (vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tu (vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tu (vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tu (vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tu (vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tu (vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tu (vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tu (vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tu (vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tu (vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tu (vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tu (vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tu (vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tum (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tum (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tum (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tum (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tum (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tum (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tum (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tum (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tum (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tum (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tum (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tum (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tum (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tum (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tum (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tum (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tum (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tum (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tum (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tum (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tum (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tum (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tum (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tum (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tum (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tum (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tum (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tum (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tum (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tum (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tum (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tum (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tum (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tum (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tum (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tum (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tum (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tum (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tum (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tumu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tumu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tumu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tumu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tumu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tumu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tumu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tumu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tumu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tumu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tumu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tumu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tumu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tumu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tumu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tumu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tumu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tumu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tumu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tumu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tumu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tumu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tumu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tumu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tumu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tumu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tumu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tumu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tumu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tumu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tumu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tumu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tumu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tumu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tumu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tumu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tumu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tumu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tumu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
// masked functions
vfloat16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint8mf8_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint8mf4_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint8mf2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint8m1_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint8m2_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint16mf4_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint16mf2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint16m1_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint16m2_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint16m4_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint32mf2_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint32m1_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint32m2_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint32m4_t bindex, size_t vl);
vfloat16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vfloat16m4x2_t maskedoff_tuple, const float16_t *base, vuint32m8_t bindex, size_t vl);
vfloat16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat16mf4x2_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat16mf4x3_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat16mf4x4_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat16mf4x5_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat16mf4x6_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat16mf4x7_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat16mf4x8_t maskedoff_tuple, const float16_t *base, vuint64m1_t bindex, size_t vl);
vfloat16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat16mf2x2_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat16mf2x3_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat16mf2x4_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vfloat16mf2x5_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vfloat16mf2x6_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vfloat16mf2x7_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vfloat16mf2x8_t maskedoff_tuple, const float16_t *base, vuint64m2_t bindex, size_t vl);
vfloat16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat16m1x2_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vfloat16m1x3_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vfloat16m1x4_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vfloat16m1x5_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vfloat16m1x6_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vfloat16m1x7_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vfloat16m1x8_t maskedoff_tuple, const float16_t *base, vuint64m4_t bindex, size_t vl);
vfloat16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vfloat16m2x2_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vfloat16m2x3_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vfloat16m2x4_t maskedoff_tuple, const float16_t *base, vuint64m8_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint8mf8_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint8mf4_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint8mf2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint8m1_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint16mf4_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint16mf2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint16m1_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint16m2_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint32mf2_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint32m1_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint32m2_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint32m4_t bindex, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat32mf2x2_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat32mf2x3_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat32mf2x4_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat32mf2x5_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat32mf2x6_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat32mf2x7_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat32mf2x8_t maskedoff_tuple, const float32_t *base, vuint64m1_t bindex, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat32m1x2_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat32m1x3_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat32m1x4_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vfloat32m1x5_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vfloat32m1x6_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vfloat32m1x7_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vfloat32m1x8_t maskedoff_tuple, const float32_t *base, vuint64m2_t bindex, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat32m2x2_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vfloat32m2x3_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vfloat32m2x4_t maskedoff_tuple, const float32_t *base, vuint64m4_t bindex, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vfloat32m4x2_t maskedoff_tuple, const float32_t *base, vuint64m8_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint8mf8_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint8mf4_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint8mf2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint16mf4_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint16mf2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint16m1_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint32mf2_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint32m1_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint32m2_t bindex, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vfloat64m1x2_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vfloat64m1x3_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vfloat64m1x4_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vfloat64m1x5_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vfloat64m1x6_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vfloat64m1x7_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vfloat64m1x8_t maskedoff_tuple, const float64_t *base, vuint64m1_t bindex, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vfloat64m2x2_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vfloat64m2x3_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vfloat64m2x4_t maskedoff_tuple, const float64_t *base, vuint64m2_t bindex, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vfloat64m4x2_t maskedoff_tuple, const float64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint8mf8_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint8mf4_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint8mf2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint8m1_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint8m2_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint8m4_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint16mf4_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint16mf2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint16m1_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint16m2_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint16m4_t bindex, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_mu (vbool2_t mask, vint8m4x2_t maskedoff_tuple, const int8_t *base, vuint16m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint32mf2_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint32m1_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint32m2_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint32m4_t bindex, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vint8m2x2_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_mu (vbool4_t mask, vint8m2x3_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_mu (vbool4_t mask, vint8m2x4_t maskedoff_tuple, const int8_t *base, vuint32m8_t bindex, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint8mf8x2_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint8mf8x3_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint8mf8x4_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint8mf8x5_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint8mf8x6_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint8mf8x7_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint8mf8x8_t maskedoff_tuple, const int8_t *base, vuint64m1_t bindex, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint8mf4x2_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint8mf4x3_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint8mf4x4_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint8mf4x5_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint8mf4x6_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint8mf4x7_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint8mf4x8_t maskedoff_tuple, const int8_t *base, vuint64m2_t bindex, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint8mf2x2_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint8mf2x3_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint8mf2x4_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vint8mf2x5_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vint8mf2x6_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vint8mf2x7_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vint8mf2x8_t maskedoff_tuple, const int8_t *base, vuint64m4_t bindex, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint8m1x2_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vint8m1x3_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vint8m1x4_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_mu (vbool8_t mask, vint8m1x5_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_mu (vbool8_t mask, vint8m1x6_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_mu (vbool8_t mask, vint8m1x7_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_mu (vbool8_t mask, vint8m1x8_t maskedoff_tuple, const int8_t *base, vuint64m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint8mf8_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint8mf4_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint8mf2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint8m1_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint8m2_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint16mf4_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint16mf2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint16m1_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint16m2_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint16m4_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint32mf2_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint32m1_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint32m2_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint32m4_t bindex, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vint16m4x2_t maskedoff_tuple, const int16_t *base, vuint32m8_t bindex, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint16mf4x2_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint16mf4x3_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint16mf4x4_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint16mf4x5_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint16mf4x6_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint16mf4x7_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint16mf4x8_t maskedoff_tuple, const int16_t *base, vuint64m1_t bindex, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint16mf2x2_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint16mf2x3_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint16mf2x4_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint16mf2x5_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint16mf2x6_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint16mf2x7_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint16mf2x8_t maskedoff_tuple, const int16_t *base, vuint64m2_t bindex, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint16m1x2_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint16m1x3_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint16m1x4_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vint16m1x5_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vint16m1x6_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vint16m1x7_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vint16m1x8_t maskedoff_tuple, const int16_t *base, vuint64m4_t bindex, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint16m2x2_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vint16m2x3_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vint16m2x4_t maskedoff_tuple, const int16_t *base, vuint64m8_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint8mf8_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint8mf4_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint8mf2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint8m1_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint16mf4_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint16mf2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint16m1_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint16m2_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint32mf2_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint32m1_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint32m2_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint32m4_t bindex, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint32mf2x2_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint32mf2x3_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint32mf2x4_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint32mf2x5_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint32mf2x6_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint32mf2x7_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint32mf2x8_t maskedoff_tuple, const int32_t *base, vuint64m1_t bindex, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint32m1x2_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint32m1x3_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint32m1x4_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vint32m1x5_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vint32m1x6_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vint32m1x7_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vint32m1x8_t maskedoff_tuple, const int32_t *base, vuint64m2_t bindex, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint32m2x2_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vint32m2x3_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vint32m2x4_t maskedoff_tuple, const int32_t *base, vuint64m4_t bindex, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vint32m4x2_t maskedoff_tuple, const int32_t *base, vuint64m8_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint8mf8_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint8mf4_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint8mf2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint16mf4_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint16mf2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint16m1_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint32mf2_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint32m1_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint32m2_t bindex, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vint64m1x2_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vint64m1x3_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vint64m1x4_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vint64m1x5_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vint64m1x6_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vint64m1x7_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vint64m1x8_t maskedoff_tuple, const int64_t *base, vuint64m1_t bindex, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vint64m2x2_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vint64m2x3_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vint64m2x4_t maskedoff_tuple, const int64_t *base, vuint64m2_t bindex, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vint64m4x2_t maskedoff_tuple, const int64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint8mf8_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint8mf4_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint8mf2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint8m1_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint8m2_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint8m4_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint16mf4_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint16mf2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint16m1_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint16m2_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint16m4_t bindex, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_mu (vbool2_t mask, vuint8m4x2_t maskedoff_tuple, const uint8_t *base, vuint16m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint32mf2_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint32m1_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint32m2_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint32m4_t bindex, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vuint8m2x2_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_mu (vbool4_t mask, vuint8m2x3_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_mu (vbool4_t mask, vuint8m2x4_t maskedoff_tuple, const uint8_t *base, vuint32m8_t bindex, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint8mf8x2_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint8mf8x3_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint8mf8x4_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint8mf8x5_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint8mf8x6_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint8mf8x7_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint8mf8x8_t maskedoff_tuple, const uint8_t *base, vuint64m1_t bindex, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint8mf4x2_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint8mf4x3_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint8mf4x4_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint8mf4x5_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint8mf4x6_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint8mf4x7_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint8mf4x8_t maskedoff_tuple, const uint8_t *base, vuint64m2_t bindex, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint8mf2x2_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint8mf2x3_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint8mf2x4_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vuint8mf2x5_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vuint8mf2x6_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vuint8mf2x7_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vuint8mf2x8_t maskedoff_tuple, const uint8_t *base, vuint64m4_t bindex, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint8m1x2_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vuint8m1x3_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vuint8m1x4_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_mu (vbool8_t mask, vuint8m1x5_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_mu (vbool8_t mask, vuint8m1x6_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_mu (vbool8_t mask, vuint8m1x7_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_mu (vbool8_t mask, vuint8m1x8_t maskedoff_tuple, const uint8_t *base, vuint64m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint8mf8_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint8mf4_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint8mf2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint8m1_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint8m2_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint16mf4_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint16mf2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint16m1_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint16m2_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint16m4_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint32mf2_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint32m1_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint32m2_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint32m4_t bindex, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_mu (vbool4_t mask, vuint16m4x2_t maskedoff_tuple, const uint16_t *base, vuint32m8_t bindex, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint16mf4x2_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint16mf4x3_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint16mf4x4_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint16mf4x5_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint16mf4x6_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint16mf4x7_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint16mf4x8_t maskedoff_tuple, const uint16_t *base, vuint64m1_t bindex, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint16mf2x2_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint16mf2x3_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint16mf2x4_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint16mf2x5_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint16mf2x6_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint16mf2x7_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint16mf2x8_t maskedoff_tuple, const uint16_t *base, vuint64m2_t bindex, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint16m1x2_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint16m1x3_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint16m1x4_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_mu (vbool16_t mask, vuint16m1x5_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_mu (vbool16_t mask, vuint16m1x6_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_mu (vbool16_t mask, vuint16m1x7_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_mu (vbool16_t mask, vuint16m1x8_t maskedoff_tuple, const uint16_t *base, vuint64m4_t bindex, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint16m2x2_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_mu (vbool8_t mask, vuint16m2x3_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_mu (vbool8_t mask, vuint16m2x4_t maskedoff_tuple, const uint16_t *base, vuint64m8_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint8mf8_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint8mf4_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint8mf2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint8m1_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint16mf4_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint16mf2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint16m1_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint16m2_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint32mf2_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint32m1_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint32m2_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint32m4_t bindex, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint32mf2x2_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint32mf2x3_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint32mf2x4_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint32mf2x5_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint32mf2x6_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint32mf2x7_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint32mf2x8_t maskedoff_tuple, const uint32_t *base, vuint64m1_t bindex, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint32m1x2_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint32m1x3_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint32m1x4_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_mu (vbool32_t mask, vuint32m1x5_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_mu (vbool32_t mask, vuint32m1x6_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_mu (vbool32_t mask, vuint32m1x7_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_mu (vbool32_t mask, vuint32m1x8_t maskedoff_tuple, const uint32_t *base, vuint64m2_t bindex, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint32m2x2_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_mu (vbool16_t mask, vuint32m2x3_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_mu (vbool16_t mask, vuint32m2x4_t maskedoff_tuple, const uint32_t *base, vuint64m4_t bindex, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_mu (vbool8_t mask, vuint32m4x2_t maskedoff_tuple, const uint32_t *base, vuint64m8_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint8mf8_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint8mf4_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint8mf2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint16mf4_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint16mf2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint16m1_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint32mf2_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint32m1_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint32m2_t bindex, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_mu (vbool64_t mask, vuint64m1x2_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_mu (vbool64_t mask, vuint64m1x3_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_mu (vbool64_t mask, vuint64m1x4_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_mu (vbool64_t mask, vuint64m1x5_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_mu (vbool64_t mask, vuint64m1x6_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_mu (vbool64_t mask, vuint64m1x7_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_mu (vbool64_t mask, vuint64m1x8_t maskedoff_tuple, const uint64_t *base, vuint64m1_t bindex, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_mu (vbool32_t mask, vuint64m2x2_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_mu (vbool32_t mask, vuint64m2x3_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_mu (vbool32_t mask, vuint64m2x4_t maskedoff_tuple, const uint64_t *base, vuint64m2_t bindex, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_mu (vbool16_t mask, vuint64m4x2_t maskedoff_tuple, const uint64_t *base, vuint64m4_t bindex, size_t vl);
```

[[policy-variant-overloadedvector-indexed-segment-store]]
=== Vector Indexed Segment Store Intrinsics
Intrinsics here don't have a policy variant.
