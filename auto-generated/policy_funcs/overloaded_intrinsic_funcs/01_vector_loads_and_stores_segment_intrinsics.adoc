
=== Vector Loads and Stores Segment Intrinsics

[[policy-variant-overloadedvector-unit-stride-segment-load]]
==== Vector Unit-Stride Segment Load Intrinsics

[,c]
----
vint8mf8x2_t __riscv_vlseg2e8_tu(vint8mf8x2_t vd, const int8_t *rs1, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tu(vint8mf8x3_t vd, const int8_t *rs1, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tu(vint8mf8x4_t vd, const int8_t *rs1, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tu(vint8mf8x5_t vd, const int8_t *rs1, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tu(vint8mf8x6_t vd, const int8_t *rs1, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tu(vint8mf8x7_t vd, const int8_t *rs1, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tu(vint8mf8x8_t vd, const int8_t *rs1, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tu(vint8mf4x2_t vd, const int8_t *rs1, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tu(vint8mf4x3_t vd, const int8_t *rs1, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tu(vint8mf4x4_t vd, const int8_t *rs1, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tu(vint8mf4x5_t vd, const int8_t *rs1, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tu(vint8mf4x6_t vd, const int8_t *rs1, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tu(vint8mf4x7_t vd, const int8_t *rs1, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tu(vint8mf4x8_t vd, const int8_t *rs1, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tu(vint8mf2x2_t vd, const int8_t *rs1, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tu(vint8mf2x3_t vd, const int8_t *rs1, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tu(vint8mf2x4_t vd, const int8_t *rs1, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tu(vint8mf2x5_t vd, const int8_t *rs1, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tu(vint8mf2x6_t vd, const int8_t *rs1, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tu(vint8mf2x7_t vd, const int8_t *rs1, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tu(vint8mf2x8_t vd, const int8_t *rs1, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tu(vint8m1x2_t vd, const int8_t *rs1, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tu(vint8m1x3_t vd, const int8_t *rs1, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tu(vint8m1x4_t vd, const int8_t *rs1, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tu(vint8m1x5_t vd, const int8_t *rs1, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tu(vint8m1x6_t vd, const int8_t *rs1, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tu(vint8m1x7_t vd, const int8_t *rs1, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tu(vint8m1x8_t vd, const int8_t *rs1, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tu(vint8m2x2_t vd, const int8_t *rs1, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tu(vint8m2x3_t vd, const int8_t *rs1, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tu(vint8m2x4_t vd, const int8_t *rs1, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tu(vint8m4x2_t vd, const int8_t *rs1, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                   size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                   size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tu(vint16m1x2_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tu(vint16m1x3_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tu(vint16m1x4_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tu(vint16m1x5_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tu(vint16m1x6_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tu(vint16m1x7_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tu(vint16m1x8_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tu(vint16m2x2_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tu(vint16m2x3_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tu(vint16m2x4_t vd, const int16_t *rs1,
                                  size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tu(vint16m4x2_t vd, const int16_t *rs1,
                                  size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                   size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                   size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tu(vint32m1x2_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tu(vint32m1x3_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tu(vint32m1x4_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tu(vint32m1x5_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tu(vint32m1x6_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tu(vint32m1x7_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tu(vint32m1x8_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tu(vint32m2x2_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tu(vint32m2x3_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tu(vint32m2x4_t vd, const int32_t *rs1,
                                  size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tu(vint32m4x2_t vd, const int32_t *rs1,
                                  size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tu(vint64m1x2_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tu(vint64m1x3_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tu(vint64m1x4_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tu(vint64m1x5_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tu(vint64m1x6_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tu(vint64m1x7_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tu(vint64m1x8_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tu(vint64m2x2_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tu(vint64m2x3_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tu(vint64m2x4_t vd, const int64_t *rs1,
                                  size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tu(vint64m4x2_t vd, const int64_t *rs1,
                                  size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                   size_t *new_vl, size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tu(vint8m1x2_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tu(vint8m1x3_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tu(vint8m1x4_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tu(vint8m1x5_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tu(vint8m1x6_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tu(vint8m1x7_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tu(vint8m1x8_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tu(vint8m2x2_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tu(vint8m2x3_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tu(vint8m2x4_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tu(vint8m4x2_t vd, const int8_t *rs1,
                                  size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                     size_t *new_vl, size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tu(vint16m1x2_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tu(vint16m1x3_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tu(vint16m1x4_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tu(vint16m1x5_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tu(vint16m1x6_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tu(vint16m1x7_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tu(vint16m1x8_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tu(vint16m2x2_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tu(vint16m2x3_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tu(vint16m2x4_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tu(vint16m4x2_t vd, const int16_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                     size_t *new_vl, size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tu(vint32m1x2_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tu(vint32m1x3_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tu(vint32m1x4_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tu(vint32m1x5_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tu(vint32m1x6_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tu(vint32m1x7_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tu(vint32m1x8_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tu(vint32m2x2_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tu(vint32m2x3_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tu(vint32m2x4_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tu(vint32m4x2_t vd, const int32_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tu(vint64m1x2_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tu(vint64m1x3_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tu(vint64m1x4_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tu(vint64m1x5_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tu(vint64m1x6_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tu(vint64m1x7_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tu(vint64m1x8_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tu(vint64m2x2_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tu(vint64m2x3_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tu(vint64m2x4_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tu(vint64m4x2_t vd, const int64_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                  size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                 size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                    size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                   size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                    size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                   size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                   size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                    size_t *new_vl, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                   size_t *new_vl, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                      size_t *new_vl, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                     size_t *new_vl, size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlseg2e8_tum(vbool64_t vm, vint8mf8x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tum(vbool64_t vm, vint8mf8x3_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tum(vbool64_t vm, vint8mf8x4_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tum(vbool64_t vm, vint8mf8x5_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tum(vbool64_t vm, vint8mf8x6_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tum(vbool64_t vm, vint8mf8x7_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tum(vbool64_t vm, vint8mf8x8_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tum(vbool32_t vm, vint8mf4x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tum(vbool32_t vm, vint8mf4x3_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tum(vbool32_t vm, vint8mf4x4_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tum(vbool32_t vm, vint8mf4x5_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tum(vbool32_t vm, vint8mf4x6_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tum(vbool32_t vm, vint8mf4x7_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tum(vbool32_t vm, vint8mf4x8_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tum(vbool16_t vm, vint8mf2x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tum(vbool16_t vm, vint8mf2x3_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tum(vbool16_t vm, vint8mf2x4_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tum(vbool16_t vm, vint8mf2x5_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tum(vbool16_t vm, vint8mf2x6_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tum(vbool16_t vm, vint8mf2x7_t vd,
                                  const int8_t *rs1, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tum(vbool16_t vm, vint8mf2x8_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tum(vbool8_t vm, vint8m1x2_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tum(vbool8_t vm, vint8m1x3_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tum(vbool8_t vm, vint8m1x4_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tum(vbool8_t vm, vint8m1x5_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tum(vbool8_t vm, vint8m1x6_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tum(vbool8_t vm, vint8m1x7_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tum(vbool8_t vm, vint8m1x8_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tum(vbool4_t vm, vint8m2x2_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tum(vbool4_t vm, vint8m2x3_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tum(vbool4_t vm, vint8m2x4_t vd, const int8_t *rs1,
                                 size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tum(vbool2_t vm, vint8m4x2_t vd, const int8_t *rs1,
                                 size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tum(vbool64_t vm, vint16mf4x2_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tum(vbool64_t vm, vint16mf4x3_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tum(vbool64_t vm, vint16mf4x4_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tum(vbool64_t vm, vint16mf4x5_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tum(vbool64_t vm, vint16mf4x6_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tum(vbool64_t vm, vint16mf4x7_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tum(vbool64_t vm, vint16mf4x8_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tum(vbool32_t vm, vint16mf2x2_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tum(vbool32_t vm, vint16mf2x3_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tum(vbool32_t vm, vint16mf2x4_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tum(vbool32_t vm, vint16mf2x5_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tum(vbool32_t vm, vint16mf2x6_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tum(vbool32_t vm, vint16mf2x7_t vd,
                                    const int16_t *rs1, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tum(vbool32_t vm, vint16mf2x8_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tum(vbool16_t vm, vint16m1x2_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tum(vbool16_t vm, vint16m1x3_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tum(vbool16_t vm, vint16m1x4_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tum(vbool16_t vm, vint16m1x5_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tum(vbool16_t vm, vint16m1x6_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tum(vbool16_t vm, vint16m1x7_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tum(vbool16_t vm, vint16m1x8_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tum(vbool8_t vm, vint16m2x2_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tum(vbool8_t vm, vint16m2x3_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tum(vbool8_t vm, vint16m2x4_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tum(vbool4_t vm, vint16m4x2_t vd,
                                   const int16_t *rs1, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tum(vbool64_t vm, vint32mf2x2_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tum(vbool64_t vm, vint32mf2x3_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tum(vbool64_t vm, vint32mf2x4_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tum(vbool64_t vm, vint32mf2x5_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tum(vbool64_t vm, vint32mf2x6_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tum(vbool64_t vm, vint32mf2x7_t vd,
                                    const int32_t *rs1, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tum(vbool64_t vm, vint32mf2x8_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tum(vbool32_t vm, vint32m1x2_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tum(vbool32_t vm, vint32m1x3_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tum(vbool32_t vm, vint32m1x4_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tum(vbool32_t vm, vint32m1x5_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tum(vbool32_t vm, vint32m1x6_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tum(vbool32_t vm, vint32m1x7_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tum(vbool32_t vm, vint32m1x8_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tum(vbool16_t vm, vint32m2x2_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tum(vbool16_t vm, vint32m2x3_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tum(vbool16_t vm, vint32m2x4_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tum(vbool8_t vm, vint32m4x2_t vd,
                                   const int32_t *rs1, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tum(vbool64_t vm, vint64m1x2_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tum(vbool64_t vm, vint64m1x3_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tum(vbool64_t vm, vint64m1x4_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tum(vbool64_t vm, vint64m1x5_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tum(vbool64_t vm, vint64m1x6_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tum(vbool64_t vm, vint64m1x7_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tum(vbool64_t vm, vint64m1x8_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tum(vbool32_t vm, vint64m2x2_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tum(vbool32_t vm, vint64m2x3_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tum(vbool32_t vm, vint64m2x4_t vd,
                                   const int64_t *rs1, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tum(vbool16_t vm, vint64m4x2_t vd,
                                   const int64_t *rs1, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tum(vbool64_t vm, vint8mf8x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tum(vbool64_t vm, vint8mf8x3_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tum(vbool64_t vm, vint8mf8x4_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tum(vbool64_t vm, vint8mf8x5_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tum(vbool64_t vm, vint8mf8x6_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tum(vbool64_t vm, vint8mf8x7_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tum(vbool64_t vm, vint8mf8x8_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tum(vbool32_t vm, vint8mf4x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tum(vbool32_t vm, vint8mf4x3_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tum(vbool32_t vm, vint8mf4x4_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tum(vbool32_t vm, vint8mf4x5_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tum(vbool32_t vm, vint8mf4x6_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tum(vbool32_t vm, vint8mf4x7_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tum(vbool32_t vm, vint8mf4x8_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tum(vbool16_t vm, vint8mf2x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tum(vbool16_t vm, vint8mf2x3_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tum(vbool16_t vm, vint8mf2x4_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tum(vbool16_t vm, vint8mf2x5_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tum(vbool16_t vm, vint8mf2x6_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tum(vbool16_t vm, vint8mf2x7_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tum(vbool16_t vm, vint8mf2x8_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tum(vbool8_t vm, vint8m1x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tum(vbool8_t vm, vint8m1x3_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tum(vbool8_t vm, vint8m1x4_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tum(vbool8_t vm, vint8m1x5_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tum(vbool8_t vm, vint8m1x6_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tum(vbool8_t vm, vint8m1x7_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tum(vbool8_t vm, vint8m1x8_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tum(vbool4_t vm, vint8m2x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tum(vbool4_t vm, vint8m2x3_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tum(vbool4_t vm, vint8m2x4_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tum(vbool2_t vm, vint8m4x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tum(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tum(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tum(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tum(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tum(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tum(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tum(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tum(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tum(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tum(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tum(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tum(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tum(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tum(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tum(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tum(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tum(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tum(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tum(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tum(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tum(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tum(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tum(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tum(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tum(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tum(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tum(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tum(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tum(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tum(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tum(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tum(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tum(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tum(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tum(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tum(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tum(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tum(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tum(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tum(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tum(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tum(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tum(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tum(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tum(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tum(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tum(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tum(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tum(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tum(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tum(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tum(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tum(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tum(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tum(vbool8_t vm, vuint8m1x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tum(vbool8_t vm, vuint8m1x3_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tum(vbool8_t vm, vuint8m1x4_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tum(vbool8_t vm, vuint8m1x5_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tum(vbool8_t vm, vuint8m1x6_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tum(vbool8_t vm, vuint8m1x7_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tum(vbool8_t vm, vuint8m1x8_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tum(vbool4_t vm, vuint8m2x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tum(vbool4_t vm, vuint8m2x3_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tum(vbool4_t vm, vuint8m2x4_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tum(vbool2_t vm, vuint8m4x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tum(vbool16_t vm, vuint16m1x2_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tum(vbool16_t vm, vuint16m1x3_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tum(vbool16_t vm, vuint16m1x4_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tum(vbool16_t vm, vuint16m1x5_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tum(vbool16_t vm, vuint16m1x6_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tum(vbool16_t vm, vuint16m1x7_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tum(vbool16_t vm, vuint16m1x8_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tum(vbool8_t vm, vuint16m2x2_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tum(vbool8_t vm, vuint16m2x3_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tum(vbool8_t vm, vuint16m2x4_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tum(vbool4_t vm, vuint16m4x2_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tum(vbool32_t vm, vuint32m1x2_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tum(vbool32_t vm, vuint32m1x3_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tum(vbool32_t vm, vuint32m1x4_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tum(vbool32_t vm, vuint32m1x5_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tum(vbool32_t vm, vuint32m1x6_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tum(vbool32_t vm, vuint32m1x7_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tum(vbool32_t vm, vuint32m1x8_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tum(vbool16_t vm, vuint32m2x2_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tum(vbool16_t vm, vuint32m2x3_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tum(vbool16_t vm, vuint32m2x4_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tum(vbool8_t vm, vuint32m4x2_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tum(vbool64_t vm, vuint64m1x2_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tum(vbool64_t vm, vuint64m1x3_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tum(vbool64_t vm, vuint64m1x4_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tum(vbool64_t vm, vuint64m1x5_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tum(vbool64_t vm, vuint64m1x6_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tum(vbool64_t vm, vuint64m1x7_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tum(vbool64_t vm, vuint64m1x8_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tum(vbool32_t vm, vuint64m2x2_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tum(vbool32_t vm, vuint64m2x3_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tum(vbool32_t vm, vuint64m2x4_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tum(vbool16_t vm, vuint64m4x2_t vd,
                                    const uint64_t *rs1, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tum(vbool8_t vm, vuint8m1x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tum(vbool8_t vm, vuint8m1x3_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tum(vbool8_t vm, vuint8m1x4_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tum(vbool8_t vm, vuint8m1x5_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tum(vbool8_t vm, vuint8m1x6_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tum(vbool8_t vm, vuint8m1x7_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tum(vbool8_t vm, vuint8m1x8_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tum(vbool4_t vm, vuint8m2x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tum(vbool4_t vm, vuint8m2x3_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tum(vbool4_t vm, vuint8m2x4_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tum(vbool2_t vm, vuint8m4x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tum(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tum(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tum(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tum(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tum(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tum(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tum(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tum(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tum(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tum(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tum(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tum(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tum(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tum(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tum(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tum(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tum(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tum(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tum(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tum(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tum(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tum(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tum(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tum(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tum(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tum(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tum(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tum(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tum(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tum(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tum(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tum(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tum(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, size_t *new_vl,
                                      size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlseg2e8_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                   const int8_t *rs1, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                   const int8_t *rs1, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_tumu(vbool8_t vm, vint8m1x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x3_t __riscv_vlseg3e8_tumu(vbool8_t vm, vint8m1x3_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x4_t __riscv_vlseg4e8_tumu(vbool8_t vm, vint8m1x4_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x5_t __riscv_vlseg5e8_tumu(vbool8_t vm, vint8m1x5_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x6_t __riscv_vlseg6e8_tumu(vbool8_t vm, vint8m1x6_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x7_t __riscv_vlseg7e8_tumu(vbool8_t vm, vint8m1x7_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m1x8_t __riscv_vlseg8e8_tumu(vbool8_t vm, vint8m1x8_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m2x2_t __riscv_vlseg2e8_tumu(vbool4_t vm, vint8m2x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m2x3_t __riscv_vlseg3e8_tumu(vbool4_t vm, vint8m2x3_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m2x4_t __riscv_vlseg4e8_tumu(vbool4_t vm, vint8m2x4_t vd,
                                  const int8_t *rs1, size_t vl);
vint8m4x2_t __riscv_vlseg2e8_tumu(vbool2_t vm, vint8m4x2_t vd,
                                  const int8_t *rs1, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                     const int16_t *rs1, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                     const int16_t *rs1, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_tumu(vbool16_t vm, vint16m1x2_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_tumu(vbool16_t vm, vint16m1x3_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_tumu(vbool16_t vm, vint16m1x4_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_tumu(vbool16_t vm, vint16m1x5_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_tumu(vbool16_t vm, vint16m1x6_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_tumu(vbool16_t vm, vint16m1x7_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_tumu(vbool16_t vm, vint16m1x8_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_tumu(vbool8_t vm, vint16m2x2_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_tumu(vbool8_t vm, vint16m2x3_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_tumu(vbool8_t vm, vint16m2x4_t vd,
                                    const int16_t *rs1, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_tumu(vbool4_t vm, vint16m4x2_t vd,
                                    const int16_t *rs1, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                     const int32_t *rs1, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                     const int32_t *rs1, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_tumu(vbool32_t vm, vint32m1x2_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_tumu(vbool32_t vm, vint32m1x3_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_tumu(vbool32_t vm, vint32m1x4_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_tumu(vbool32_t vm, vint32m1x5_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_tumu(vbool32_t vm, vint32m1x6_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_tumu(vbool32_t vm, vint32m1x7_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_tumu(vbool32_t vm, vint32m1x8_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_tumu(vbool16_t vm, vint32m2x2_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_tumu(vbool16_t vm, vint32m2x3_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_tumu(vbool16_t vm, vint32m2x4_t vd,
                                    const int32_t *rs1, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_tumu(vbool8_t vm, vint32m4x2_t vd,
                                    const int32_t *rs1, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_tumu(vbool64_t vm, vint64m1x2_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_tumu(vbool64_t vm, vint64m1x3_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_tumu(vbool64_t vm, vint64m1x4_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_tumu(vbool64_t vm, vint64m1x5_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_tumu(vbool64_t vm, vint64m1x6_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_tumu(vbool64_t vm, vint64m1x7_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_tumu(vbool64_t vm, vint64m1x8_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_tumu(vbool32_t vm, vint64m2x2_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_tumu(vbool32_t vm, vint64m2x3_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_tumu(vbool32_t vm, vint64m2x4_t vd,
                                    const int64_t *rs1, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_tumu(vbool16_t vm, vint64m4x2_t vd,
                                    const int64_t *rs1, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, size_t *new_vl,
                                     size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_tumu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_tumu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_tumu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_tumu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_tumu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_tumu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_tumu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_tumu(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_tumu(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_tumu(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_tumu(vbool2_t vm, vint8m4x2_t vd,
                                    const int8_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, size_t *new_vl,
                                       size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_tumu(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_tumu(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_tumu(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_tumu(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_tumu(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_tumu(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_tumu(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_tumu(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_tumu(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_tumu(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_tumu(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, size_t *new_vl,
                                       size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_tumu(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_tumu(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_tumu(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_tumu(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_tumu(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_tumu(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_tumu(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_tumu(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_tumu(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_tumu(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_tumu(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_tumu(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_tumu(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_tumu(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_tumu(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_tumu(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_tumu(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_tumu(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_tumu(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_tumu(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_tumu(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_tumu(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                    const uint8_t *rs1, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                   const uint8_t *rs1, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                      const uint16_t *rs1, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                     const uint16_t *rs1, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                      const uint32_t *rs1, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                     const uint32_t *rs1, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                     const uint64_t *rs1, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                     const uint8_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, size_t *new_vl,
                                        size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, size_t *new_vl,
                                       size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlseg2e8_mu(vbool64_t vm, vint8mf8x2_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x3_t __riscv_vlseg3e8_mu(vbool64_t vm, vint8mf8x3_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x4_t __riscv_vlseg4e8_mu(vbool64_t vm, vint8mf8x4_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x5_t __riscv_vlseg5e8_mu(vbool64_t vm, vint8mf8x5_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x6_t __riscv_vlseg6e8_mu(vbool64_t vm, vint8mf8x6_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x7_t __riscv_vlseg7e8_mu(vbool64_t vm, vint8mf8x7_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf8x8_t __riscv_vlseg8e8_mu(vbool64_t vm, vint8mf8x8_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x2_t __riscv_vlseg2e8_mu(vbool32_t vm, vint8mf4x2_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x3_t __riscv_vlseg3e8_mu(vbool32_t vm, vint8mf4x3_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x4_t __riscv_vlseg4e8_mu(vbool32_t vm, vint8mf4x4_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x5_t __riscv_vlseg5e8_mu(vbool32_t vm, vint8mf4x5_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x6_t __riscv_vlseg6e8_mu(vbool32_t vm, vint8mf4x6_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x7_t __riscv_vlseg7e8_mu(vbool32_t vm, vint8mf4x7_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf4x8_t __riscv_vlseg8e8_mu(vbool32_t vm, vint8mf4x8_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x2_t __riscv_vlseg2e8_mu(vbool16_t vm, vint8mf2x2_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x3_t __riscv_vlseg3e8_mu(vbool16_t vm, vint8mf2x3_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x4_t __riscv_vlseg4e8_mu(vbool16_t vm, vint8mf2x4_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x5_t __riscv_vlseg5e8_mu(vbool16_t vm, vint8mf2x5_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x6_t __riscv_vlseg6e8_mu(vbool16_t vm, vint8mf2x6_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x7_t __riscv_vlseg7e8_mu(vbool16_t vm, vint8mf2x7_t vd,
                                 const int8_t *rs1, size_t vl);
vint8mf2x8_t __riscv_vlseg8e8_mu(vbool16_t vm, vint8mf2x8_t vd,
                                 const int8_t *rs1, size_t vl);
vint8m1x2_t __riscv_vlseg2e8_mu(vbool8_t vm, vint8m1x2_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x3_t __riscv_vlseg3e8_mu(vbool8_t vm, vint8m1x3_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x4_t __riscv_vlseg4e8_mu(vbool8_t vm, vint8m1x4_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x5_t __riscv_vlseg5e8_mu(vbool8_t vm, vint8m1x5_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x6_t __riscv_vlseg6e8_mu(vbool8_t vm, vint8m1x6_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x7_t __riscv_vlseg7e8_mu(vbool8_t vm, vint8m1x7_t vd, const int8_t *rs1,
                                size_t vl);
vint8m1x8_t __riscv_vlseg8e8_mu(vbool8_t vm, vint8m1x8_t vd, const int8_t *rs1,
                                size_t vl);
vint8m2x2_t __riscv_vlseg2e8_mu(vbool4_t vm, vint8m2x2_t vd, const int8_t *rs1,
                                size_t vl);
vint8m2x3_t __riscv_vlseg3e8_mu(vbool4_t vm, vint8m2x3_t vd, const int8_t *rs1,
                                size_t vl);
vint8m2x4_t __riscv_vlseg4e8_mu(vbool4_t vm, vint8m2x4_t vd, const int8_t *rs1,
                                size_t vl);
vint8m4x2_t __riscv_vlseg2e8_mu(vbool2_t vm, vint8m4x2_t vd, const int8_t *rs1,
                                size_t vl);
vint16mf4x2_t __riscv_vlseg2e16_mu(vbool64_t vm, vint16mf4x2_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x3_t __riscv_vlseg3e16_mu(vbool64_t vm, vint16mf4x3_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x4_t __riscv_vlseg4e16_mu(vbool64_t vm, vint16mf4x4_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x5_t __riscv_vlseg5e16_mu(vbool64_t vm, vint16mf4x5_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x6_t __riscv_vlseg6e16_mu(vbool64_t vm, vint16mf4x6_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x7_t __riscv_vlseg7e16_mu(vbool64_t vm, vint16mf4x7_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf4x8_t __riscv_vlseg8e16_mu(vbool64_t vm, vint16mf4x8_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x2_t __riscv_vlseg2e16_mu(vbool32_t vm, vint16mf2x2_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x3_t __riscv_vlseg3e16_mu(vbool32_t vm, vint16mf2x3_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x4_t __riscv_vlseg4e16_mu(vbool32_t vm, vint16mf2x4_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x5_t __riscv_vlseg5e16_mu(vbool32_t vm, vint16mf2x5_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x6_t __riscv_vlseg6e16_mu(vbool32_t vm, vint16mf2x6_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x7_t __riscv_vlseg7e16_mu(vbool32_t vm, vint16mf2x7_t vd,
                                   const int16_t *rs1, size_t vl);
vint16mf2x8_t __riscv_vlseg8e16_mu(vbool32_t vm, vint16mf2x8_t vd,
                                   const int16_t *rs1, size_t vl);
vint16m1x2_t __riscv_vlseg2e16_mu(vbool16_t vm, vint16m1x2_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x3_t __riscv_vlseg3e16_mu(vbool16_t vm, vint16m1x3_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x4_t __riscv_vlseg4e16_mu(vbool16_t vm, vint16m1x4_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x5_t __riscv_vlseg5e16_mu(vbool16_t vm, vint16m1x5_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x6_t __riscv_vlseg6e16_mu(vbool16_t vm, vint16m1x6_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x7_t __riscv_vlseg7e16_mu(vbool16_t vm, vint16m1x7_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m1x8_t __riscv_vlseg8e16_mu(vbool16_t vm, vint16m1x8_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m2x2_t __riscv_vlseg2e16_mu(vbool8_t vm, vint16m2x2_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m2x3_t __riscv_vlseg3e16_mu(vbool8_t vm, vint16m2x3_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m2x4_t __riscv_vlseg4e16_mu(vbool8_t vm, vint16m2x4_t vd,
                                  const int16_t *rs1, size_t vl);
vint16m4x2_t __riscv_vlseg2e16_mu(vbool4_t vm, vint16m4x2_t vd,
                                  const int16_t *rs1, size_t vl);
vint32mf2x2_t __riscv_vlseg2e32_mu(vbool64_t vm, vint32mf2x2_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x3_t __riscv_vlseg3e32_mu(vbool64_t vm, vint32mf2x3_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x4_t __riscv_vlseg4e32_mu(vbool64_t vm, vint32mf2x4_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x5_t __riscv_vlseg5e32_mu(vbool64_t vm, vint32mf2x5_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x6_t __riscv_vlseg6e32_mu(vbool64_t vm, vint32mf2x6_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x7_t __riscv_vlseg7e32_mu(vbool64_t vm, vint32mf2x7_t vd,
                                   const int32_t *rs1, size_t vl);
vint32mf2x8_t __riscv_vlseg8e32_mu(vbool64_t vm, vint32mf2x8_t vd,
                                   const int32_t *rs1, size_t vl);
vint32m1x2_t __riscv_vlseg2e32_mu(vbool32_t vm, vint32m1x2_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x3_t __riscv_vlseg3e32_mu(vbool32_t vm, vint32m1x3_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x4_t __riscv_vlseg4e32_mu(vbool32_t vm, vint32m1x4_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x5_t __riscv_vlseg5e32_mu(vbool32_t vm, vint32m1x5_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x6_t __riscv_vlseg6e32_mu(vbool32_t vm, vint32m1x6_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x7_t __riscv_vlseg7e32_mu(vbool32_t vm, vint32m1x7_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m1x8_t __riscv_vlseg8e32_mu(vbool32_t vm, vint32m1x8_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m2x2_t __riscv_vlseg2e32_mu(vbool16_t vm, vint32m2x2_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m2x3_t __riscv_vlseg3e32_mu(vbool16_t vm, vint32m2x3_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m2x4_t __riscv_vlseg4e32_mu(vbool16_t vm, vint32m2x4_t vd,
                                  const int32_t *rs1, size_t vl);
vint32m4x2_t __riscv_vlseg2e32_mu(vbool8_t vm, vint32m4x2_t vd,
                                  const int32_t *rs1, size_t vl);
vint64m1x2_t __riscv_vlseg2e64_mu(vbool64_t vm, vint64m1x2_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x3_t __riscv_vlseg3e64_mu(vbool64_t vm, vint64m1x3_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x4_t __riscv_vlseg4e64_mu(vbool64_t vm, vint64m1x4_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x5_t __riscv_vlseg5e64_mu(vbool64_t vm, vint64m1x5_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x6_t __riscv_vlseg6e64_mu(vbool64_t vm, vint64m1x6_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x7_t __riscv_vlseg7e64_mu(vbool64_t vm, vint64m1x7_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m1x8_t __riscv_vlseg8e64_mu(vbool64_t vm, vint64m1x8_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m2x2_t __riscv_vlseg2e64_mu(vbool32_t vm, vint64m2x2_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m2x3_t __riscv_vlseg3e64_mu(vbool32_t vm, vint64m2x3_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m2x4_t __riscv_vlseg4e64_mu(vbool32_t vm, vint64m2x4_t vd,
                                  const int64_t *rs1, size_t vl);
vint64m4x2_t __riscv_vlseg2e64_mu(vbool16_t vm, vint64m4x2_t vd,
                                  const int64_t *rs1, size_t vl);
vint8mf8x2_t __riscv_vlseg2e8ff_mu(vbool64_t vm, vint8mf8x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x3_t __riscv_vlseg3e8ff_mu(vbool64_t vm, vint8mf8x3_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x4_t __riscv_vlseg4e8ff_mu(vbool64_t vm, vint8mf8x4_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x5_t __riscv_vlseg5e8ff_mu(vbool64_t vm, vint8mf8x5_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x6_t __riscv_vlseg6e8ff_mu(vbool64_t vm, vint8mf8x6_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x7_t __riscv_vlseg7e8ff_mu(vbool64_t vm, vint8mf8x7_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf8x8_t __riscv_vlseg8e8ff_mu(vbool64_t vm, vint8mf8x8_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x2_t __riscv_vlseg2e8ff_mu(vbool32_t vm, vint8mf4x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x3_t __riscv_vlseg3e8ff_mu(vbool32_t vm, vint8mf4x3_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x4_t __riscv_vlseg4e8ff_mu(vbool32_t vm, vint8mf4x4_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x5_t __riscv_vlseg5e8ff_mu(vbool32_t vm, vint8mf4x5_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x6_t __riscv_vlseg6e8ff_mu(vbool32_t vm, vint8mf4x6_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x7_t __riscv_vlseg7e8ff_mu(vbool32_t vm, vint8mf4x7_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf4x8_t __riscv_vlseg8e8ff_mu(vbool32_t vm, vint8mf4x8_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x2_t __riscv_vlseg2e8ff_mu(vbool16_t vm, vint8mf2x2_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x3_t __riscv_vlseg3e8ff_mu(vbool16_t vm, vint8mf2x3_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x4_t __riscv_vlseg4e8ff_mu(vbool16_t vm, vint8mf2x4_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x5_t __riscv_vlseg5e8ff_mu(vbool16_t vm, vint8mf2x5_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x6_t __riscv_vlseg6e8ff_mu(vbool16_t vm, vint8mf2x6_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x7_t __riscv_vlseg7e8ff_mu(vbool16_t vm, vint8mf2x7_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8mf2x8_t __riscv_vlseg8e8ff_mu(vbool16_t vm, vint8mf2x8_t vd,
                                   const int8_t *rs1, size_t *new_vl,
                                   size_t vl);
vint8m1x2_t __riscv_vlseg2e8ff_mu(vbool8_t vm, vint8m1x2_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x3_t __riscv_vlseg3e8ff_mu(vbool8_t vm, vint8m1x3_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x4_t __riscv_vlseg4e8ff_mu(vbool8_t vm, vint8m1x4_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x5_t __riscv_vlseg5e8ff_mu(vbool8_t vm, vint8m1x5_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x6_t __riscv_vlseg6e8ff_mu(vbool8_t vm, vint8m1x6_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x7_t __riscv_vlseg7e8ff_mu(vbool8_t vm, vint8m1x7_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m1x8_t __riscv_vlseg8e8ff_mu(vbool8_t vm, vint8m1x8_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m2x2_t __riscv_vlseg2e8ff_mu(vbool4_t vm, vint8m2x2_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m2x3_t __riscv_vlseg3e8ff_mu(vbool4_t vm, vint8m2x3_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m2x4_t __riscv_vlseg4e8ff_mu(vbool4_t vm, vint8m2x4_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint8m4x2_t __riscv_vlseg2e8ff_mu(vbool2_t vm, vint8m4x2_t vd,
                                  const int8_t *rs1, size_t *new_vl, size_t vl);
vint16mf4x2_t __riscv_vlseg2e16ff_mu(vbool64_t vm, vint16mf4x2_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x3_t __riscv_vlseg3e16ff_mu(vbool64_t vm, vint16mf4x3_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x4_t __riscv_vlseg4e16ff_mu(vbool64_t vm, vint16mf4x4_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x5_t __riscv_vlseg5e16ff_mu(vbool64_t vm, vint16mf4x5_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x6_t __riscv_vlseg6e16ff_mu(vbool64_t vm, vint16mf4x6_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x7_t __riscv_vlseg7e16ff_mu(vbool64_t vm, vint16mf4x7_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf4x8_t __riscv_vlseg8e16ff_mu(vbool64_t vm, vint16mf4x8_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x2_t __riscv_vlseg2e16ff_mu(vbool32_t vm, vint16mf2x2_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x3_t __riscv_vlseg3e16ff_mu(vbool32_t vm, vint16mf2x3_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x4_t __riscv_vlseg4e16ff_mu(vbool32_t vm, vint16mf2x4_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x5_t __riscv_vlseg5e16ff_mu(vbool32_t vm, vint16mf2x5_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x6_t __riscv_vlseg6e16ff_mu(vbool32_t vm, vint16mf2x6_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x7_t __riscv_vlseg7e16ff_mu(vbool32_t vm, vint16mf2x7_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16mf2x8_t __riscv_vlseg8e16ff_mu(vbool32_t vm, vint16mf2x8_t vd,
                                     const int16_t *rs1, size_t *new_vl,
                                     size_t vl);
vint16m1x2_t __riscv_vlseg2e16ff_mu(vbool16_t vm, vint16m1x2_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x3_t __riscv_vlseg3e16ff_mu(vbool16_t vm, vint16m1x3_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x4_t __riscv_vlseg4e16ff_mu(vbool16_t vm, vint16m1x4_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x5_t __riscv_vlseg5e16ff_mu(vbool16_t vm, vint16m1x5_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x6_t __riscv_vlseg6e16ff_mu(vbool16_t vm, vint16m1x6_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x7_t __riscv_vlseg7e16ff_mu(vbool16_t vm, vint16m1x7_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m1x8_t __riscv_vlseg8e16ff_mu(vbool16_t vm, vint16m1x8_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m2x2_t __riscv_vlseg2e16ff_mu(vbool8_t vm, vint16m2x2_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m2x3_t __riscv_vlseg3e16ff_mu(vbool8_t vm, vint16m2x3_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m2x4_t __riscv_vlseg4e16ff_mu(vbool8_t vm, vint16m2x4_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint16m4x2_t __riscv_vlseg2e16ff_mu(vbool4_t vm, vint16m4x2_t vd,
                                    const int16_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32mf2x2_t __riscv_vlseg2e32ff_mu(vbool64_t vm, vint32mf2x2_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x3_t __riscv_vlseg3e32ff_mu(vbool64_t vm, vint32mf2x3_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x4_t __riscv_vlseg4e32ff_mu(vbool64_t vm, vint32mf2x4_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x5_t __riscv_vlseg5e32ff_mu(vbool64_t vm, vint32mf2x5_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x6_t __riscv_vlseg6e32ff_mu(vbool64_t vm, vint32mf2x6_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x7_t __riscv_vlseg7e32ff_mu(vbool64_t vm, vint32mf2x7_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32mf2x8_t __riscv_vlseg8e32ff_mu(vbool64_t vm, vint32mf2x8_t vd,
                                     const int32_t *rs1, size_t *new_vl,
                                     size_t vl);
vint32m1x2_t __riscv_vlseg2e32ff_mu(vbool32_t vm, vint32m1x2_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x3_t __riscv_vlseg3e32ff_mu(vbool32_t vm, vint32m1x3_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x4_t __riscv_vlseg4e32ff_mu(vbool32_t vm, vint32m1x4_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x5_t __riscv_vlseg5e32ff_mu(vbool32_t vm, vint32m1x5_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x6_t __riscv_vlseg6e32ff_mu(vbool32_t vm, vint32m1x6_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x7_t __riscv_vlseg7e32ff_mu(vbool32_t vm, vint32m1x7_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m1x8_t __riscv_vlseg8e32ff_mu(vbool32_t vm, vint32m1x8_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m2x2_t __riscv_vlseg2e32ff_mu(vbool16_t vm, vint32m2x2_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m2x3_t __riscv_vlseg3e32ff_mu(vbool16_t vm, vint32m2x3_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m2x4_t __riscv_vlseg4e32ff_mu(vbool16_t vm, vint32m2x4_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint32m4x2_t __riscv_vlseg2e32ff_mu(vbool8_t vm, vint32m4x2_t vd,
                                    const int32_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x2_t __riscv_vlseg2e64ff_mu(vbool64_t vm, vint64m1x2_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x3_t __riscv_vlseg3e64ff_mu(vbool64_t vm, vint64m1x3_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x4_t __riscv_vlseg4e64ff_mu(vbool64_t vm, vint64m1x4_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x5_t __riscv_vlseg5e64ff_mu(vbool64_t vm, vint64m1x5_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x6_t __riscv_vlseg6e64ff_mu(vbool64_t vm, vint64m1x6_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x7_t __riscv_vlseg7e64ff_mu(vbool64_t vm, vint64m1x7_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m1x8_t __riscv_vlseg8e64ff_mu(vbool64_t vm, vint64m1x8_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m2x2_t __riscv_vlseg2e64ff_mu(vbool32_t vm, vint64m2x2_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m2x3_t __riscv_vlseg3e64ff_mu(vbool32_t vm, vint64m2x3_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m2x4_t __riscv_vlseg4e64ff_mu(vbool32_t vm, vint64m2x4_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vint64m4x2_t __riscv_vlseg2e64ff_mu(vbool16_t vm, vint64m4x2_t vd,
                                    const int64_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                  const uint8_t *rs1, size_t vl);
vuint8m1x2_t __riscv_vlseg2e8_mu(vbool8_t vm, vuint8m1x2_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x3_t __riscv_vlseg3e8_mu(vbool8_t vm, vuint8m1x3_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x4_t __riscv_vlseg4e8_mu(vbool8_t vm, vuint8m1x4_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x5_t __riscv_vlseg5e8_mu(vbool8_t vm, vuint8m1x5_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x6_t __riscv_vlseg6e8_mu(vbool8_t vm, vuint8m1x6_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x7_t __riscv_vlseg7e8_mu(vbool8_t vm, vuint8m1x7_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m1x8_t __riscv_vlseg8e8_mu(vbool8_t vm, vuint8m1x8_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m2x2_t __riscv_vlseg2e8_mu(vbool4_t vm, vuint8m2x2_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m2x3_t __riscv_vlseg3e8_mu(vbool4_t vm, vuint8m2x3_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m2x4_t __riscv_vlseg4e8_mu(vbool4_t vm, vuint8m2x4_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint8m4x2_t __riscv_vlseg2e8_mu(vbool2_t vm, vuint8m4x2_t vd,
                                 const uint8_t *rs1, size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                    const uint16_t *rs1, size_t vl);
vuint16m1x2_t __riscv_vlseg2e16_mu(vbool16_t vm, vuint16m1x2_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x3_t __riscv_vlseg3e16_mu(vbool16_t vm, vuint16m1x3_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x4_t __riscv_vlseg4e16_mu(vbool16_t vm, vuint16m1x4_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x5_t __riscv_vlseg5e16_mu(vbool16_t vm, vuint16m1x5_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x6_t __riscv_vlseg6e16_mu(vbool16_t vm, vuint16m1x6_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x7_t __riscv_vlseg7e16_mu(vbool16_t vm, vuint16m1x7_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m1x8_t __riscv_vlseg8e16_mu(vbool16_t vm, vuint16m1x8_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m2x2_t __riscv_vlseg2e16_mu(vbool8_t vm, vuint16m2x2_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m2x3_t __riscv_vlseg3e16_mu(vbool8_t vm, vuint16m2x3_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m2x4_t __riscv_vlseg4e16_mu(vbool8_t vm, vuint16m2x4_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint16m4x2_t __riscv_vlseg2e16_mu(vbool4_t vm, vuint16m4x2_t vd,
                                   const uint16_t *rs1, size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                    const uint32_t *rs1, size_t vl);
vuint32m1x2_t __riscv_vlseg2e32_mu(vbool32_t vm, vuint32m1x2_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x3_t __riscv_vlseg3e32_mu(vbool32_t vm, vuint32m1x3_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x4_t __riscv_vlseg4e32_mu(vbool32_t vm, vuint32m1x4_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x5_t __riscv_vlseg5e32_mu(vbool32_t vm, vuint32m1x5_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x6_t __riscv_vlseg6e32_mu(vbool32_t vm, vuint32m1x6_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x7_t __riscv_vlseg7e32_mu(vbool32_t vm, vuint32m1x7_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m1x8_t __riscv_vlseg8e32_mu(vbool32_t vm, vuint32m1x8_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m2x2_t __riscv_vlseg2e32_mu(vbool16_t vm, vuint32m2x2_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m2x3_t __riscv_vlseg3e32_mu(vbool16_t vm, vuint32m2x3_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m2x4_t __riscv_vlseg4e32_mu(vbool16_t vm, vuint32m2x4_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint32m4x2_t __riscv_vlseg2e32_mu(vbool8_t vm, vuint32m4x2_t vd,
                                   const uint32_t *rs1, size_t vl);
vuint64m1x2_t __riscv_vlseg2e64_mu(vbool64_t vm, vuint64m1x2_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x3_t __riscv_vlseg3e64_mu(vbool64_t vm, vuint64m1x3_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x4_t __riscv_vlseg4e64_mu(vbool64_t vm, vuint64m1x4_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x5_t __riscv_vlseg5e64_mu(vbool64_t vm, vuint64m1x5_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x6_t __riscv_vlseg6e64_mu(vbool64_t vm, vuint64m1x6_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x7_t __riscv_vlseg7e64_mu(vbool64_t vm, vuint64m1x7_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m1x8_t __riscv_vlseg8e64_mu(vbool64_t vm, vuint64m1x8_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m2x2_t __riscv_vlseg2e64_mu(vbool32_t vm, vuint64m2x2_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m2x3_t __riscv_vlseg3e64_mu(vbool32_t vm, vuint64m2x3_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m2x4_t __riscv_vlseg4e64_mu(vbool32_t vm, vuint64m2x4_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint64m4x2_t __riscv_vlseg2e64_mu(vbool16_t vm, vuint64m4x2_t vd,
                                   const uint64_t *rs1, size_t vl);
vuint8mf8x2_t __riscv_vlseg2e8ff_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x3_t __riscv_vlseg3e8ff_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x4_t __riscv_vlseg4e8ff_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x5_t __riscv_vlseg5e8ff_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x6_t __riscv_vlseg6e8ff_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x7_t __riscv_vlseg7e8ff_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf8x8_t __riscv_vlseg8e8ff_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x2_t __riscv_vlseg2e8ff_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x3_t __riscv_vlseg3e8ff_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x4_t __riscv_vlseg4e8ff_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x5_t __riscv_vlseg5e8ff_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x6_t __riscv_vlseg6e8ff_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x7_t __riscv_vlseg7e8ff_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf4x8_t __riscv_vlseg8e8ff_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x2_t __riscv_vlseg2e8ff_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x3_t __riscv_vlseg3e8ff_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x4_t __riscv_vlseg4e8ff_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x5_t __riscv_vlseg5e8ff_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x6_t __riscv_vlseg6e8ff_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x7_t __riscv_vlseg7e8ff_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8mf2x8_t __riscv_vlseg8e8ff_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                    const uint8_t *rs1, size_t *new_vl,
                                    size_t vl);
vuint8m1x2_t __riscv_vlseg2e8ff_mu(vbool8_t vm, vuint8m1x2_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x3_t __riscv_vlseg3e8ff_mu(vbool8_t vm, vuint8m1x3_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x4_t __riscv_vlseg4e8ff_mu(vbool8_t vm, vuint8m1x4_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x5_t __riscv_vlseg5e8ff_mu(vbool8_t vm, vuint8m1x5_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x6_t __riscv_vlseg6e8ff_mu(vbool8_t vm, vuint8m1x6_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x7_t __riscv_vlseg7e8ff_mu(vbool8_t vm, vuint8m1x7_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m1x8_t __riscv_vlseg8e8ff_mu(vbool8_t vm, vuint8m1x8_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m2x2_t __riscv_vlseg2e8ff_mu(vbool4_t vm, vuint8m2x2_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m2x3_t __riscv_vlseg3e8ff_mu(vbool4_t vm, vuint8m2x3_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m2x4_t __riscv_vlseg4e8ff_mu(vbool4_t vm, vuint8m2x4_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint8m4x2_t __riscv_vlseg2e8ff_mu(vbool2_t vm, vuint8m4x2_t vd,
                                   const uint8_t *rs1, size_t *new_vl,
                                   size_t vl);
vuint16mf4x2_t __riscv_vlseg2e16ff_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x3_t __riscv_vlseg3e16ff_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x4_t __riscv_vlseg4e16ff_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x5_t __riscv_vlseg5e16ff_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x6_t __riscv_vlseg6e16ff_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x7_t __riscv_vlseg7e16ff_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf4x8_t __riscv_vlseg8e16ff_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x2_t __riscv_vlseg2e16ff_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x3_t __riscv_vlseg3e16ff_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x4_t __riscv_vlseg4e16ff_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x5_t __riscv_vlseg5e16ff_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x6_t __riscv_vlseg6e16ff_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x7_t __riscv_vlseg7e16ff_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16mf2x8_t __riscv_vlseg8e16ff_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                      const uint16_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint16m1x2_t __riscv_vlseg2e16ff_mu(vbool16_t vm, vuint16m1x2_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x3_t __riscv_vlseg3e16ff_mu(vbool16_t vm, vuint16m1x3_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x4_t __riscv_vlseg4e16ff_mu(vbool16_t vm, vuint16m1x4_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x5_t __riscv_vlseg5e16ff_mu(vbool16_t vm, vuint16m1x5_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x6_t __riscv_vlseg6e16ff_mu(vbool16_t vm, vuint16m1x6_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x7_t __riscv_vlseg7e16ff_mu(vbool16_t vm, vuint16m1x7_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m1x8_t __riscv_vlseg8e16ff_mu(vbool16_t vm, vuint16m1x8_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m2x2_t __riscv_vlseg2e16ff_mu(vbool8_t vm, vuint16m2x2_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m2x3_t __riscv_vlseg3e16ff_mu(vbool8_t vm, vuint16m2x3_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m2x4_t __riscv_vlseg4e16ff_mu(vbool8_t vm, vuint16m2x4_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint16m4x2_t __riscv_vlseg2e16ff_mu(vbool4_t vm, vuint16m4x2_t vd,
                                     const uint16_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32mf2x2_t __riscv_vlseg2e32ff_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x3_t __riscv_vlseg3e32ff_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x4_t __riscv_vlseg4e32ff_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x5_t __riscv_vlseg5e32ff_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x6_t __riscv_vlseg6e32ff_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x7_t __riscv_vlseg7e32ff_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32mf2x8_t __riscv_vlseg8e32ff_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                      const uint32_t *rs1, size_t *new_vl,
                                      size_t vl);
vuint32m1x2_t __riscv_vlseg2e32ff_mu(vbool32_t vm, vuint32m1x2_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x3_t __riscv_vlseg3e32ff_mu(vbool32_t vm, vuint32m1x3_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x4_t __riscv_vlseg4e32ff_mu(vbool32_t vm, vuint32m1x4_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x5_t __riscv_vlseg5e32ff_mu(vbool32_t vm, vuint32m1x5_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x6_t __riscv_vlseg6e32ff_mu(vbool32_t vm, vuint32m1x6_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x7_t __riscv_vlseg7e32ff_mu(vbool32_t vm, vuint32m1x7_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m1x8_t __riscv_vlseg8e32ff_mu(vbool32_t vm, vuint32m1x8_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m2x2_t __riscv_vlseg2e32ff_mu(vbool16_t vm, vuint32m2x2_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m2x3_t __riscv_vlseg3e32ff_mu(vbool16_t vm, vuint32m2x3_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m2x4_t __riscv_vlseg4e32ff_mu(vbool16_t vm, vuint32m2x4_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint32m4x2_t __riscv_vlseg2e32ff_mu(vbool8_t vm, vuint32m4x2_t vd,
                                     const uint32_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x2_t __riscv_vlseg2e64ff_mu(vbool64_t vm, vuint64m1x2_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x3_t __riscv_vlseg3e64ff_mu(vbool64_t vm, vuint64m1x3_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x4_t __riscv_vlseg4e64ff_mu(vbool64_t vm, vuint64m1x4_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x5_t __riscv_vlseg5e64ff_mu(vbool64_t vm, vuint64m1x5_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x6_t __riscv_vlseg6e64ff_mu(vbool64_t vm, vuint64m1x6_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x7_t __riscv_vlseg7e64ff_mu(vbool64_t vm, vuint64m1x7_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m1x8_t __riscv_vlseg8e64ff_mu(vbool64_t vm, vuint64m1x8_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m2x2_t __riscv_vlseg2e64ff_mu(vbool32_t vm, vuint64m2x2_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m2x3_t __riscv_vlseg3e64ff_mu(vbool32_t vm, vuint64m2x3_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m2x4_t __riscv_vlseg4e64ff_mu(vbool32_t vm, vuint64m2x4_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
vuint64m4x2_t __riscv_vlseg2e64ff_mu(vbool16_t vm, vuint64m4x2_t vd,
                                     const uint64_t *rs1, size_t *new_vl,
                                     size_t vl);
----

[[policy-variant-overloadedfloat-vector-unit-stride-segment-load]]
==== Float Vector Unit-Stride Segment Load Intrinsics

[,c]
----
vfloat32mf2x2_t __riscv_vlseg2e32_tu(vfloat32mf2x2_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tu(vfloat32mf2x3_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tu(vfloat32mf2x4_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tu(vfloat32mf2x5_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tu(vfloat32mf2x6_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tu(vfloat32mf2x7_t vd, const float *rs1,
                                     size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tu(vfloat32mf2x8_t vd, const float *rs1,
                                     size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tu(vfloat32m1x2_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tu(vfloat32m1x3_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tu(vfloat32m1x4_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tu(vfloat32m1x5_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tu(vfloat32m1x6_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tu(vfloat32m1x7_t vd, const float *rs1,
                                    size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tu(vfloat32m1x8_t vd, const float *rs1,
                                    size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tu(vfloat32m2x2_t vd, const float *rs1,
                                    size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tu(vfloat32m2x3_t vd, const float *rs1,
                                    size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tu(vfloat32m2x4_t vd, const float *rs1,
                                    size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tu(vfloat32m4x2_t vd, const float *rs1,
                                    size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tu(vfloat64m1x2_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tu(vfloat64m1x3_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tu(vfloat64m1x4_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tu(vfloat64m1x5_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tu(vfloat64m1x6_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tu(vfloat64m1x7_t vd, const double *rs1,
                                    size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tu(vfloat64m1x8_t vd, const double *rs1,
                                    size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tu(vfloat64m2x2_t vd, const double *rs1,
                                    size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tu(vfloat64m2x3_t vd, const double *rs1,
                                    size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tu(vfloat64m2x4_t vd, const double *rs1,
                                    size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tu(vfloat64m4x2_t vd, const double *rs1,
                                    size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tu(vfloat32mf2x2_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tu(vfloat32mf2x3_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tu(vfloat32mf2x4_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tu(vfloat32mf2x5_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tu(vfloat32mf2x6_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tu(vfloat32mf2x7_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tu(vfloat32mf2x8_t vd, const float *rs1,
                                       size_t *new_vl, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tu(vfloat32m1x2_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tu(vfloat32m1x3_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tu(vfloat32m1x4_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tu(vfloat32m1x5_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tu(vfloat32m1x6_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tu(vfloat32m1x7_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tu(vfloat32m1x8_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tu(vfloat32m2x2_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tu(vfloat32m2x3_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tu(vfloat32m2x4_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tu(vfloat32m4x2_t vd, const float *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tu(vfloat64m1x2_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tu(vfloat64m1x3_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tu(vfloat64m1x4_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tu(vfloat64m1x5_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tu(vfloat64m1x6_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tu(vfloat64m1x7_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tu(vfloat64m1x8_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tu(vfloat64m2x2_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tu(vfloat64m2x3_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tu(vfloat64m2x4_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tu(vfloat64m4x2_t vd, const double *rs1,
                                      size_t *new_vl, size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlseg2e32_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                      const float *rs1, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                     const float *rs1, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                     const float *rs1, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                     const float *rs1, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                     const float *rs1, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                     const float *rs1, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                     const double *rs1, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                     const double *rs1, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                     const double *rs1, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                     const double *rs1, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                     const double *rs1, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                     const double *rs1, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, size_t *new_vl,
                                       size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlseg2e32_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                       const float *rs1, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                       const float *rs1, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                      const float *rs1, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                      const float *rs1, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                      const float *rs1, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                      const float *rs1, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                      const float *rs1, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                      const float *rs1, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                      const double *rs1, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                      const double *rs1, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                      const double *rs1, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                      const double *rs1, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                      const double *rs1, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                      const double *rs1, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                         const float *rs1, size_t *new_vl,
                                         size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                        const float *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                        const double *rs1, size_t *new_vl,
                                        size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlseg2e32_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                     const float *rs1, size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                     const float *rs1, size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                    const float *rs1, size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                    const float *rs1, size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                    const float *rs1, size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                    const float *rs1, size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                    const float *rs1, size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                    const float *rs1, size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                    const double *rs1, size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                    const double *rs1, size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                    const double *rs1, size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                    const double *rs1, size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                    const double *rs1, size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                    const double *rs1, size_t vl);
vfloat32mf2x2_t __riscv_vlseg2e32ff_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x3_t __riscv_vlseg3e32ff_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x4_t __riscv_vlseg4e32ff_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x5_t __riscv_vlseg5e32ff_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x6_t __riscv_vlseg6e32ff_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x7_t __riscv_vlseg7e32ff_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32mf2x8_t __riscv_vlseg8e32ff_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                       const float *rs1, size_t *new_vl,
                                       size_t vl);
vfloat32m1x2_t __riscv_vlseg2e32ff_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x3_t __riscv_vlseg3e32ff_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x4_t __riscv_vlseg4e32ff_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x5_t __riscv_vlseg5e32ff_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x6_t __riscv_vlseg6e32ff_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x7_t __riscv_vlseg7e32ff_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m1x8_t __riscv_vlseg8e32ff_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m2x2_t __riscv_vlseg2e32ff_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m2x3_t __riscv_vlseg3e32ff_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m2x4_t __riscv_vlseg4e32ff_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat32m4x2_t __riscv_vlseg2e32ff_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                      const float *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x2_t __riscv_vlseg2e64ff_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x3_t __riscv_vlseg3e64ff_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x4_t __riscv_vlseg4e64ff_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x5_t __riscv_vlseg5e64ff_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x6_t __riscv_vlseg6e64ff_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x7_t __riscv_vlseg7e64ff_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m1x8_t __riscv_vlseg8e64ff_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m2x2_t __riscv_vlseg2e64ff_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m2x3_t __riscv_vlseg3e64ff_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m2x4_t __riscv_vlseg4e64ff_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
vfloat64m4x2_t __riscv_vlseg2e64ff_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                      const double *rs1, size_t *new_vl,
                                      size_t vl);
----

[[policy-variant-overloadedvecrtor-unit-stride-segment-store]]
==== Vector Unit-Stride Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedfloat-vecrtor-unit-stride-segment-store]]
==== Float Vector Unit-Stride Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-strided-segment-load]]
==== Vector Strided Segment Load Intrinsics

[,c]
----
vint8mf8x2_t __riscv_vlsseg2e8_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tu(vint8m1x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tu(vint8m1x3_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tu(vint8m1x4_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tu(vint8m1x5_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tu(vint8m1x6_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tu(vint8m1x7_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tu(vint8m1x8_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tu(vint8m2x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tu(vint8m2x3_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tu(vint8m2x4_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tu(vint8m4x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tu(vint16m1x2_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tu(vint16m1x3_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tu(vint16m1x4_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tu(vint16m1x5_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tu(vint16m1x6_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tu(vint16m1x7_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tu(vint16m1x8_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tu(vint16m2x2_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tu(vint16m2x3_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tu(vint16m2x4_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tu(vint16m4x2_t vd, const int16_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tu(vint32m1x2_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tu(vint32m1x3_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tu(vint32m1x4_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tu(vint32m1x5_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tu(vint32m1x6_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tu(vint32m1x7_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tu(vint32m1x8_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tu(vint32m2x2_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tu(vint32m2x3_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tu(vint32m2x4_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tu(vint32m4x2_t vd, const int32_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tu(vint64m1x2_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tu(vint64m1x3_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tu(vint64m1x4_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tu(vint64m1x5_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tu(vint64m1x6_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tu(vint64m1x7_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tu(vint64m1x8_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tu(vint64m2x2_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tu(vint64m2x3_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tu(vint64m2x4_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tu(vint64m4x2_t vd, const int64_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                   ptrdiff_t rs2, size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                  ptrdiff_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                     ptrdiff_t rs2, size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                    ptrdiff_t rs2, size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlsseg2e8_tum(vbool64_t vm, vint8mf8x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tum(vbool64_t vm, vint8mf8x3_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tum(vbool64_t vm, vint8mf8x4_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tum(vbool64_t vm, vint8mf8x5_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tum(vbool64_t vm, vint8mf8x6_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tum(vbool64_t vm, vint8mf8x7_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tum(vbool64_t vm, vint8mf8x8_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tum(vbool32_t vm, vint8mf4x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tum(vbool32_t vm, vint8mf4x3_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tum(vbool32_t vm, vint8mf4x4_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tum(vbool32_t vm, vint8mf4x5_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tum(vbool32_t vm, vint8mf4x6_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tum(vbool32_t vm, vint8mf4x7_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tum(vbool32_t vm, vint8mf4x8_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tum(vbool16_t vm, vint8mf2x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tum(vbool16_t vm, vint8mf2x3_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tum(vbool16_t vm, vint8mf2x4_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tum(vbool16_t vm, vint8mf2x5_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tum(vbool16_t vm, vint8mf2x6_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tum(vbool16_t vm, vint8mf2x7_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tum(vbool16_t vm, vint8mf2x8_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tum(vbool8_t vm, vint8m1x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tum(vbool8_t vm, vint8m1x3_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tum(vbool8_t vm, vint8m1x4_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tum(vbool8_t vm, vint8m1x5_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tum(vbool8_t vm, vint8m1x6_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tum(vbool8_t vm, vint8m1x7_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tum(vbool8_t vm, vint8m1x8_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tum(vbool4_t vm, vint8m2x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tum(vbool4_t vm, vint8m2x3_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tum(vbool4_t vm, vint8m2x4_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tum(vbool2_t vm, vint8m4x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tum(vbool64_t vm, vint16mf4x2_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tum(vbool64_t vm, vint16mf4x3_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tum(vbool64_t vm, vint16mf4x4_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tum(vbool64_t vm, vint16mf4x5_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tum(vbool64_t vm, vint16mf4x6_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tum(vbool64_t vm, vint16mf4x7_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tum(vbool64_t vm, vint16mf4x8_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tum(vbool32_t vm, vint16mf2x2_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tum(vbool32_t vm, vint16mf2x3_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tum(vbool32_t vm, vint16mf2x4_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tum(vbool32_t vm, vint16mf2x5_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tum(vbool32_t vm, vint16mf2x6_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tum(vbool32_t vm, vint16mf2x7_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tum(vbool32_t vm, vint16mf2x8_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tum(vbool16_t vm, vint16m1x2_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tum(vbool16_t vm, vint16m1x3_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tum(vbool16_t vm, vint16m1x4_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tum(vbool16_t vm, vint16m1x5_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tum(vbool16_t vm, vint16m1x6_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tum(vbool16_t vm, vint16m1x7_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tum(vbool16_t vm, vint16m1x8_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tum(vbool8_t vm, vint16m2x2_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tum(vbool8_t vm, vint16m2x3_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tum(vbool8_t vm, vint16m2x4_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tum(vbool4_t vm, vint16m4x2_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tum(vbool64_t vm, vint32mf2x2_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tum(vbool64_t vm, vint32mf2x3_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tum(vbool64_t vm, vint32mf2x4_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tum(vbool64_t vm, vint32mf2x5_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tum(vbool64_t vm, vint32mf2x6_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tum(vbool64_t vm, vint32mf2x7_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tum(vbool64_t vm, vint32mf2x8_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tum(vbool32_t vm, vint32m1x2_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tum(vbool32_t vm, vint32m1x3_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tum(vbool32_t vm, vint32m1x4_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tum(vbool32_t vm, vint32m1x5_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tum(vbool32_t vm, vint32m1x6_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tum(vbool32_t vm, vint32m1x7_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tum(vbool32_t vm, vint32m1x8_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tum(vbool16_t vm, vint32m2x2_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tum(vbool16_t vm, vint32m2x3_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tum(vbool16_t vm, vint32m2x4_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tum(vbool8_t vm, vint32m4x2_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tum(vbool64_t vm, vint64m1x2_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tum(vbool64_t vm, vint64m1x3_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tum(vbool64_t vm, vint64m1x4_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tum(vbool64_t vm, vint64m1x5_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tum(vbool64_t vm, vint64m1x6_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tum(vbool64_t vm, vint64m1x7_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tum(vbool64_t vm, vint64m1x8_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tum(vbool32_t vm, vint64m2x2_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tum(vbool32_t vm, vint64m2x3_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tum(vbool32_t vm, vint64m2x4_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tum(vbool16_t vm, vint64m4x2_t vd,
                                    const int64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tum(vbool8_t vm, vuint8m1x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tum(vbool8_t vm, vuint8m1x3_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tum(vbool8_t vm, vuint8m1x4_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tum(vbool8_t vm, vuint8m1x5_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tum(vbool8_t vm, vuint8m1x6_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tum(vbool8_t vm, vuint8m1x7_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tum(vbool8_t vm, vuint8m1x8_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tum(vbool4_t vm, vuint8m2x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tum(vbool4_t vm, vuint8m2x3_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tum(vbool4_t vm, vuint8m2x4_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tum(vbool2_t vm, vuint8m4x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tum(vbool16_t vm, vuint16m1x2_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tum(vbool16_t vm, vuint16m1x3_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tum(vbool16_t vm, vuint16m1x4_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tum(vbool16_t vm, vuint16m1x5_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tum(vbool16_t vm, vuint16m1x6_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tum(vbool16_t vm, vuint16m1x7_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tum(vbool16_t vm, vuint16m1x8_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tum(vbool8_t vm, vuint16m2x2_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tum(vbool8_t vm, vuint16m2x3_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tum(vbool8_t vm, vuint16m2x4_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tum(vbool4_t vm, vuint16m4x2_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tum(vbool32_t vm, vuint32m1x2_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tum(vbool32_t vm, vuint32m1x3_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tum(vbool32_t vm, vuint32m1x4_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tum(vbool32_t vm, vuint32m1x5_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tum(vbool32_t vm, vuint32m1x6_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tum(vbool32_t vm, vuint32m1x7_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tum(vbool32_t vm, vuint32m1x8_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tum(vbool16_t vm, vuint32m2x2_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tum(vbool16_t vm, vuint32m2x3_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tum(vbool16_t vm, vuint32m2x4_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tum(vbool8_t vm, vuint32m4x2_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tum(vbool64_t vm, vuint64m1x2_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tum(vbool64_t vm, vuint64m1x3_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tum(vbool64_t vm, vuint64m1x4_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tum(vbool64_t vm, vuint64m1x5_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tum(vbool64_t vm, vuint64m1x6_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tum(vbool64_t vm, vuint64m1x7_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tum(vbool64_t vm, vuint64m1x8_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tum(vbool32_t vm, vuint64m2x2_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tum(vbool32_t vm, vuint64m2x3_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tum(vbool32_t vm, vuint64m2x4_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tum(vbool16_t vm, vuint64m4x2_t vd,
                                     const uint64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlsseg2e8_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                    const int8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_tumu(vbool8_t vm, vint8m1x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_tumu(vbool8_t vm, vint8m1x3_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_tumu(vbool8_t vm, vint8m1x4_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_tumu(vbool8_t vm, vint8m1x5_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_tumu(vbool8_t vm, vint8m1x6_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_tumu(vbool8_t vm, vint8m1x7_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_tumu(vbool8_t vm, vint8m1x8_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_tumu(vbool4_t vm, vint8m2x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_tumu(vbool4_t vm, vint8m2x3_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_tumu(vbool4_t vm, vint8m2x4_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_tumu(vbool2_t vm, vint8m4x2_t vd,
                                   const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_tumu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_tumu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_tumu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_tumu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_tumu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_tumu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_tumu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_tumu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_tumu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_tumu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_tumu(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_tumu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_tumu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_tumu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_tumu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_tumu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_tumu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_tumu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_tumu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_tumu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_tumu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_tumu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_tumu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_tumu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_tumu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_tumu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_tumu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_tumu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_tumu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_tumu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_tumu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_tumu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_tumu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                     const uint8_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                    const uint8_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, ptrdiff_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, ptrdiff_t rs2,
                                      size_t vl);
// masked functions
vint8mf8x2_t __riscv_vlsseg2e8_mu(vbool64_t vm, vint8mf8x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x3_t __riscv_vlsseg3e8_mu(vbool64_t vm, vint8mf8x3_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x4_t __riscv_vlsseg4e8_mu(vbool64_t vm, vint8mf8x4_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x5_t __riscv_vlsseg5e8_mu(vbool64_t vm, vint8mf8x5_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x6_t __riscv_vlsseg6e8_mu(vbool64_t vm, vint8mf8x6_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x7_t __riscv_vlsseg7e8_mu(vbool64_t vm, vint8mf8x7_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf8x8_t __riscv_vlsseg8e8_mu(vbool64_t vm, vint8mf8x8_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x2_t __riscv_vlsseg2e8_mu(vbool32_t vm, vint8mf4x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x3_t __riscv_vlsseg3e8_mu(vbool32_t vm, vint8mf4x3_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x4_t __riscv_vlsseg4e8_mu(vbool32_t vm, vint8mf4x4_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x5_t __riscv_vlsseg5e8_mu(vbool32_t vm, vint8mf4x5_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x6_t __riscv_vlsseg6e8_mu(vbool32_t vm, vint8mf4x6_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x7_t __riscv_vlsseg7e8_mu(vbool32_t vm, vint8mf4x7_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf4x8_t __riscv_vlsseg8e8_mu(vbool32_t vm, vint8mf4x8_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x2_t __riscv_vlsseg2e8_mu(vbool16_t vm, vint8mf2x2_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x3_t __riscv_vlsseg3e8_mu(vbool16_t vm, vint8mf2x3_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x4_t __riscv_vlsseg4e8_mu(vbool16_t vm, vint8mf2x4_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x5_t __riscv_vlsseg5e8_mu(vbool16_t vm, vint8mf2x5_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x6_t __riscv_vlsseg6e8_mu(vbool16_t vm, vint8mf2x6_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x7_t __riscv_vlsseg7e8_mu(vbool16_t vm, vint8mf2x7_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8mf2x8_t __riscv_vlsseg8e8_mu(vbool16_t vm, vint8mf2x8_t vd,
                                  const int8_t *rs1, ptrdiff_t rs2, size_t vl);
vint8m1x2_t __riscv_vlsseg2e8_mu(vbool8_t vm, vint8m1x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x3_t __riscv_vlsseg3e8_mu(vbool8_t vm, vint8m1x3_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x4_t __riscv_vlsseg4e8_mu(vbool8_t vm, vint8m1x4_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x5_t __riscv_vlsseg5e8_mu(vbool8_t vm, vint8m1x5_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x6_t __riscv_vlsseg6e8_mu(vbool8_t vm, vint8m1x6_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x7_t __riscv_vlsseg7e8_mu(vbool8_t vm, vint8m1x7_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m1x8_t __riscv_vlsseg8e8_mu(vbool8_t vm, vint8m1x8_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x2_t __riscv_vlsseg2e8_mu(vbool4_t vm, vint8m2x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x3_t __riscv_vlsseg3e8_mu(vbool4_t vm, vint8m2x3_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m2x4_t __riscv_vlsseg4e8_mu(vbool4_t vm, vint8m2x4_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint8m4x2_t __riscv_vlsseg2e8_mu(vbool2_t vm, vint8m4x2_t vd, const int8_t *rs1,
                                 ptrdiff_t rs2, size_t vl);
vint16mf4x2_t __riscv_vlsseg2e16_mu(vbool64_t vm, vint16mf4x2_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x3_t __riscv_vlsseg3e16_mu(vbool64_t vm, vint16mf4x3_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x4_t __riscv_vlsseg4e16_mu(vbool64_t vm, vint16mf4x4_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x5_t __riscv_vlsseg5e16_mu(vbool64_t vm, vint16mf4x5_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x6_t __riscv_vlsseg6e16_mu(vbool64_t vm, vint16mf4x6_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x7_t __riscv_vlsseg7e16_mu(vbool64_t vm, vint16mf4x7_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf4x8_t __riscv_vlsseg8e16_mu(vbool64_t vm, vint16mf4x8_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x2_t __riscv_vlsseg2e16_mu(vbool32_t vm, vint16mf2x2_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x3_t __riscv_vlsseg3e16_mu(vbool32_t vm, vint16mf2x3_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x4_t __riscv_vlsseg4e16_mu(vbool32_t vm, vint16mf2x4_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x5_t __riscv_vlsseg5e16_mu(vbool32_t vm, vint16mf2x5_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x6_t __riscv_vlsseg6e16_mu(vbool32_t vm, vint16mf2x6_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x7_t __riscv_vlsseg7e16_mu(vbool32_t vm, vint16mf2x7_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16mf2x8_t __riscv_vlsseg8e16_mu(vbool32_t vm, vint16mf2x8_t vd,
                                    const int16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint16m1x2_t __riscv_vlsseg2e16_mu(vbool16_t vm, vint16m1x2_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x3_t __riscv_vlsseg3e16_mu(vbool16_t vm, vint16m1x3_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x4_t __riscv_vlsseg4e16_mu(vbool16_t vm, vint16m1x4_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x5_t __riscv_vlsseg5e16_mu(vbool16_t vm, vint16m1x5_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x6_t __riscv_vlsseg6e16_mu(vbool16_t vm, vint16m1x6_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x7_t __riscv_vlsseg7e16_mu(vbool16_t vm, vint16m1x7_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m1x8_t __riscv_vlsseg8e16_mu(vbool16_t vm, vint16m1x8_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m2x2_t __riscv_vlsseg2e16_mu(vbool8_t vm, vint16m2x2_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m2x3_t __riscv_vlsseg3e16_mu(vbool8_t vm, vint16m2x3_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m2x4_t __riscv_vlsseg4e16_mu(vbool8_t vm, vint16m2x4_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint16m4x2_t __riscv_vlsseg2e16_mu(vbool4_t vm, vint16m4x2_t vd,
                                   const int16_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32mf2x2_t __riscv_vlsseg2e32_mu(vbool64_t vm, vint32mf2x2_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x3_t __riscv_vlsseg3e32_mu(vbool64_t vm, vint32mf2x3_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x4_t __riscv_vlsseg4e32_mu(vbool64_t vm, vint32mf2x4_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x5_t __riscv_vlsseg5e32_mu(vbool64_t vm, vint32mf2x5_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x6_t __riscv_vlsseg6e32_mu(vbool64_t vm, vint32mf2x6_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x7_t __riscv_vlsseg7e32_mu(vbool64_t vm, vint32mf2x7_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32mf2x8_t __riscv_vlsseg8e32_mu(vbool64_t vm, vint32mf2x8_t vd,
                                    const int32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vint32m1x2_t __riscv_vlsseg2e32_mu(vbool32_t vm, vint32m1x2_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x3_t __riscv_vlsseg3e32_mu(vbool32_t vm, vint32m1x3_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x4_t __riscv_vlsseg4e32_mu(vbool32_t vm, vint32m1x4_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x5_t __riscv_vlsseg5e32_mu(vbool32_t vm, vint32m1x5_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x6_t __riscv_vlsseg6e32_mu(vbool32_t vm, vint32m1x6_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x7_t __riscv_vlsseg7e32_mu(vbool32_t vm, vint32m1x7_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m1x8_t __riscv_vlsseg8e32_mu(vbool32_t vm, vint32m1x8_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m2x2_t __riscv_vlsseg2e32_mu(vbool16_t vm, vint32m2x2_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m2x3_t __riscv_vlsseg3e32_mu(vbool16_t vm, vint32m2x3_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m2x4_t __riscv_vlsseg4e32_mu(vbool16_t vm, vint32m2x4_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint32m4x2_t __riscv_vlsseg2e32_mu(vbool8_t vm, vint32m4x2_t vd,
                                   const int32_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x2_t __riscv_vlsseg2e64_mu(vbool64_t vm, vint64m1x2_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x3_t __riscv_vlsseg3e64_mu(vbool64_t vm, vint64m1x3_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x4_t __riscv_vlsseg4e64_mu(vbool64_t vm, vint64m1x4_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x5_t __riscv_vlsseg5e64_mu(vbool64_t vm, vint64m1x5_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x6_t __riscv_vlsseg6e64_mu(vbool64_t vm, vint64m1x6_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x7_t __riscv_vlsseg7e64_mu(vbool64_t vm, vint64m1x7_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m1x8_t __riscv_vlsseg8e64_mu(vbool64_t vm, vint64m1x8_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m2x2_t __riscv_vlsseg2e64_mu(vbool32_t vm, vint64m2x2_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m2x3_t __riscv_vlsseg3e64_mu(vbool32_t vm, vint64m2x3_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m2x4_t __riscv_vlsseg4e64_mu(vbool32_t vm, vint64m2x4_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vint64m4x2_t __riscv_vlsseg2e64_mu(vbool16_t vm, vint64m4x2_t vd,
                                   const int64_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x2_t __riscv_vlsseg2e8_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x3_t __riscv_vlsseg3e8_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x4_t __riscv_vlsseg4e8_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x5_t __riscv_vlsseg5e8_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x6_t __riscv_vlsseg6e8_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x7_t __riscv_vlsseg7e8_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf8x8_t __riscv_vlsseg8e8_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x2_t __riscv_vlsseg2e8_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x3_t __riscv_vlsseg3e8_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x4_t __riscv_vlsseg4e8_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x5_t __riscv_vlsseg5e8_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x6_t __riscv_vlsseg6e8_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x7_t __riscv_vlsseg7e8_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf4x8_t __riscv_vlsseg8e8_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x2_t __riscv_vlsseg2e8_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x3_t __riscv_vlsseg3e8_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x4_t __riscv_vlsseg4e8_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x5_t __riscv_vlsseg5e8_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x6_t __riscv_vlsseg6e8_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x7_t __riscv_vlsseg7e8_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8mf2x8_t __riscv_vlsseg8e8_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                   const uint8_t *rs1, ptrdiff_t rs2,
                                   size_t vl);
vuint8m1x2_t __riscv_vlsseg2e8_mu(vbool8_t vm, vuint8m1x2_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x3_t __riscv_vlsseg3e8_mu(vbool8_t vm, vuint8m1x3_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x4_t __riscv_vlsseg4e8_mu(vbool8_t vm, vuint8m1x4_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x5_t __riscv_vlsseg5e8_mu(vbool8_t vm, vuint8m1x5_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x6_t __riscv_vlsseg6e8_mu(vbool8_t vm, vuint8m1x6_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x7_t __riscv_vlsseg7e8_mu(vbool8_t vm, vuint8m1x7_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m1x8_t __riscv_vlsseg8e8_mu(vbool8_t vm, vuint8m1x8_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m2x2_t __riscv_vlsseg2e8_mu(vbool4_t vm, vuint8m2x2_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m2x3_t __riscv_vlsseg3e8_mu(vbool4_t vm, vuint8m2x3_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m2x4_t __riscv_vlsseg4e8_mu(vbool4_t vm, vuint8m2x4_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint8m4x2_t __riscv_vlsseg2e8_mu(vbool2_t vm, vuint8m4x2_t vd,
                                  const uint8_t *rs1, ptrdiff_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vlsseg2e16_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x3_t __riscv_vlsseg3e16_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x4_t __riscv_vlsseg4e16_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x5_t __riscv_vlsseg5e16_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x6_t __riscv_vlsseg6e16_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x7_t __riscv_vlsseg7e16_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf4x8_t __riscv_vlsseg8e16_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x2_t __riscv_vlsseg2e16_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x3_t __riscv_vlsseg3e16_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x4_t __riscv_vlsseg4e16_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x5_t __riscv_vlsseg5e16_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x6_t __riscv_vlsseg6e16_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x7_t __riscv_vlsseg7e16_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16mf2x8_t __riscv_vlsseg8e16_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                     const uint16_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint16m1x2_t __riscv_vlsseg2e16_mu(vbool16_t vm, vuint16m1x2_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x3_t __riscv_vlsseg3e16_mu(vbool16_t vm, vuint16m1x3_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x4_t __riscv_vlsseg4e16_mu(vbool16_t vm, vuint16m1x4_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x5_t __riscv_vlsseg5e16_mu(vbool16_t vm, vuint16m1x5_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x6_t __riscv_vlsseg6e16_mu(vbool16_t vm, vuint16m1x6_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x7_t __riscv_vlsseg7e16_mu(vbool16_t vm, vuint16m1x7_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m1x8_t __riscv_vlsseg8e16_mu(vbool16_t vm, vuint16m1x8_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m2x2_t __riscv_vlsseg2e16_mu(vbool8_t vm, vuint16m2x2_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m2x3_t __riscv_vlsseg3e16_mu(vbool8_t vm, vuint16m2x3_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m2x4_t __riscv_vlsseg4e16_mu(vbool8_t vm, vuint16m2x4_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint16m4x2_t __riscv_vlsseg2e16_mu(vbool4_t vm, vuint16m4x2_t vd,
                                    const uint16_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32mf2x2_t __riscv_vlsseg2e32_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x3_t __riscv_vlsseg3e32_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x4_t __riscv_vlsseg4e32_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x5_t __riscv_vlsseg5e32_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x6_t __riscv_vlsseg6e32_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x7_t __riscv_vlsseg7e32_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32mf2x8_t __riscv_vlsseg8e32_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                     const uint32_t *rs1, ptrdiff_t rs2,
                                     size_t vl);
vuint32m1x2_t __riscv_vlsseg2e32_mu(vbool32_t vm, vuint32m1x2_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x3_t __riscv_vlsseg3e32_mu(vbool32_t vm, vuint32m1x3_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x4_t __riscv_vlsseg4e32_mu(vbool32_t vm, vuint32m1x4_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x5_t __riscv_vlsseg5e32_mu(vbool32_t vm, vuint32m1x5_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x6_t __riscv_vlsseg6e32_mu(vbool32_t vm, vuint32m1x6_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x7_t __riscv_vlsseg7e32_mu(vbool32_t vm, vuint32m1x7_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m1x8_t __riscv_vlsseg8e32_mu(vbool32_t vm, vuint32m1x8_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m2x2_t __riscv_vlsseg2e32_mu(vbool16_t vm, vuint32m2x2_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m2x3_t __riscv_vlsseg3e32_mu(vbool16_t vm, vuint32m2x3_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m2x4_t __riscv_vlsseg4e32_mu(vbool16_t vm, vuint32m2x4_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint32m4x2_t __riscv_vlsseg2e32_mu(vbool8_t vm, vuint32m4x2_t vd,
                                    const uint32_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x2_t __riscv_vlsseg2e64_mu(vbool64_t vm, vuint64m1x2_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x3_t __riscv_vlsseg3e64_mu(vbool64_t vm, vuint64m1x3_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x4_t __riscv_vlsseg4e64_mu(vbool64_t vm, vuint64m1x4_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x5_t __riscv_vlsseg5e64_mu(vbool64_t vm, vuint64m1x5_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x6_t __riscv_vlsseg6e64_mu(vbool64_t vm, vuint64m1x6_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x7_t __riscv_vlsseg7e64_mu(vbool64_t vm, vuint64m1x7_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m1x8_t __riscv_vlsseg8e64_mu(vbool64_t vm, vuint64m1x8_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m2x2_t __riscv_vlsseg2e64_mu(vbool32_t vm, vuint64m2x2_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m2x3_t __riscv_vlsseg3e64_mu(vbool32_t vm, vuint64m2x3_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m2x4_t __riscv_vlsseg4e64_mu(vbool32_t vm, vuint64m2x4_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
vuint64m4x2_t __riscv_vlsseg2e64_mu(vbool16_t vm, vuint64m4x2_t vd,
                                    const uint64_t *rs1, ptrdiff_t rs2,
                                    size_t vl);
----

[[policy-variant-overloadedfloat-vector-strided-segment-load]]
==== Float Vector Strided Segment Load Intrinsics

[,c]
----
vfloat32mf2x2_t __riscv_vlsseg2e32_tu(vfloat32mf2x2_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tu(vfloat32mf2x3_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tu(vfloat32mf2x4_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tu(vfloat32mf2x5_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tu(vfloat32mf2x6_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tu(vfloat32mf2x7_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tu(vfloat32mf2x8_t vd, const float *rs1,
                                      ptrdiff_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tu(vfloat32m1x2_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tu(vfloat32m1x3_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tu(vfloat32m1x4_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tu(vfloat32m1x5_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tu(vfloat32m1x6_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tu(vfloat32m1x7_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tu(vfloat32m1x8_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tu(vfloat32m2x2_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tu(vfloat32m2x3_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tu(vfloat32m2x4_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tu(vfloat32m4x2_t vd, const float *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tu(vfloat64m1x2_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tu(vfloat64m1x3_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tu(vfloat64m1x4_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tu(vfloat64m1x5_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tu(vfloat64m1x6_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tu(vfloat64m1x7_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tu(vfloat64m1x8_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tu(vfloat64m2x2_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tu(vfloat64m2x3_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tu(vfloat64m2x4_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tu(vfloat64m4x2_t vd, const double *rs1,
                                     ptrdiff_t rs2, size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlsseg2e32_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                      const double *rs1, ptrdiff_t rs2,
                                      size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlsseg2e32_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, ptrdiff_t rs2,
                                        size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, ptrdiff_t rs2,
                                       size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vlsseg2e32_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x3_t __riscv_vlsseg3e32_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x4_t __riscv_vlsseg4e32_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x5_t __riscv_vlsseg5e32_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x6_t __riscv_vlsseg6e32_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x7_t __riscv_vlsseg7e32_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32mf2x8_t __riscv_vlsseg8e32_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                      const float *rs1, ptrdiff_t rs2,
                                      size_t vl);
vfloat32m1x2_t __riscv_vlsseg2e32_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x3_t __riscv_vlsseg3e32_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x4_t __riscv_vlsseg4e32_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x5_t __riscv_vlsseg5e32_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x6_t __riscv_vlsseg6e32_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x7_t __riscv_vlsseg7e32_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m1x8_t __riscv_vlsseg8e32_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m2x2_t __riscv_vlsseg2e32_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m2x3_t __riscv_vlsseg3e32_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m2x4_t __riscv_vlsseg4e32_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat32m4x2_t __riscv_vlsseg2e32_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                     const float *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x2_t __riscv_vlsseg2e64_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x3_t __riscv_vlsseg3e64_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x4_t __riscv_vlsseg4e64_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x5_t __riscv_vlsseg5e64_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x6_t __riscv_vlsseg6e64_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x7_t __riscv_vlsseg7e64_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m1x8_t __riscv_vlsseg8e64_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m2x2_t __riscv_vlsseg2e64_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m2x3_t __riscv_vlsseg3e64_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m2x4_t __riscv_vlsseg4e64_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
vfloat64m4x2_t __riscv_vlsseg2e64_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                     const double *rs1, ptrdiff_t rs2,
                                     size_t vl);
----

[[policy-variant-overloadedvector-strided-segment-store]]
==== Vector Strided Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedfloat-vector-strided-segment-store]]
==== Float Vector Strided Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedvector-indexed-segment-load]]
==== Vector Indexed Segment Load Intrinsics

[,c]
----
vint8mf8x2_t __riscv_vloxseg2ei8_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tu(vint8m1x2_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tu(vint8m1x3_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tu(vint8m1x4_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tu(vint8m1x5_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tu(vint8m1x6_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tu(vint8m1x7_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tu(vint8m1x8_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tu(vint8m2x2_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tu(vint8m2x3_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tu(vint8m2x4_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tu(vint8m4x2_t vd, const int8_t *rs1,
                                   vuint8m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tu(vint8m2x2_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tu(vint8m2x3_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tu(vint8m2x4_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tu(vint8m4x2_t vd, const int8_t *rs1,
                                    vuint16m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tu(vint8m2x2_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tu(vint8m2x3_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tu(vint8m2x4_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tu(vint16m1x2_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tu(vint16m1x3_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tu(vint16m1x4_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tu(vint16m1x5_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tu(vint16m1x6_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tu(vint16m1x7_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tu(vint16m1x8_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tu(vint16m2x2_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tu(vint16m2x3_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tu(vint16m2x4_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tu(vint16m4x2_t vd, const int16_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tu(vint16m4x2_t vd, const int16_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tu(vint16m4x2_t vd, const int16_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tu(vint32m1x2_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tu(vint32m1x3_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tu(vint32m1x4_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tu(vint32m1x5_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tu(vint32m1x6_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tu(vint32m1x7_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tu(vint32m1x8_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tu(vint32m2x2_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tu(vint32m2x3_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tu(vint32m2x4_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tu(vint32m4x2_t vd, const int32_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tu(vint64m1x2_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tu(vint64m1x3_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tu(vint64m1x4_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tu(vint64m1x5_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tu(vint64m1x6_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tu(vint64m1x7_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tu(vint64m1x8_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tu(vint64m2x2_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tu(vint64m2x3_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tu(vint64m2x4_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tu(vint64m4x2_t vd, const int64_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tu(vint8m1x2_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tu(vint8m1x3_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tu(vint8m1x4_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tu(vint8m1x5_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tu(vint8m1x6_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tu(vint8m1x7_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tu(vint8m1x8_t vd, const int8_t *rs1,
                                   vuint8m1_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tu(vint8m2x2_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tu(vint8m2x3_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tu(vint8m2x4_t vd, const int8_t *rs1,
                                   vuint8m2_t rs2, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tu(vint8m4x2_t vd, const int8_t *rs1,
                                   vuint8m4_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint16m2_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tu(vint8m2x2_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tu(vint8m2x3_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tu(vint8m2x4_t vd, const int8_t *rs1,
                                    vuint16m4_t rs2, size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tu(vint8m4x2_t vd, const int8_t *rs1,
                                    vuint16m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint32m4_t rs2, size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tu(vint8m2x2_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tu(vint8m2x3_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tu(vint8m2x4_t vd, const int8_t *rs1,
                                    vuint32m8_t rs2, size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tu(vint8mf8x2_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tu(vint8mf8x3_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tu(vint8mf8x4_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tu(vint8mf8x5_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tu(vint8mf8x6_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tu(vint8mf8x7_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tu(vint8mf8x8_t vd, const int8_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tu(vint8mf4x2_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tu(vint8mf4x3_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tu(vint8mf4x4_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tu(vint8mf4x5_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tu(vint8mf4x6_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tu(vint8mf4x7_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tu(vint8mf4x8_t vd, const int8_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tu(vint8mf2x2_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tu(vint8mf2x3_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tu(vint8mf2x4_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tu(vint8mf2x5_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tu(vint8mf2x6_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tu(vint8mf2x7_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tu(vint8mf2x8_t vd, const int8_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tu(vint8m1x2_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tu(vint8m1x3_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tu(vint8m1x4_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tu(vint8m1x5_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tu(vint8m1x6_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tu(vint8m1x7_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tu(vint8m1x8_t vd, const int8_t *rs1,
                                    vuint64m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tu(vint16m1x2_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tu(vint16m1x3_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tu(vint16m1x4_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tu(vint16m1x5_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tu(vint16m1x6_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tu(vint16m1x7_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tu(vint16m1x8_t vd, const int16_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tu(vint16m2x2_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tu(vint16m2x3_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tu(vint16m2x4_t vd, const int16_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tu(vint16m4x2_t vd, const int16_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tu(vint16m4x2_t vd, const int16_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tu(vint16m4x2_t vd, const int16_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tu(vint16mf4x2_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tu(vint16mf4x3_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tu(vint16mf4x4_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tu(vint16mf4x5_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tu(vint16mf4x6_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tu(vint16mf4x7_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tu(vint16mf4x8_t vd, const int16_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tu(vint16mf2x2_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tu(vint16mf2x3_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tu(vint16mf2x4_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tu(vint16mf2x5_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tu(vint16mf2x6_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tu(vint16mf2x7_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tu(vint16mf2x8_t vd, const int16_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tu(vint16m1x2_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tu(vint16m1x3_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tu(vint16m1x4_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tu(vint16m1x5_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tu(vint16m1x6_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tu(vint16m1x7_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tu(vint16m1x8_t vd, const int16_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tu(vint16m2x2_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tu(vint16m2x3_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tu(vint16m2x4_t vd, const int16_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tu(vint32m1x2_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tu(vint32m1x3_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tu(vint32m1x4_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tu(vint32m1x5_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tu(vint32m1x6_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tu(vint32m1x7_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tu(vint32m1x8_t vd, const int32_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tu(vint32m2x2_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tu(vint32m2x3_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tu(vint32m2x4_t vd, const int32_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tu(vint32m4x2_t vd, const int32_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tu(vint32mf2x2_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tu(vint32mf2x3_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tu(vint32mf2x4_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tu(vint32mf2x5_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tu(vint32mf2x6_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tu(vint32mf2x7_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tu(vint32mf2x8_t vd, const int32_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tu(vint32m1x2_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tu(vint32m1x3_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tu(vint32m1x4_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tu(vint32m1x5_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tu(vint32m1x6_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tu(vint32m1x7_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tu(vint32m1x8_t vd, const int32_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tu(vint32m2x2_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tu(vint32m2x3_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tu(vint32m2x4_t vd, const int32_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tu(vint32m4x2_t vd, const int32_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tu(vint64m1x2_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tu(vint64m1x3_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tu(vint64m1x4_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tu(vint64m1x5_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tu(vint64m1x6_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tu(vint64m1x7_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tu(vint64m1x8_t vd, const int64_t *rs1,
                                    vuint8mf8_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tu(vint64m2x2_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tu(vint64m2x3_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tu(vint64m2x4_t vd, const int64_t *rs1,
                                    vuint8mf4_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tu(vint64m4x2_t vd, const int64_t *rs1,
                                    vuint8mf2_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint16mf4_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint16mf2_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint16m1_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint32mf2_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint32m1_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint32m2_t rs2, size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tu(vint64m1x2_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tu(vint64m1x3_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tu(vint64m1x4_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tu(vint64m1x5_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tu(vint64m1x6_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tu(vint64m1x7_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tu(vint64m1x8_t vd, const int64_t *rs1,
                                     vuint64m1_t rs2, size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tu(vint64m2x2_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tu(vint64m2x3_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tu(vint64m2x4_t vd, const int64_t *rs1,
                                     vuint64m2_t rs2, size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tu(vint64m4x2_t vd, const int64_t *rs1,
                                     vuint64m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                    vuint8m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                     vuint16m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                    vuint8m1_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                    vuint8m2_t rs2, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                    vuint8m4_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint16m2_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                     vuint16m4_t rs2, size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tu(vuint8m4x2_t vd, const uint8_t *rs1,
                                     vuint16m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint32m4_t rs2, size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tu(vuint8m2x2_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tu(vuint8m2x3_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tu(vuint8m2x4_t vd, const uint8_t *rs1,
                                     vuint32m8_t rs2, size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tu(vuint8mf8x2_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tu(vuint8mf8x3_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tu(vuint8mf8x4_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tu(vuint8mf8x5_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tu(vuint8mf8x6_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tu(vuint8mf8x7_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tu(vuint8mf8x8_t vd, const uint8_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tu(vuint8mf4x2_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tu(vuint8mf4x3_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tu(vuint8mf4x4_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tu(vuint8mf4x5_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tu(vuint8mf4x6_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tu(vuint8mf4x7_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tu(vuint8mf4x8_t vd, const uint8_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tu(vuint8mf2x2_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tu(vuint8mf2x3_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tu(vuint8mf2x4_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tu(vuint8mf2x5_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tu(vuint8mf2x6_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tu(vuint8mf2x7_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tu(vuint8mf2x8_t vd, const uint8_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tu(vuint8m1x2_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tu(vuint8m1x3_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tu(vuint8m1x4_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tu(vuint8m1x5_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tu(vuint8m1x6_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tu(vuint8m1x7_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tu(vuint8m1x8_t vd, const uint8_t *rs1,
                                     vuint64m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                      vuint8mf4_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                     vuint8m2_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint16mf2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                      vuint16m4_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint32m1_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tu(vuint16m4x2_t vd, const uint16_t *rs1,
                                      vuint32m8_t rs2, size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tu(vuint16mf4x2_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tu(vuint16mf4x3_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tu(vuint16mf4x4_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tu(vuint16mf4x5_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tu(vuint16mf4x6_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tu(vuint16mf4x7_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tu(vuint16mf4x8_t vd, const uint16_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tu(vuint16mf2x2_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tu(vuint16mf2x3_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tu(vuint16mf2x4_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tu(vuint16mf2x5_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tu(vuint16mf2x6_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tu(vuint16mf2x7_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tu(vuint16mf2x8_t vd, const uint16_t *rs1,
                                       vuint64m2_t rs2, size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tu(vuint16m1x2_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tu(vuint16m1x3_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tu(vuint16m1x4_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tu(vuint16m1x5_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tu(vuint16m1x6_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tu(vuint16m1x7_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tu(vuint16m1x8_t vd, const uint16_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tu(vuint16m2x2_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tu(vuint16m2x3_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tu(vuint16m2x4_t vd, const uint16_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                      vuint8mf8_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                     vuint8m1_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint16mf4_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint16m2_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint32m4_t rs2, size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tu(vuint32mf2x2_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tu(vuint32mf2x3_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tu(vuint32mf2x4_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tu(vuint32mf2x5_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tu(vuint32mf2x6_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tu(vuint32mf2x7_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tu(vuint32mf2x8_t vd, const uint32_t *rs1,
                                       vuint64m1_t rs2, size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tu(vuint32m1x2_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tu(vuint32m1x3_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tu(vuint32m1x4_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tu(vuint32m1x5_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tu(vuint32m1x6_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tu(vuint32m1x7_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tu(vuint32m1x8_t vd, const uint32_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tu(vuint32m2x2_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tu(vuint32m2x3_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tu(vuint32m2x4_t vd, const uint32_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tu(vuint32m4x2_t vd, const uint32_t *rs1,
                                      vuint64m8_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                     vuint8mf8_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                     vuint8mf4_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                     vuint8mf2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint16mf4_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint16mf2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint16m1_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint32mf2_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint32m1_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint32m2_t rs2, size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tu(vuint64m1x2_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tu(vuint64m1x3_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tu(vuint64m1x4_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tu(vuint64m1x5_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tu(vuint64m1x6_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tu(vuint64m1x7_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tu(vuint64m1x8_t vd, const uint64_t *rs1,
                                      vuint64m1_t rs2, size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tu(vuint64m2x2_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tu(vuint64m2x3_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tu(vuint64m2x4_t vd, const uint64_t *rs1,
                                      vuint64m2_t rs2, size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tu(vuint64m4x2_t vd, const uint64_t *rs1,
                                      vuint64m4_t rs2, size_t vl);
// masked functions
vint8mf8x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tum(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tum(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tum(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tum(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tum(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tum(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tum(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tum(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tum(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tum(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tum(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tum(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tum(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tum(vbool2_t vm, vint8m4x2_t vd,
                                    const int8_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tum(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tum(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tum(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tum(vbool2_t vm, vint8m4x2_t vd,
                                     const int8_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tum(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tum(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tum(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tum(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tum(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tum(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tum(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tum(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tum(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tum(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tum(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tum(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tum(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tum(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tum(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tum(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tum(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tum(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tum(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tum(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tum(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tum(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tum(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tum(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tum(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tum(vbool2_t vm, vint8m4x2_t vd,
                                    const int8_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tum(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tum(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tum(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tum(vbool2_t vm, vint8m4x2_t vd,
                                     const int8_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tum(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tum(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tum(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tum(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tum(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tum(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tum(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tum(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tum(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tum(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tum(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tum(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tum(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tum(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tum(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tum(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tum(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tum(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tum(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tum(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tum(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tum(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tum(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tum(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tum(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tum(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tum(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tum(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tum(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tum(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tum(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tum(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tum(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tum(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tum(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tum(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tum(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tum(vbool2_t vm, vuint8m4x2_t vd,
                                     const uint8_t *rs1, vuint8m4_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tum(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tum(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tum(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tum(vbool2_t vm, vuint8m4x2_t vd,
                                      const uint8_t *rs1, vuint16m8_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tum(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tum(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tum(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tum(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tum(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tum(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tum(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tum(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tum(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tum(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tum(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tum(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tum(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tum(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tum(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tum(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tum(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tum(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tum(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tum(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tum(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tum(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tum(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tum(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tum(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tum(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tum(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tum(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tum(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tum(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tum(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tum(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tum(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tum(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tum(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tum(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tum(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tum(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tum(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tum(vbool2_t vm, vuint8m4x2_t vd,
                                     const uint8_t *rs1, vuint8m4_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tum(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tum(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tum(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tum(vbool2_t vm, vuint8m4x2_t vd,
                                      const uint8_t *rs1, vuint16m8_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tum(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tum(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tum(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tum(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tum(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tum(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tum(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tum(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tum(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tum(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tum(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tum(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tum(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tum(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tum(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tum(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tum(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tum(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tum(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tum(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tum(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tum(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tum(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tum(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tum(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tum(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tum(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tum(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tum(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tum(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tum(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tum(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tum(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tum(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tum(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tum(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tum(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tum(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tum(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tum(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tum(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tum(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tum(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tum(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tum(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tum(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
// masked functions
vint8mf8x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_tumu(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_tumu(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_tumu(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_tumu(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_tumu(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_tumu(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_tumu(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_tumu(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_tumu(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_tumu(vbool2_t vm, vint8m4x2_t vd,
                                     const int8_t *rs1, vuint8m4_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_tumu(vbool4_t vm, vint8m2x2_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_tumu(vbool4_t vm, vint8m2x3_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_tumu(vbool4_t vm, vint8m2x4_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_tumu(vbool2_t vm, vint8m4x2_t vd,
                                      const int8_t *rs1, vuint16m8_t rs2,
                                      size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_tumu(vbool4_t vm, vint8m2x2_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_tumu(vbool4_t vm, vint8m2x3_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_tumu(vbool4_t vm, vint8m2x4_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_tumu(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_tumu(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_tumu(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_tumu(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_tumu(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_tumu(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_tumu(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_tumu(vbool4_t vm, vint16m4x2_t vd,
                                       const int16_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_tumu(vbool4_t vm, vint16m4x2_t vd,
                                       const int16_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                      const int8_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                      const int8_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                      const int8_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vint8m1x2_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_tumu(vbool8_t vm, vint8m1x3_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_tumu(vbool8_t vm, vint8m1x4_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_tumu(vbool8_t vm, vint8m1x5_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_tumu(vbool8_t vm, vint8m1x6_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_tumu(vbool8_t vm, vint8m1x7_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_tumu(vbool8_t vm, vint8m1x8_t vd,
                                     const int8_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_tumu(vbool4_t vm, vint8m2x2_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_tumu(vbool4_t vm, vint8m2x3_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_tumu(vbool4_t vm, vint8m2x4_t vd,
                                     const int8_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_tumu(vbool2_t vm, vint8m4x2_t vd,
                                     const int8_t *rs1, vuint8m4_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_tumu(vbool4_t vm, vint8m2x2_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_tumu(vbool4_t vm, vint8m2x3_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_tumu(vbool4_t vm, vint8m2x4_t vd,
                                      const int8_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_tumu(vbool2_t vm, vint8m4x2_t vd,
                                      const int8_t *rs1, vuint16m8_t rs2,
                                      size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_tumu(vbool4_t vm, vint8m2x2_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_tumu(vbool4_t vm, vint8m2x3_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_tumu(vbool4_t vm, vint8m2x4_t vd,
                                      const int8_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vint8mf8x2_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vint8mf8x3_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vint8mf8x4_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vint8mf8x5_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vint8mf8x6_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vint8mf8x7_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vint8mf8x8_t vd,
                                       const int8_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vint8mf4x2_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vint8mf4x3_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vint8mf4x4_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vint8mf4x5_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vint8mf4x6_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vint8mf4x7_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vint8mf4x8_t vd,
                                       const int8_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vint8mf2x2_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vint8mf2x3_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vint8mf2x4_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_tumu(vbool16_t vm, vint8mf2x5_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_tumu(vbool16_t vm, vint8mf2x6_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_tumu(vbool16_t vm, vint8mf2x7_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_tumu(vbool16_t vm, vint8mf2x8_t vd,
                                       const int8_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vint8m1x2_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_tumu(vbool8_t vm, vint8m1x3_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_tumu(vbool8_t vm, vint8m1x4_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_tumu(vbool8_t vm, vint8m1x5_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_tumu(vbool8_t vm, vint8m1x6_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_tumu(vbool8_t vm, vint8m1x7_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_tumu(vbool8_t vm, vint8m1x8_t vd,
                                      const int8_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                       const int16_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                       const int16_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vint16m1x2_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vint16m1x3_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vint16m1x4_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_tumu(vbool16_t vm, vint16m1x5_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_tumu(vbool16_t vm, vint16m1x6_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_tumu(vbool16_t vm, vint16m1x7_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_tumu(vbool16_t vm, vint16m1x8_t vd,
                                      const int16_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vint16m2x2_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_tumu(vbool8_t vm, vint16m2x3_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_tumu(vbool8_t vm, vint16m2x4_t vd,
                                      const int16_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_tumu(vbool4_t vm, vint16m4x2_t vd,
                                      const int16_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_tumu(vbool4_t vm, vint16m4x2_t vd,
                                       const int16_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_tumu(vbool4_t vm, vint16m4x2_t vd,
                                       const int16_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vint16mf4x2_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vint16mf4x3_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vint16mf4x4_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vint16mf4x5_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vint16mf4x6_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vint16mf4x7_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vint16mf4x8_t vd,
                                        const int16_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vint16mf2x2_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vint16mf2x3_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vint16mf2x4_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vint16mf2x5_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vint16mf2x6_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vint16mf2x7_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vint16mf2x8_t vd,
                                        const int16_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vint16m1x2_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vint16m1x3_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vint16m1x4_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_tumu(vbool16_t vm, vint16m1x5_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_tumu(vbool16_t vm, vint16m1x6_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_tumu(vbool16_t vm, vint16m1x7_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_tumu(vbool16_t vm, vint16m1x8_t vd,
                                       const int16_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vint16m2x2_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_tumu(vbool8_t vm, vint16m2x3_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_tumu(vbool8_t vm, vint16m2x4_t vd,
                                       const int16_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                       const int32_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vint32m1x2_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vint32m1x3_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vint32m1x4_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vint32m1x5_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vint32m1x6_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vint32m1x7_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vint32m1x8_t vd,
                                      const int32_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vint32m2x2_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vint32m2x3_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vint32m2x4_t vd,
                                      const int32_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vint32m4x2_t vd,
                                      const int32_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vint32mf2x2_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vint32mf2x3_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vint32mf2x4_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vint32mf2x5_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vint32mf2x6_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vint32mf2x7_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vint32mf2x8_t vd,
                                        const int32_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vint32m1x2_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vint32m1x3_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vint32m1x4_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vint32m1x5_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vint32m1x6_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vint32m1x7_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vint32m1x8_t vd,
                                       const int32_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vint32m2x2_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vint32m2x3_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vint32m2x4_t vd,
                                       const int32_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vint32m4x2_t vd,
                                       const int32_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vint64m1x2_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vint64m1x3_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vint64m1x4_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vint64m1x5_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vint64m1x6_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vint64m1x7_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vint64m1x8_t vd,
                                      const int64_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vint64m2x2_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vint64m2x3_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vint64m2x4_t vd,
                                      const int64_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vint64m4x2_t vd,
                                      const int64_t *rs1, vuint8mf2_t rs2,
                                      size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint16m1_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint32m2_t rs2,
                                       size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vint64m1x2_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vint64m1x3_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vint64m1x4_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vint64m1x5_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vint64m1x6_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vint64m1x7_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vint64m1x8_t vd,
                                       const int64_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vint64m2x2_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vint64m2x3_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vint64m2x4_t vd,
                                       const int64_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vint64m4x2_t vd,
                                       const int64_t *rs1, vuint64m4_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                      const uint8_t *rs1, vuint8m4_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                       const uint8_t *rs1, vuint16m8_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint8m2_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                        const uint16_t *rs1, vuint16m4_t rs2,
                                        size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                        const uint16_t *rs1, vuint32m8_t rs2,
                                        size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                       const uint8_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                       const uint8_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                       const uint8_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                      const uint8_t *rs1, vuint8m1_t rs2,
                                      size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                      const uint8_t *rs1, vuint8m2_t rs2,
                                      size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                      const uint8_t *rs1, vuint8m4_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint16m2_t rs2,
                                       size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                       const uint8_t *rs1, vuint16m4_t rs2,
                                       size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_tumu(vbool2_t vm, vuint8m4x2_t vd,
                                       const uint8_t *rs1, vuint16m8_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint32m4_t rs2,
                                       size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_tumu(vbool4_t vm, vuint8m2x2_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_tumu(vbool4_t vm, vuint8m2x3_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_tumu(vbool4_t vm, vuint8m2x4_t vd,
                                       const uint8_t *rs1, vuint32m8_t rs2,
                                       size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vuint8mf8x2_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vuint8mf8x3_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vuint8mf8x4_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vuint8mf8x5_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vuint8mf8x6_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vuint8mf8x7_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vuint8mf8x8_t vd,
                                        const uint8_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vuint8mf4x2_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vuint8mf4x3_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vuint8mf4x4_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vuint8mf4x5_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vuint8mf4x6_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vuint8mf4x7_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vuint8mf4x8_t vd,
                                        const uint8_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vuint8mf2x2_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vuint8mf2x3_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vuint8mf2x4_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_tumu(vbool16_t vm, vuint8mf2x5_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_tumu(vbool16_t vm, vuint8mf2x6_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_tumu(vbool16_t vm, vuint8mf2x7_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_tumu(vbool16_t vm, vuint8mf2x8_t vd,
                                        const uint8_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vuint8m1x2_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_tumu(vbool8_t vm, vuint8m1x3_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_tumu(vbool8_t vm, vuint8m1x4_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_tumu(vbool8_t vm, vuint8m1x5_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_tumu(vbool8_t vm, vuint8m1x6_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_tumu(vbool8_t vm, vuint8m1x7_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_tumu(vbool8_t vm, vuint8m1x8_t vd,
                                       const uint8_t *rs1, vuint64m8_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                        const uint16_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                        const uint16_t *rs1, vuint8mf4_t rs2,
                                        size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                       const uint16_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                       const uint16_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                       const uint16_t *rs1, vuint8m2_t rs2,
                                       size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint16mf2_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                        const uint16_t *rs1, vuint16m4_t rs2,
                                        size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint32m1_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_tumu(vbool4_t vm, vuint16m4x2_t vd,
                                        const uint16_t *rs1, vuint32m8_t rs2,
                                        size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vuint16mf4x2_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vuint16mf4x3_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vuint16mf4x4_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vuint16mf4x5_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vuint16mf4x6_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vuint16mf4x7_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vuint16mf4x8_t vd,
                                         const uint16_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vuint16mf2x2_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vuint16mf2x3_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vuint16mf2x4_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vuint16mf2x5_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vuint16mf2x6_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vuint16mf2x7_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vuint16mf2x8_t vd,
                                         const uint16_t *rs1, vuint64m2_t rs2,
                                         size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vuint16m1x2_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vuint16m1x3_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vuint16m1x4_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_tumu(vbool16_t vm, vuint16m1x5_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_tumu(vbool16_t vm, vuint16m1x6_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_tumu(vbool16_t vm, vuint16m1x7_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_tumu(vbool16_t vm, vuint16m1x8_t vd,
                                        const uint16_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vuint16m2x2_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_tumu(vbool8_t vm, vuint16m2x3_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_tumu(vbool8_t vm, vuint16m2x4_t vd,
                                        const uint16_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                        const uint32_t *rs1, vuint8mf8_t rs2,
                                        size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                       const uint32_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                       const uint32_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                       const uint32_t *rs1, vuint8m1_t rs2,
                                       size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint16mf4_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint16m2_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint32m4_t rs2,
                                        size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vuint32mf2x2_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vuint32mf2x3_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vuint32mf2x4_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vuint32mf2x5_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vuint32mf2x6_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vuint32mf2x7_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vuint32mf2x8_t vd,
                                         const uint32_t *rs1, vuint64m1_t rs2,
                                         size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vuint32m1x2_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vuint32m1x3_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vuint32m1x4_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vuint32m1x5_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vuint32m1x6_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vuint32m1x7_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vuint32m1x8_t vd,
                                        const uint32_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vuint32m2x2_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vuint32m2x3_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vuint32m2x4_t vd,
                                        const uint32_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vuint32m4x2_t vd,
                                        const uint32_t *rs1, vuint64m8_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                       const uint64_t *rs1, vuint8mf8_t rs2,
                                       size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                       const uint64_t *rs1, vuint8mf4_t rs2,
                                       size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                       const uint64_t *rs1, vuint8mf2_t rs2,
                                       size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint16mf4_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint16mf2_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint16m1_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint32m1_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint32m2_t rs2,
                                        size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vuint64m1x2_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vuint64m1x3_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vuint64m1x4_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vuint64m1x5_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vuint64m1x6_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vuint64m1x7_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vuint64m1x8_t vd,
                                        const uint64_t *rs1, vuint64m1_t rs2,
                                        size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vuint64m2x2_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vuint64m2x3_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vuint64m2x4_t vd,
                                        const uint64_t *rs1, vuint64m2_t rs2,
                                        size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vuint64m4x2_t vd,
                                        const uint64_t *rs1, vuint64m4_t rs2,
                                        size_t vl);
// masked functions
vint8mf8x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vint8mf8x2_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vint8mf8x3_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vint8mf8x4_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vint8mf8x5_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vint8mf8x6_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vint8mf8x7_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vint8mf8x8_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vint8mf4x2_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vint8mf4x3_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vint8mf4x4_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vint8mf4x5_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vint8mf4x6_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vint8mf4x7_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vint8mf4x8_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vint8mf2x2_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vint8mf2x3_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vint8mf2x4_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei8_mu(vbool16_t vm, vint8mf2x5_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei8_mu(vbool16_t vm, vint8mf2x6_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei8_mu(vbool16_t vm, vint8mf2x7_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei8_mu(vbool16_t vm, vint8mf2x8_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8m1x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vint8m1x2_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x3_t __riscv_vloxseg3ei8_mu(vbool8_t vm, vint8m1x3_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x4_t __riscv_vloxseg4ei8_mu(vbool8_t vm, vint8m1x4_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x5_t __riscv_vloxseg5ei8_mu(vbool8_t vm, vint8m1x5_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x6_t __riscv_vloxseg6ei8_mu(vbool8_t vm, vint8m1x6_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x7_t __riscv_vloxseg7ei8_mu(vbool8_t vm, vint8m1x7_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x8_t __riscv_vloxseg8ei8_mu(vbool8_t vm, vint8m1x8_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m2x2_t __riscv_vloxseg2ei8_mu(vbool4_t vm, vint8m2x2_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m2x3_t __riscv_vloxseg3ei8_mu(vbool4_t vm, vint8m2x3_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m2x4_t __riscv_vloxseg4ei8_mu(vbool4_t vm, vint8m2x4_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m4x2_t __riscv_vloxseg2ei8_mu(vbool2_t vm, vint8m4x2_t vd,
                                   const int8_t *rs1, vuint8m4_t rs2,
                                   size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei16_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei16_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei16_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei16_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vloxseg3ei16_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vloxseg4ei16_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vloxseg5ei16_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vloxseg6ei16_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vloxseg7ei16_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vloxseg8ei16_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vloxseg2ei16_mu(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vloxseg3ei16_mu(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vloxseg4ei16_mu(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m4x2_t __riscv_vloxseg2ei16_mu(vbool2_t vm, vint8m4x2_t vd,
                                    const int8_t *rs1, vuint16m8_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei32_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei32_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei32_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei32_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vloxseg3ei32_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vloxseg4ei32_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vloxseg5ei32_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vloxseg6ei32_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vloxseg7ei32_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vloxseg8ei32_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vloxseg2ei32_mu(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vloxseg3ei32_mu(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vloxseg4ei32_mu(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vloxseg5ei64_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vloxseg6ei64_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vloxseg7ei64_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vloxseg8ei64_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vloxseg3ei64_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vloxseg4ei64_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vloxseg5ei64_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vloxseg6ei64_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vloxseg7ei64_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vloxseg8ei64_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vint16mf4x2_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vint16mf4x3_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vint16mf4x4_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vint16mf4x5_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vint16mf4x6_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vint16mf4x7_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vint16mf4x8_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vint16mf2x2_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vint16mf2x3_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vint16mf2x4_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vint16mf2x5_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vint16mf2x6_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vint16mf2x7_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vint16mf2x8_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16m1x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vint16m1x2_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vint16m1x3_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vint16m1x4_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x5_t __riscv_vloxseg5ei8_mu(vbool16_t vm, vint16m1x5_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x6_t __riscv_vloxseg6ei8_mu(vbool16_t vm, vint16m1x6_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x7_t __riscv_vloxseg7ei8_mu(vbool16_t vm, vint16m1x7_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x8_t __riscv_vloxseg8ei8_mu(vbool16_t vm, vint16m1x8_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m2x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vint16m2x2_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m2x3_t __riscv_vloxseg3ei8_mu(vbool8_t vm, vint16m2x3_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m2x4_t __riscv_vloxseg4ei8_mu(vbool8_t vm, vint16m2x4_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m4x2_t __riscv_vloxseg2ei8_mu(vbool4_t vm, vint16m4x2_t vd,
                                    const int16_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vloxseg5ei16_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vloxseg6ei16_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vloxseg7ei16_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vloxseg8ei16_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vloxseg3ei16_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vloxseg4ei16_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vloxseg2ei16_mu(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vloxseg5ei32_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vloxseg6ei32_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vloxseg7ei32_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vloxseg8ei32_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vloxseg3ei32_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vloxseg4ei32_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vloxseg2ei32_mu(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vloxseg5ei64_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vloxseg6ei64_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vloxseg7ei64_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vloxseg8ei64_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vloxseg3ei64_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vloxseg4ei64_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vint32mf2x2_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vint32mf2x3_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vint32mf2x4_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vint32mf2x5_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vint32mf2x6_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vint32mf2x7_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vint32mf2x8_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32m1x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vint32m1x2_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vint32m1x3_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vint32m1x4_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vint32m1x5_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vint32m1x6_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vint32m1x7_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vint32m1x8_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m2x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vint32m2x2_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m2x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vint32m2x3_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m2x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vint32m2x4_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m4x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vint32m4x2_t vd,
                                    const int32_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vint64m1x2_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vint64m1x3_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vint64m1x4_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vint64m1x5_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vint64m1x6_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vint64m1x7_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vint64m1x8_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m2x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vint64m2x2_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m2x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vint64m2x3_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m2x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vint64m2x4_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m4x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vint64m4x2_t vd,
                                    const int64_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint64m1x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vint8mf8x2_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vint8mf8x3_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vint8mf8x4_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vint8mf8x5_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vint8mf8x6_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vint8mf8x7_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vint8mf8x8_t vd,
                                    const int8_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vint8mf4x2_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vint8mf4x3_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vint8mf4x4_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vint8mf4x5_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vint8mf4x6_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vint8mf4x7_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vint8mf4x8_t vd,
                                    const int8_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vint8mf2x2_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vint8mf2x3_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vint8mf2x4_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei8_mu(vbool16_t vm, vint8mf2x5_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei8_mu(vbool16_t vm, vint8mf2x6_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei8_mu(vbool16_t vm, vint8mf2x7_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei8_mu(vbool16_t vm, vint8mf2x8_t vd,
                                    const int8_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint8m1x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vint8m1x2_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x3_t __riscv_vluxseg3ei8_mu(vbool8_t vm, vint8m1x3_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x4_t __riscv_vluxseg4ei8_mu(vbool8_t vm, vint8m1x4_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x5_t __riscv_vluxseg5ei8_mu(vbool8_t vm, vint8m1x5_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x6_t __riscv_vluxseg6ei8_mu(vbool8_t vm, vint8m1x6_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x7_t __riscv_vluxseg7ei8_mu(vbool8_t vm, vint8m1x7_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m1x8_t __riscv_vluxseg8ei8_mu(vbool8_t vm, vint8m1x8_t vd,
                                   const int8_t *rs1, vuint8m1_t rs2,
                                   size_t vl);
vint8m2x2_t __riscv_vluxseg2ei8_mu(vbool4_t vm, vint8m2x2_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m2x3_t __riscv_vluxseg3ei8_mu(vbool4_t vm, vint8m2x3_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m2x4_t __riscv_vluxseg4ei8_mu(vbool4_t vm, vint8m2x4_t vd,
                                   const int8_t *rs1, vuint8m2_t rs2,
                                   size_t vl);
vint8m4x2_t __riscv_vluxseg2ei8_mu(vbool2_t vm, vint8m4x2_t vd,
                                   const int8_t *rs1, vuint8m4_t rs2,
                                   size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei16_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei16_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei16_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei16_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vluxseg3ei16_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vluxseg4ei16_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vluxseg5ei16_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vluxseg6ei16_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vluxseg7ei16_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vluxseg8ei16_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint16m2_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vluxseg2ei16_mu(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vluxseg3ei16_mu(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vluxseg4ei16_mu(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint16m4_t rs2,
                                    size_t vl);
vint8m4x2_t __riscv_vluxseg2ei16_mu(vbool2_t vm, vint8m4x2_t vd,
                                    const int8_t *rs1, vuint16m8_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei32_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei32_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei32_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei32_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vluxseg3ei32_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vluxseg4ei32_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vluxseg5ei32_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vluxseg6ei32_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vluxseg7ei32_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vluxseg8ei32_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint32m4_t rs2,
                                    size_t vl);
vint8m2x2_t __riscv_vluxseg2ei32_mu(vbool4_t vm, vint8m2x2_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8m2x3_t __riscv_vluxseg3ei32_mu(vbool4_t vm, vint8m2x3_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8m2x4_t __riscv_vluxseg4ei32_mu(vbool4_t vm, vint8m2x4_t vd,
                                    const int8_t *rs1, vuint32m8_t rs2,
                                    size_t vl);
vint8mf8x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vint8mf8x2_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vint8mf8x3_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vint8mf8x4_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vint8mf8x5_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vint8mf8x6_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vint8mf8x7_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf8x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vint8mf8x8_t vd,
                                     const int8_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint8mf4x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vint8mf4x2_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vint8mf4x3_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vint8mf4x4_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vint8mf4x5_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vint8mf4x6_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vint8mf4x7_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf4x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vint8mf4x8_t vd,
                                     const int8_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint8mf2x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vint8mf2x2_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vint8mf2x3_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vint8mf2x4_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x5_t __riscv_vluxseg5ei64_mu(vbool16_t vm, vint8mf2x5_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x6_t __riscv_vluxseg6ei64_mu(vbool16_t vm, vint8mf2x6_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x7_t __riscv_vluxseg7ei64_mu(vbool16_t vm, vint8mf2x7_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8mf2x8_t __riscv_vluxseg8ei64_mu(vbool16_t vm, vint8mf2x8_t vd,
                                     const int8_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint8m1x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vint8m1x2_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x3_t __riscv_vluxseg3ei64_mu(vbool8_t vm, vint8m1x3_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x4_t __riscv_vluxseg4ei64_mu(vbool8_t vm, vint8m1x4_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x5_t __riscv_vluxseg5ei64_mu(vbool8_t vm, vint8m1x5_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x6_t __riscv_vluxseg6ei64_mu(vbool8_t vm, vint8m1x6_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x7_t __riscv_vluxseg7ei64_mu(vbool8_t vm, vint8m1x7_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint8m1x8_t __riscv_vluxseg8ei64_mu(vbool8_t vm, vint8m1x8_t vd,
                                    const int8_t *rs1, vuint64m8_t rs2,
                                    size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vint16mf4x2_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vint16mf4x3_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vint16mf4x4_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vint16mf4x5_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vint16mf4x6_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vint16mf4x7_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vint16mf4x8_t vd,
                                     const int16_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vint16mf2x2_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vint16mf2x3_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vint16mf2x4_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vint16mf2x5_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vint16mf2x6_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vint16mf2x7_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vint16mf2x8_t vd,
                                     const int16_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vint16m1x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vint16m1x2_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vint16m1x3_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vint16m1x4_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x5_t __riscv_vluxseg5ei8_mu(vbool16_t vm, vint16m1x5_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x6_t __riscv_vluxseg6ei8_mu(vbool16_t vm, vint16m1x6_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x7_t __riscv_vluxseg7ei8_mu(vbool16_t vm, vint16m1x7_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m1x8_t __riscv_vluxseg8ei8_mu(vbool16_t vm, vint16m1x8_t vd,
                                    const int16_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint16m2x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vint16m2x2_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m2x3_t __riscv_vluxseg3ei8_mu(vbool8_t vm, vint16m2x3_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m2x4_t __riscv_vluxseg4ei8_mu(vbool8_t vm, vint16m2x4_t vd,
                                    const int16_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint16m4x2_t __riscv_vluxseg2ei8_mu(vbool4_t vm, vint16m4x2_t vd,
                                    const int16_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vluxseg5ei16_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vluxseg6ei16_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vluxseg7ei16_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vluxseg8ei16_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vluxseg3ei16_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vluxseg4ei16_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vluxseg2ei16_mu(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vluxseg5ei32_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vluxseg6ei32_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vluxseg7ei32_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vluxseg8ei32_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vluxseg3ei32_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vluxseg4ei32_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint16m4x2_t __riscv_vluxseg2ei32_mu(vbool4_t vm, vint16m4x2_t vd,
                                     const int16_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vint16mf4x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vint16mf4x2_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vint16mf4x3_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vint16mf4x4_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vint16mf4x5_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vint16mf4x6_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vint16mf4x7_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf4x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vint16mf4x8_t vd,
                                      const int16_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint16mf2x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vint16mf2x2_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vint16mf2x3_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vint16mf2x4_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vint16mf2x5_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vint16mf2x6_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vint16mf2x7_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16mf2x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vint16mf2x8_t vd,
                                      const int16_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vint16m1x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vint16m1x2_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vint16m1x3_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vint16m1x4_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x5_t __riscv_vluxseg5ei64_mu(vbool16_t vm, vint16m1x5_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x6_t __riscv_vluxseg6ei64_mu(vbool16_t vm, vint16m1x6_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x7_t __riscv_vluxseg7ei64_mu(vbool16_t vm, vint16m1x7_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m1x8_t __riscv_vluxseg8ei64_mu(vbool16_t vm, vint16m1x8_t vd,
                                     const int16_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint16m2x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vint16m2x2_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16m2x3_t __riscv_vluxseg3ei64_mu(vbool8_t vm, vint16m2x3_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint16m2x4_t __riscv_vluxseg4ei64_mu(vbool8_t vm, vint16m2x4_t vd,
                                     const int16_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vint32mf2x2_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vint32mf2x3_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vint32mf2x4_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vint32mf2x5_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vint32mf2x6_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vint32mf2x7_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vint32mf2x8_t vd,
                                     const int32_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vint32m1x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vint32m1x2_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vint32m1x3_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vint32m1x4_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vint32m1x5_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vint32m1x6_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vint32m1x7_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m1x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vint32m1x8_t vd,
                                    const int32_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint32m2x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vint32m2x2_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m2x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vint32m2x3_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m2x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vint32m2x4_t vd,
                                    const int32_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint32m4x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vint32m4x2_t vd,
                                    const int32_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vint32mf2x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vint32mf2x2_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vint32mf2x3_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vint32mf2x4_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vint32mf2x5_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vint32mf2x6_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vint32mf2x7_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32mf2x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vint32mf2x8_t vd,
                                      const int32_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vint32m1x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vint32m1x2_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vint32m1x3_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vint32m1x4_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vint32m1x5_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vint32m1x6_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vint32m1x7_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m1x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vint32m1x8_t vd,
                                     const int32_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint32m2x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vint32m2x2_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m2x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vint32m2x3_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m2x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vint32m2x4_t vd,
                                     const int32_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vint32m4x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vint32m4x2_t vd,
                                     const int32_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vint64m1x2_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vint64m1x3_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vint64m1x4_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vint64m1x5_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vint64m1x6_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vint64m1x7_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m1x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vint64m1x8_t vd,
                                    const int64_t *rs1, vuint8mf8_t rs2,
                                    size_t vl);
vint64m2x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vint64m2x2_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m2x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vint64m2x3_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m2x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vint64m2x4_t vd,
                                    const int64_t *rs1, vuint8mf4_t rs2,
                                    size_t vl);
vint64m4x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vint64m4x2_t vd,
                                    const int64_t *rs1, vuint8mf2_t rs2,
                                    size_t vl);
vint64m1x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint16mf4_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint16mf2_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint16m1_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint32mf2_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint32m1_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint32m2_t rs2,
                                     size_t vl);
vint64m1x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vint64m1x2_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vint64m1x3_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vint64m1x4_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vint64m1x5_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vint64m1x6_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vint64m1x7_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m1x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vint64m1x8_t vd,
                                     const int64_t *rs1, vuint64m1_t rs2,
                                     size_t vl);
vint64m2x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vint64m2x2_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m2x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vint64m2x3_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m2x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vint64m2x4_t vd,
                                     const int64_t *rs1, vuint64m2_t rs2,
                                     size_t vl);
vint64m4x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vint64m4x2_t vd,
                                     const int64_t *rs1, vuint64m4_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei8_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei8_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei8_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei8_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vuint8m1x2_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei8_mu(vbool8_t vm, vuint8m1x3_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei8_mu(vbool8_t vm, vuint8m1x4_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei8_mu(vbool8_t vm, vuint8m1x5_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei8_mu(vbool8_t vm, vuint8m1x6_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei8_mu(vbool8_t vm, vuint8m1x7_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei8_mu(vbool8_t vm, vuint8m1x8_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei8_mu(vbool4_t vm, vuint8m2x2_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei8_mu(vbool4_t vm, vuint8m2x3_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei8_mu(vbool4_t vm, vuint8m2x4_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei8_mu(vbool2_t vm, vuint8m4x2_t vd,
                                    const uint8_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei16_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei16_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei16_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei16_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei16_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei16_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei16_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei16_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei16_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei16_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei16_mu(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei16_mu(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei16_mu(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m4x2_t __riscv_vloxseg2ei16_mu(vbool2_t vm, vuint8m4x2_t vd,
                                     const uint8_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei32_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei32_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei32_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei32_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei32_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei32_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei32_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei32_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei32_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei32_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vloxseg2ei32_mu(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vloxseg3ei32_mu(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vloxseg4ei32_mu(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vloxseg5ei64_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vloxseg6ei64_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vloxseg7ei64_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vloxseg8ei64_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vloxseg3ei64_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vloxseg4ei64_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vloxseg5ei64_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vloxseg6ei64_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vloxseg7ei64_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vloxseg8ei64_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vuint16m1x2_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vuint16m1x3_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vuint16m1x4_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei8_mu(vbool16_t vm, vuint16m1x5_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei8_mu(vbool16_t vm, vuint16m1x6_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei8_mu(vbool16_t vm, vuint16m1x7_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei8_mu(vbool16_t vm, vuint16m1x8_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vuint16m2x2_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei8_mu(vbool8_t vm, vuint16m2x3_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei8_mu(vbool8_t vm, vuint16m2x4_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei8_mu(vbool4_t vm, vuint16m4x2_t vd,
                                     const uint16_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei16_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei16_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei16_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei16_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei16_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei16_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei16_mu(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei32_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei32_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei32_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei32_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei32_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei32_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vloxseg2ei32_mu(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vloxseg5ei64_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vloxseg6ei64_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vloxseg7ei64_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vloxseg8ei64_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vloxseg3ei64_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vloxseg4ei64_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vuint32m1x2_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vuint32m1x3_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vuint32m1x4_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei8_mu(vbool32_t vm, vuint32m1x5_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei8_mu(vbool32_t vm, vuint32m1x6_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei8_mu(vbool32_t vm, vuint32m1x7_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei8_mu(vbool32_t vm, vuint32m1x8_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vuint32m2x2_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei8_mu(vbool16_t vm, vuint32m2x3_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei8_mu(vbool16_t vm, vuint32m2x4_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei8_mu(vbool8_t vm, vuint32m4x2_t vd,
                                     const uint32_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei16_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei16_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei16_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei16_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei16_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei16_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei16_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei8_mu(vbool64_t vm, vuint64m1x2_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei8_mu(vbool64_t vm, vuint64m1x3_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei8_mu(vbool64_t vm, vuint64m1x4_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei8_mu(vbool64_t vm, vuint64m1x5_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei8_mu(vbool64_t vm, vuint64m1x6_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei8_mu(vbool64_t vm, vuint64m1x7_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei8_mu(vbool64_t vm, vuint64m1x8_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei8_mu(vbool32_t vm, vuint64m2x2_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei8_mu(vbool32_t vm, vuint64m2x3_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei8_mu(vbool32_t vm, vuint64m2x4_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei8_mu(vbool16_t vm, vuint64m4x2_t vd,
                                     const uint64_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei16_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei16_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei16_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei16_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei16_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei16_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei16_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei16_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei16_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei16_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei16_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                     const uint8_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                     const uint8_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei8_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei8_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei8_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei8_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                     const uint8_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vuint8m1x2_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei8_mu(vbool8_t vm, vuint8m1x3_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei8_mu(vbool8_t vm, vuint8m1x4_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei8_mu(vbool8_t vm, vuint8m1x5_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei8_mu(vbool8_t vm, vuint8m1x6_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei8_mu(vbool8_t vm, vuint8m1x7_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei8_mu(vbool8_t vm, vuint8m1x8_t vd,
                                    const uint8_t *rs1, vuint8m1_t rs2,
                                    size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei8_mu(vbool4_t vm, vuint8m2x2_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei8_mu(vbool4_t vm, vuint8m2x3_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei8_mu(vbool4_t vm, vuint8m2x4_t vd,
                                    const uint8_t *rs1, vuint8m2_t rs2,
                                    size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei8_mu(vbool2_t vm, vuint8m4x2_t vd,
                                    const uint8_t *rs1, vuint8m4_t rs2,
                                    size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei16_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei16_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei16_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei16_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei16_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei16_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei16_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei16_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei16_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei16_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint16m2_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei16_mu(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei16_mu(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei16_mu(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint16m4_t rs2,
                                     size_t vl);
vuint8m4x2_t __riscv_vluxseg2ei16_mu(vbool2_t vm, vuint8m4x2_t vd,
                                     const uint8_t *rs1, vuint16m8_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei32_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei32_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei32_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei32_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei32_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei32_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei32_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei32_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei32_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei32_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint32m4_t rs2,
                                     size_t vl);
vuint8m2x2_t __riscv_vluxseg2ei32_mu(vbool4_t vm, vuint8m2x2_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8m2x3_t __riscv_vluxseg3ei32_mu(vbool4_t vm, vuint8m2x3_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8m2x4_t __riscv_vluxseg4ei32_mu(vbool4_t vm, vuint8m2x4_t vd,
                                     const uint8_t *rs1, vuint32m8_t rs2,
                                     size_t vl);
vuint8mf8x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vuint8mf8x2_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vuint8mf8x3_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vuint8mf8x4_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vuint8mf8x5_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vuint8mf8x6_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vuint8mf8x7_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf8x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vuint8mf8x8_t vd,
                                      const uint8_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint8mf4x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vuint8mf4x2_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vuint8mf4x3_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vuint8mf4x4_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vuint8mf4x5_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vuint8mf4x6_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vuint8mf4x7_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf4x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vuint8mf4x8_t vd,
                                      const uint8_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint8mf2x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vuint8mf2x2_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vuint8mf2x3_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vuint8mf2x4_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x5_t __riscv_vluxseg5ei64_mu(vbool16_t vm, vuint8mf2x5_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x6_t __riscv_vluxseg6ei64_mu(vbool16_t vm, vuint8mf2x6_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x7_t __riscv_vluxseg7ei64_mu(vbool16_t vm, vuint8mf2x7_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8mf2x8_t __riscv_vluxseg8ei64_mu(vbool16_t vm, vuint8mf2x8_t vd,
                                      const uint8_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint8m1x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vuint8m1x2_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x3_t __riscv_vluxseg3ei64_mu(vbool8_t vm, vuint8m1x3_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x4_t __riscv_vluxseg4ei64_mu(vbool8_t vm, vuint8m1x4_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x5_t __riscv_vluxseg5ei64_mu(vbool8_t vm, vuint8m1x5_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x6_t __riscv_vluxseg6ei64_mu(vbool8_t vm, vuint8m1x6_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x7_t __riscv_vluxseg7ei64_mu(vbool8_t vm, vuint8m1x7_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint8m1x8_t __riscv_vluxseg8ei64_mu(vbool8_t vm, vuint8m1x8_t vd,
                                     const uint8_t *rs1, vuint64m8_t rs2,
                                     size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                      const uint16_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                      const uint16_t *rs1, vuint8mf4_t rs2,
                                      size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vuint16m1x2_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vuint16m1x3_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vuint16m1x4_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei8_mu(vbool16_t vm, vuint16m1x5_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei8_mu(vbool16_t vm, vuint16m1x6_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei8_mu(vbool16_t vm, vuint16m1x7_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei8_mu(vbool16_t vm, vuint16m1x8_t vd,
                                     const uint16_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vuint16m2x2_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei8_mu(vbool8_t vm, vuint16m2x3_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei8_mu(vbool8_t vm, vuint16m2x4_t vd,
                                     const uint16_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei8_mu(vbool4_t vm, vuint16m4x2_t vd,
                                     const uint16_t *rs1, vuint8m2_t rs2,
                                     size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint16mf2_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei16_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei16_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei16_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei16_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei16_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei16_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei16_mu(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint16m4_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint32m1_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei32_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei32_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei32_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei32_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei32_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei32_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint16m4x2_t __riscv_vluxseg2ei32_mu(vbool4_t vm, vuint16m4x2_t vd,
                                      const uint16_t *rs1, vuint32m8_t rs2,
                                      size_t vl);
vuint16mf4x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vuint16mf4x2_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vuint16mf4x3_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vuint16mf4x4_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vuint16mf4x5_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vuint16mf4x6_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vuint16mf4x7_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf4x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vuint16mf4x8_t vd,
                                       const uint16_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint16mf2x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vuint16mf2x2_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vuint16mf2x3_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vuint16mf2x4_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vuint16mf2x5_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vuint16mf2x6_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vuint16mf2x7_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16mf2x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vuint16mf2x8_t vd,
                                       const uint16_t *rs1, vuint64m2_t rs2,
                                       size_t vl);
vuint16m1x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vuint16m1x2_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vuint16m1x3_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vuint16m1x4_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x5_t __riscv_vluxseg5ei64_mu(vbool16_t vm, vuint16m1x5_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x6_t __riscv_vluxseg6ei64_mu(vbool16_t vm, vuint16m1x6_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x7_t __riscv_vluxseg7ei64_mu(vbool16_t vm, vuint16m1x7_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m1x8_t __riscv_vluxseg8ei64_mu(vbool16_t vm, vuint16m1x8_t vd,
                                      const uint16_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint16m2x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vuint16m2x2_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16m2x3_t __riscv_vluxseg3ei64_mu(vbool8_t vm, vuint16m2x3_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint16m2x4_t __riscv_vluxseg4ei64_mu(vbool8_t vm, vuint16m2x4_t vd,
                                      const uint16_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                      const uint32_t *rs1, vuint8mf8_t rs2,
                                      size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vuint32m1x2_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vuint32m1x3_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vuint32m1x4_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei8_mu(vbool32_t vm, vuint32m1x5_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei8_mu(vbool32_t vm, vuint32m1x6_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei8_mu(vbool32_t vm, vuint32m1x7_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei8_mu(vbool32_t vm, vuint32m1x8_t vd,
                                     const uint32_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vuint32m2x2_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei8_mu(vbool16_t vm, vuint32m2x3_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei8_mu(vbool16_t vm, vuint32m2x4_t vd,
                                     const uint32_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei8_mu(vbool8_t vm, vuint32m4x2_t vd,
                                     const uint32_t *rs1, vuint8m1_t rs2,
                                     size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint16mf4_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei16_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei16_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei16_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei16_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei16_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei16_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei16_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint16m2_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint32m4_t rs2,
                                      size_t vl);
vuint32mf2x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vuint32mf2x2_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vuint32mf2x3_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vuint32mf2x4_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vuint32mf2x5_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vuint32mf2x6_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vuint32mf2x7_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32mf2x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vuint32mf2x8_t vd,
                                       const uint32_t *rs1, vuint64m1_t rs2,
                                       size_t vl);
vuint32m1x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vuint32m1x2_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vuint32m1x3_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vuint32m1x4_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vuint32m1x5_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vuint32m1x6_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vuint32m1x7_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m1x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vuint32m1x8_t vd,
                                      const uint32_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint32m2x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vuint32m2x2_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m2x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vuint32m2x3_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m2x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vuint32m2x4_t vd,
                                      const uint32_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
vuint32m4x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vuint32m4x2_t vd,
                                      const uint32_t *rs1, vuint64m8_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei8_mu(vbool64_t vm, vuint64m1x2_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei8_mu(vbool64_t vm, vuint64m1x3_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei8_mu(vbool64_t vm, vuint64m1x4_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei8_mu(vbool64_t vm, vuint64m1x5_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei8_mu(vbool64_t vm, vuint64m1x6_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei8_mu(vbool64_t vm, vuint64m1x7_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei8_mu(vbool64_t vm, vuint64m1x8_t vd,
                                     const uint64_t *rs1, vuint8mf8_t rs2,
                                     size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei8_mu(vbool32_t vm, vuint64m2x2_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei8_mu(vbool32_t vm, vuint64m2x3_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei8_mu(vbool32_t vm, vuint64m2x4_t vd,
                                     const uint64_t *rs1, vuint8mf4_t rs2,
                                     size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei8_mu(vbool16_t vm, vuint64m4x2_t vd,
                                     const uint64_t *rs1, vuint8mf2_t rs2,
                                     size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei16_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei16_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei16_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei16_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei16_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei16_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei16_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint16mf4_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei16_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei16_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei16_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint16mf2_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei16_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint16m1_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint32mf2_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint32m1_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint32m2_t rs2,
                                      size_t vl);
vuint64m1x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vuint64m1x2_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vuint64m1x3_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vuint64m1x4_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vuint64m1x5_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vuint64m1x6_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vuint64m1x7_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m1x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vuint64m1x8_t vd,
                                      const uint64_t *rs1, vuint64m1_t rs2,
                                      size_t vl);
vuint64m2x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vuint64m2x2_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m2x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vuint64m2x3_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m2x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vuint64m2x4_t vd,
                                      const uint64_t *rs1, vuint64m2_t rs2,
                                      size_t vl);
vuint64m4x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vuint64m4x2_t vd,
                                      const uint64_t *rs1, vuint64m4_t rs2,
                                      size_t vl);
----

[[policy-variant-overloadedfloat-vector-indexed-segment-load]]
==== Float Vector Indexed Segment Load Intrinsics

[,c]
----
vfloat32mf2x2_t __riscv_vloxseg2ei32_tu(vfloat32mf2x2_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tu(vfloat32mf2x3_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tu(vfloat32mf2x4_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tu(vfloat32mf2x5_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tu(vfloat32mf2x6_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tu(vfloat32mf2x7_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tu(vfloat32mf2x8_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tu(vfloat32m1x2_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tu(vfloat32m1x3_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tu(vfloat32m1x4_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tu(vfloat32m1x5_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tu(vfloat32m1x6_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tu(vfloat32m1x7_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tu(vfloat32m1x8_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tu(vfloat32m2x2_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tu(vfloat32m2x3_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tu(vfloat32m2x4_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tu(vfloat32m4x2_t vd, const float *rs1,
                                       vuint32m4_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tu(vfloat32mf2x2_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tu(vfloat32mf2x3_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tu(vfloat32mf2x4_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tu(vfloat32mf2x5_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tu(vfloat32mf2x6_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tu(vfloat32mf2x7_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tu(vfloat32mf2x8_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tu(vfloat32m1x2_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tu(vfloat32m1x3_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tu(vfloat32m1x4_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tu(vfloat32m1x5_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tu(vfloat32m1x6_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tu(vfloat32m1x7_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tu(vfloat32m1x8_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tu(vfloat32m2x2_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tu(vfloat32m2x3_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tu(vfloat32m2x4_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tu(vfloat32m4x2_t vd, const float *rs1,
                                       vuint64m8_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tu(vfloat64m1x2_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tu(vfloat64m1x3_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tu(vfloat64m1x4_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tu(vfloat64m1x5_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tu(vfloat64m1x6_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tu(vfloat64m1x7_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tu(vfloat64m1x8_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tu(vfloat64m2x2_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tu(vfloat64m2x3_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tu(vfloat64m2x4_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tu(vfloat64m4x2_t vd, const double *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tu(vfloat64m1x2_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tu(vfloat64m1x3_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tu(vfloat64m1x4_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tu(vfloat64m1x5_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tu(vfloat64m1x6_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tu(vfloat64m1x7_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tu(vfloat64m1x8_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tu(vfloat64m2x2_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tu(vfloat64m2x3_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tu(vfloat64m2x4_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tu(vfloat64m4x2_t vd, const double *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tu(vfloat32mf2x2_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tu(vfloat32mf2x3_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tu(vfloat32mf2x4_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tu(vfloat32mf2x5_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tu(vfloat32mf2x6_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tu(vfloat32mf2x7_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tu(vfloat32mf2x8_t vd, const float *rs1,
                                        vuint32mf2_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tu(vfloat32m1x2_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tu(vfloat32m1x3_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tu(vfloat32m1x4_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tu(vfloat32m1x5_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tu(vfloat32m1x6_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tu(vfloat32m1x7_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tu(vfloat32m1x8_t vd, const float *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tu(vfloat32m2x2_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tu(vfloat32m2x3_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tu(vfloat32m2x4_t vd, const float *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tu(vfloat32m4x2_t vd, const float *rs1,
                                       vuint32m4_t rs2, size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tu(vfloat32mf2x2_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tu(vfloat32mf2x3_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tu(vfloat32mf2x4_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tu(vfloat32mf2x5_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tu(vfloat32mf2x6_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tu(vfloat32mf2x7_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tu(vfloat32mf2x8_t vd, const float *rs1,
                                        vuint64m1_t rs2, size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tu(vfloat32m1x2_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tu(vfloat32m1x3_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tu(vfloat32m1x4_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tu(vfloat32m1x5_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tu(vfloat32m1x6_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tu(vfloat32m1x7_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tu(vfloat32m1x8_t vd, const float *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tu(vfloat32m2x2_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tu(vfloat32m2x3_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tu(vfloat32m2x4_t vd, const float *rs1,
                                       vuint64m4_t rs2, size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tu(vfloat32m4x2_t vd, const float *rs1,
                                       vuint64m8_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tu(vfloat64m1x2_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tu(vfloat64m1x3_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tu(vfloat64m1x4_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tu(vfloat64m1x5_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tu(vfloat64m1x6_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tu(vfloat64m1x7_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tu(vfloat64m1x8_t vd, const double *rs1,
                                       vuint32mf2_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tu(vfloat64m2x2_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tu(vfloat64m2x3_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tu(vfloat64m2x4_t vd, const double *rs1,
                                       vuint32m1_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tu(vfloat64m4x2_t vd, const double *rs1,
                                       vuint32m2_t rs2, size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tu(vfloat64m1x2_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tu(vfloat64m1x3_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tu(vfloat64m1x4_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tu(vfloat64m1x5_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tu(vfloat64m1x6_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tu(vfloat64m1x7_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tu(vfloat64m1x8_t vd, const double *rs1,
                                       vuint64m1_t rs2, size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tu(vfloat64m2x2_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tu(vfloat64m2x3_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tu(vfloat64m2x4_t vd, const double *rs1,
                                       vuint64m2_t rs2, size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tu(vfloat64m4x2_t vd, const double *rs1,
                                       vuint64m4_t rs2, size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                        const float *rs1, vuint32m4_t rs2,
                                        size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                        const float *rs1, vuint64m8_t rs2,
                                        size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                        const double *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                        const double *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                         const float *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                        const float *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                        const float *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                        const float *rs1, vuint32m4_t rs2,
                                        size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vfloat32mf2x2_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vfloat32mf2x3_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vfloat32mf2x4_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vfloat32mf2x5_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vfloat32mf2x6_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vfloat32mf2x7_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vfloat32mf2x8_t vd,
                                         const float *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vfloat32m1x2_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vfloat32m1x3_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vfloat32m1x4_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tum(vbool32_t vm, vfloat32m1x5_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tum(vbool32_t vm, vfloat32m1x6_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tum(vbool32_t vm, vfloat32m1x7_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tum(vbool32_t vm, vfloat32m1x8_t vd,
                                        const float *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vfloat32m2x2_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tum(vbool16_t vm, vfloat32m2x3_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tum(vbool16_t vm, vfloat32m2x4_t vd,
                                        const float *rs1, vuint64m4_t rs2,
                                        size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tum(vbool8_t vm, vfloat32m4x2_t vd,
                                        const float *rs1, vuint64m8_t rs2,
                                        size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                        const double *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                        const double *rs1, vuint32m1_t rs2,
                                        size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                        const double *rs1, vuint32m2_t rs2,
                                        size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tum(vbool64_t vm, vfloat64m1x2_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tum(vbool64_t vm, vfloat64m1x3_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tum(vbool64_t vm, vfloat64m1x4_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tum(vbool64_t vm, vfloat64m1x5_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tum(vbool64_t vm, vfloat64m1x6_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tum(vbool64_t vm, vfloat64m1x7_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tum(vbool64_t vm, vfloat64m1x8_t vd,
                                        const double *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tum(vbool32_t vm, vfloat64m2x2_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tum(vbool32_t vm, vfloat64m2x3_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tum(vbool32_t vm, vfloat64m2x4_t vd,
                                        const double *rs1, vuint64m2_t rs2,
                                        size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tum(vbool16_t vm, vfloat64m4x2_t vd,
                                        const double *rs1, vuint64m4_t rs2,
                                        size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                         const float *rs1, vuint32m4_t rs2,
                                         size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                         const float *rs1, vuint64m8_t rs2,
                                         size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                         const double *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                         const double *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                          const float *rs1, vuint32mf2_t rs2,
                                          size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                         const float *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                         const float *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                         const float *rs1, vuint32m4_t rs2,
                                         size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vfloat32mf2x2_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vfloat32mf2x3_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vfloat32mf2x4_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vfloat32mf2x5_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vfloat32mf2x6_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vfloat32mf2x7_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vfloat32mf2x8_t vd,
                                          const float *rs1, vuint64m1_t rs2,
                                          size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vfloat32m1x2_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vfloat32m1x3_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vfloat32m1x4_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_tumu(vbool32_t vm, vfloat32m1x5_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_tumu(vbool32_t vm, vfloat32m1x6_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_tumu(vbool32_t vm, vfloat32m1x7_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_tumu(vbool32_t vm, vfloat32m1x8_t vd,
                                         const float *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vfloat32m2x2_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_tumu(vbool16_t vm, vfloat32m2x3_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_tumu(vbool16_t vm, vfloat32m2x4_t vd,
                                         const float *rs1, vuint64m4_t rs2,
                                         size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_tumu(vbool8_t vm, vfloat32m4x2_t vd,
                                         const float *rs1, vuint64m8_t rs2,
                                         size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                         const double *rs1, vuint32mf2_t rs2,
                                         size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                         const double *rs1, vuint32m1_t rs2,
                                         size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                         const double *rs1, vuint32m2_t rs2,
                                         size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_tumu(vbool64_t vm, vfloat64m1x2_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_tumu(vbool64_t vm, vfloat64m1x3_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_tumu(vbool64_t vm, vfloat64m1x4_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_tumu(vbool64_t vm, vfloat64m1x5_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_tumu(vbool64_t vm, vfloat64m1x6_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_tumu(vbool64_t vm, vfloat64m1x7_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_tumu(vbool64_t vm, vfloat64m1x8_t vd,
                                         const double *rs1, vuint64m1_t rs2,
                                         size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_tumu(vbool32_t vm, vfloat64m2x2_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_tumu(vbool32_t vm, vfloat64m2x3_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_tumu(vbool32_t vm, vfloat64m2x4_t vd,
                                         const double *rs1, vuint64m2_t rs2,
                                         size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_tumu(vbool16_t vm, vfloat64m4x2_t vd,
                                         const double *rs1, vuint64m4_t rs2,
                                         size_t vl);
// masked functions
vfloat32mf2x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei32_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei32_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei32_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei32_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei32_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei32_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei32_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, vuint32m4_t rs2,
                                       size_t vl);
vfloat32mf2x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32m1x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x5_t __riscv_vloxseg5ei64_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x6_t __riscv_vloxseg6ei64_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x7_t __riscv_vloxseg7ei64_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x8_t __riscv_vloxseg8ei64_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m2x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m2x3_t __riscv_vloxseg3ei64_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m2x4_t __riscv_vloxseg4ei64_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m4x2_t __riscv_vloxseg2ei64_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, vuint64m8_t rs2,
                                       size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei32_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei32_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei32_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei32_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei32_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei32_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei32_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei32_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei32_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei32_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei32_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat64m1x2_t __riscv_vloxseg2ei64_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x3_t __riscv_vloxseg3ei64_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x4_t __riscv_vloxseg4ei64_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x5_t __riscv_vloxseg5ei64_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x6_t __riscv_vloxseg6ei64_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x7_t __riscv_vloxseg7ei64_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x8_t __riscv_vloxseg8ei64_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m2x2_t __riscv_vloxseg2ei64_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m2x3_t __riscv_vloxseg3ei64_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m2x4_t __riscv_vloxseg4ei64_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m4x2_t __riscv_vloxseg2ei64_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, vuint32mf2_t rs2,
                                        size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei32_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei32_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei32_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei32_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei32_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei32_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei32_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, vuint32m4_t rs2,
                                       size_t vl);
vfloat32mf2x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vfloat32mf2x2_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vfloat32mf2x3_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vfloat32mf2x4_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vfloat32mf2x5_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vfloat32mf2x6_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vfloat32mf2x7_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32mf2x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vfloat32mf2x8_t vd,
                                        const float *rs1, vuint64m1_t rs2,
                                        size_t vl);
vfloat32m1x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vfloat32m1x2_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vfloat32m1x3_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vfloat32m1x4_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x5_t __riscv_vluxseg5ei64_mu(vbool32_t vm, vfloat32m1x5_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x6_t __riscv_vluxseg6ei64_mu(vbool32_t vm, vfloat32m1x6_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x7_t __riscv_vluxseg7ei64_mu(vbool32_t vm, vfloat32m1x7_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m1x8_t __riscv_vluxseg8ei64_mu(vbool32_t vm, vfloat32m1x8_t vd,
                                       const float *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat32m2x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vfloat32m2x2_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m2x3_t __riscv_vluxseg3ei64_mu(vbool16_t vm, vfloat32m2x3_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m2x4_t __riscv_vluxseg4ei64_mu(vbool16_t vm, vfloat32m2x4_t vd,
                                       const float *rs1, vuint64m4_t rs2,
                                       size_t vl);
vfloat32m4x2_t __riscv_vluxseg2ei64_mu(vbool8_t vm, vfloat32m4x2_t vd,
                                       const float *rs1, vuint64m8_t rs2,
                                       size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei32_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei32_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei32_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei32_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei32_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei32_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei32_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, vuint32mf2_t rs2,
                                       size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei32_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei32_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei32_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, vuint32m1_t rs2,
                                       size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei32_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, vuint32m2_t rs2,
                                       size_t vl);
vfloat64m1x2_t __riscv_vluxseg2ei64_mu(vbool64_t vm, vfloat64m1x2_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x3_t __riscv_vluxseg3ei64_mu(vbool64_t vm, vfloat64m1x3_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x4_t __riscv_vluxseg4ei64_mu(vbool64_t vm, vfloat64m1x4_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x5_t __riscv_vluxseg5ei64_mu(vbool64_t vm, vfloat64m1x5_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x6_t __riscv_vluxseg6ei64_mu(vbool64_t vm, vfloat64m1x6_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x7_t __riscv_vluxseg7ei64_mu(vbool64_t vm, vfloat64m1x7_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m1x8_t __riscv_vluxseg8ei64_mu(vbool64_t vm, vfloat64m1x8_t vd,
                                       const double *rs1, vuint64m1_t rs2,
                                       size_t vl);
vfloat64m2x2_t __riscv_vluxseg2ei64_mu(vbool32_t vm, vfloat64m2x2_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m2x3_t __riscv_vluxseg3ei64_mu(vbool32_t vm, vfloat64m2x3_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m2x4_t __riscv_vluxseg4ei64_mu(vbool32_t vm, vfloat64m2x4_t vd,
                                       const double *rs1, vuint64m2_t rs2,
                                       size_t vl);
vfloat64m4x2_t __riscv_vluxseg2ei64_mu(vbool16_t vm, vfloat64m4x2_t vd,
                                       const double *rs1, vuint64m4_t rs2,
                                       size_t vl);
----

[[policy-variant-overloadedvector-indexed-segment-store]]
==== Vector Indexed Segment Store Intrinsics
Intrinsics here don't have a policy variant.

[[policy-variant-overloadedfloat-vector-indexed-segment-store]]
==== Float Vector Indexed Segment Store Intrinsics
Intrinsics here don't have a policy variant.
