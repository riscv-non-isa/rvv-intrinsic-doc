
=== Vector Fixed-Point Arithmetic Instructions

[[policy-variant-overloadedvector-single-width-saturating-add-and-subtract]]
==== Vector Single-Width Saturating Add and Subtract Intrinsics

[,c]
----
vint8mf8_t __riscv_vsadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
// masked functions
vint8mf8_t __riscv_vsadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vsadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vsadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vsadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vsadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vsadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vsadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vsadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vsadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vsadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vsadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vsadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vsadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vsadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vsadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vsadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vsadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vsadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vsadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vsadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vsadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vsadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vsadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vsadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vsadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vsadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vsadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vsadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vsadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vsadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vsadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vsadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vsadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vsadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vsadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vsadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vsadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vsadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vint8mf8_t __riscv_vssub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, size_t vl);
vint8mf8_t __riscv_vssub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, size_t vl);
vint8mf4_t __riscv_vssub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, size_t vl);
vint8mf4_t __riscv_vssub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, size_t vl);
vint8mf2_t __riscv_vssub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, size_t vl);
vint8mf2_t __riscv_vssub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, size_t vl);
vint8m1_t __riscv_vssub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, size_t vl);
vint8m1_t __riscv_vssub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, size_t vl);
vint8m2_t __riscv_vssub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, size_t vl);
vint8m2_t __riscv_vssub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, size_t vl);
vint8m4_t __riscv_vssub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, size_t vl);
vint8m4_t __riscv_vssub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, size_t vl);
vint8m8_t __riscv_vssub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, size_t vl);
vint8m8_t __riscv_vssub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, size_t vl);
vint16mf4_t __riscv_vssub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, size_t vl);
vint16mf4_t __riscv_vssub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, size_t vl);
vint16mf2_t __riscv_vssub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, size_t vl);
vint16mf2_t __riscv_vssub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, size_t vl);
vint16m1_t __riscv_vssub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, size_t vl);
vint16m1_t __riscv_vssub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, size_t vl);
vint16m2_t __riscv_vssub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, size_t vl);
vint16m2_t __riscv_vssub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, size_t vl);
vint16m4_t __riscv_vssub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, size_t vl);
vint16m4_t __riscv_vssub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, size_t vl);
vint16m8_t __riscv_vssub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, size_t vl);
vint16m8_t __riscv_vssub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, size_t vl);
vint32mf2_t __riscv_vssub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, size_t vl);
vint32mf2_t __riscv_vssub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, size_t vl);
vint32m1_t __riscv_vssub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, size_t vl);
vint32m1_t __riscv_vssub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, size_t vl);
vint32m2_t __riscv_vssub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, size_t vl);
vint32m2_t __riscv_vssub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, size_t vl);
vint32m4_t __riscv_vssub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, size_t vl);
vint32m4_t __riscv_vssub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, size_t vl);
vint32m8_t __riscv_vssub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, size_t vl);
vint32m8_t __riscv_vssub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, size_t vl);
vint64m1_t __riscv_vssub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, size_t vl);
vint64m1_t __riscv_vssub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, size_t vl);
vint64m2_t __riscv_vssub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, size_t vl);
vint64m2_t __riscv_vssub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, size_t vl);
vint64m4_t __riscv_vssub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, size_t vl);
vint64m4_t __riscv_vssub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, size_t vl);
vint64m8_t __riscv_vssub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, size_t vl);
vint64m8_t __riscv_vssub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vsaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vsaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vsaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vsaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vsaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vsaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vsaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vsaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vsaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vsaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vsaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vsaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vsaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vsaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vsaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vsaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vsaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vsaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vsaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vsaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vsaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vsaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, size_t vl);
vuint8mf8_t __riscv_vssubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, size_t vl);
vuint8mf4_t __riscv_vssubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, size_t vl);
vuint8mf2_t __riscv_vssubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, size_t vl);
vuint8m1_t __riscv_vssubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, size_t vl);
vuint8m2_t __riscv_vssubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, size_t vl);
vuint8m4_t __riscv_vssubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, size_t vl);
vuint8m8_t __riscv_vssubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, size_t vl);
vuint16mf4_t __riscv_vssubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, size_t vl);
vuint16mf2_t __riscv_vssubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, size_t vl);
vuint16m1_t __riscv_vssubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, size_t vl);
vuint16m2_t __riscv_vssubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, size_t vl);
vuint16m4_t __riscv_vssubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, size_t vl);
vuint16m8_t __riscv_vssubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, size_t vl);
vuint32mf2_t __riscv_vssubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, size_t vl);
vuint32m1_t __riscv_vssubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, size_t vl);
vuint32m2_t __riscv_vssubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, size_t vl);
vuint32m4_t __riscv_vssubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, size_t vl);
vuint32m8_t __riscv_vssubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, size_t vl);
vuint64m1_t __riscv_vssubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, size_t vl);
vuint64m2_t __riscv_vssubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, size_t vl);
vuint64m4_t __riscv_vssubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, size_t vl);
vuint64m8_t __riscv_vssubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, size_t vl);
----

[[policy-variant-overloadedvector-single-width-averaging-add-and-subtract]]
==== Vector Single-Width Averaging Add and Subtract Intrinsics

[,c]
----
vint8mf8_t __riscv_vaadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tu (vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tu (vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tu (vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tu (vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tu (vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tu (vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tu (vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tu (vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tu (vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tu (vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tu (vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tu (vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tu (vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tu (vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tu (vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tu (vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vaadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vaadd_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vaadd_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vaadd_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vaadd_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vaadd_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vaadd_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vaadd_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vaadd_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vaadd_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vaadd_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vaadd_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vaadd_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vaadd_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vaadd_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vaadd_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vaadd_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vaadd_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vaadd_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vaadd_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vaadd_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vaadd_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vaadd_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vasub_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vasub_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vasub_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vasub_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vasub_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vasub_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vasub_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vasub_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vasub_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vasub_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vasub_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vasub_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vasub_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vasub_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vasub_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vasub_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vasub_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vasub_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vasub_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vasub_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vasub_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vasub_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vaaddu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vaaddu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vaaddu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vaaddu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vaaddu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vaaddu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vaaddu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vaaddu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vaaddu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vaaddu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vaaddu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vaaddu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vaaddu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vaaddu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vaaddu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vaaddu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vaaddu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vaaddu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vaaddu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vaaddu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vaaddu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vaaddu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t op2, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vasubu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t op2, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vasubu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t op2, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vasubu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vasubu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vasubu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vasubu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vasubu_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t op2, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vasubu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t op2, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vasubu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vasubu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vasubu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vasubu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vasubu_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t op2, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vasubu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vasubu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vasubu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vasubu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vasubu_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vasubu_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vasubu_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vasubu_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vasubu_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2, unsigned int vxrm, size_t vl);
----

[[policy-variant-overloadedvector-single-width-fractional-multiply-with-rounding-and-saturation]]
==== Vector Single-Width Fractional Multiply with Rounding and SaturationIntrinsics

[,c]
----
vint8mf8_t __riscv_vsmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tu (vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tu (vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tu (vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tu (vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tu (vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tu (vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tu (vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tu (vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tu (vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tu (vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tu (vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tu (vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tu (vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tu (vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tu (vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tu (vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tu (vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tu (vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tu (vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tu (vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tu (vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tu (vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tu (vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tu (vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tu (vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tu (vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tu (vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tu (vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tu (vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tu (vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tu (vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tu (vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tu (vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tu (vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tu (vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tu (vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tu (vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tu (vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vsmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vint8mf8_t op2, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vsmul_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vint8mf4_t op2, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vsmul_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vint8mf2_t op2, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vsmul_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vsmul_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vsmul_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vsmul_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vsmul_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vint16mf4_t op2, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vsmul_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vint16mf2_t op2, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vsmul_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vsmul_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vsmul_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vsmul_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vsmul_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vint32mf2_t op2, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vsmul_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vsmul_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vsmul_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vsmul_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vsmul_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vsmul_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vsmul_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vsmul_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vsmul_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2, unsigned int vxrm, size_t vl);
----

[[policy-variant-overloadedvector-single-width-scaling-shift]]
==== Vector Single-Width Scaling Shift Intrinsics

[,c]
----
vint8mf8_t __riscv_vssra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tu (vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tu (vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tu (vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tu (vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tu (vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tu (vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tu (vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tu (vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tu (vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tu (vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tu (vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tu (vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tu (vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tu (vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tu (vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tu (vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tu (vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tu (vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tu (vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tu (vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tu (vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tu (vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tu (vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tu (vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tu (vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tu (vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tu (vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tu (vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tu (vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tu (vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tu (vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tu (vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tu (vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tu (vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tu (vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tu (vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tu (vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tu (vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tu (vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tu (vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tu (vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tu (vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tu (vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tu (vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tu (vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tu (vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tu (vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tu (vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tu (vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tu (vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tu (vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tu (vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tu (vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tu (vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tu (vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tu (vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tu (vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tu (vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tu (vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tu (vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tum (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tum (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tum (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tum (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tum (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tum (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tum (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tum (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tum (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tum (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tum (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tum (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tum (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tum (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tum (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tum (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tum (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tum (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tum (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tum (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tum (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tum (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tum (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tum (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tum (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tum (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tum (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tum (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tum (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_tumu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_tumu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_tumu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_tumu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_tumu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_tumu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_tumu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_tumu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_tumu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_tumu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_tumu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_tumu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_tumu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_tumu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_tumu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_tumu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_tumu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_tumu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_tumu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_tumu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_tumu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_tumu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_tumu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vssra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vssra_mu (vbool64_t mask, vint8mf8_t maskedoff, vint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vssra_mu (vbool32_t mask, vint8mf4_t maskedoff, vint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vssra_mu (vbool16_t mask, vint8mf2_t maskedoff, vint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vssra_mu (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vssra_mu (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vssra_mu (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vint8m8_t __riscv_vssra_mu (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vssra_mu (vbool64_t mask, vint16mf4_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vssra_mu (vbool32_t mask, vint16mf2_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vssra_mu (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vssra_mu (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vssra_mu (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vint16m8_t __riscv_vssra_mu (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vssra_mu (vbool64_t mask, vint32mf2_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vssra_mu (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vssra_mu (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vssra_mu (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vint32m8_t __riscv_vssra_mu (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vint64m1_t __riscv_vssra_mu (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vint64m2_t __riscv_vssra_mu (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vint64m4_t __riscv_vssra_mu (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vint64m8_t __riscv_vssra_mu (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vssrl_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint8mf8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vssrl_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint8mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vssrl_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint8mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vssrl_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vssrl_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vssrl_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t shift, unsigned int vxrm, size_t vl);
vuint8m8_t __riscv_vssrl_mu (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vssrl_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vssrl_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vssrl_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vssrl_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vssrl_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t shift, unsigned int vxrm, size_t vl);
vuint16m8_t __riscv_vssrl_mu (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vssrl_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vssrl_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vssrl_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vssrl_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t shift, unsigned int vxrm, size_t vl);
vuint32m8_t __riscv_vssrl_mu (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t shift, unsigned int vxrm, size_t vl);
vuint64m1_t __riscv_vssrl_mu (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t shift, unsigned int vxrm, size_t vl);
vuint64m2_t __riscv_vssrl_mu (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t shift, unsigned int vxrm, size_t vl);
vuint64m4_t __riscv_vssrl_mu (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t shift, unsigned int vxrm, size_t vl);
vuint64m8_t __riscv_vssrl_mu (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
----

[[policy-variant-overloadedvector-narrowing-fixed-point-clip]]
==== Vector Narrowing Fixed-Point Clip Intrinsics

[,c]
----
vint8mf8_t __riscv_vnclip_tu (vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tu (vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tu (vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tu (vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tu (vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tu (vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tu (vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tu (vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tu (vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tu (vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tu (vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tu (vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tu (vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tu (vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tu (vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tu (vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tu (vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tu (vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tu (vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tu (vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tu (vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tu (vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tu (vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tu (vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tu (vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tu (vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tu (vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tu (vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tu (vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tu (vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tu (vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tu (vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tu (vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tu (vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tu (vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tu (vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tu (vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tu (vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tu (vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tu (vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tu (vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tu (vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tu (vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tu (vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tu (vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tu (vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tu (vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tu (vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tu (vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tu (vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tu (vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tu (vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tu (vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tu (vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tum (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tum (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tum (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tum (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tum (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tum (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tum (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tum (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tum (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tum (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tum (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tum (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tum (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tum (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tum (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tum (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tum (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tum (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tum (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tum (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tum (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tum (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tum (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tum (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tum (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tum (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tum (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tum (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tum (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tum (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_tumu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_tumu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_tumu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_tumu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_tumu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_tumu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_tumu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_tumu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_tumu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_tumu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_tumu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_tumu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_tumu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_tumu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_tumu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_tumu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_tumu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_tumu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_tumu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_tumu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_tumu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_tumu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_tumu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_tumu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_tumu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_tumu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_tumu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_tumu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_tumu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
// masked functions
vint8mf8_t __riscv_vnclip_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vint8mf8_t __riscv_vnclip_mu (vbool64_t mask, vint8mf8_t maskedoff, vint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vint8mf4_t __riscv_vnclip_mu (vbool32_t mask, vint8mf4_t maskedoff, vint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vint8mf2_t __riscv_vnclip_mu (vbool16_t mask, vint8mf2_t maskedoff, vint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vint8m1_t __riscv_vnclip_mu (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vint8m2_t __riscv_vnclip_mu (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vint8m4_t __riscv_vnclip_mu (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vint16mf4_t __riscv_vnclip_mu (vbool64_t mask, vint16mf4_t maskedoff, vint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vint16mf2_t __riscv_vnclip_mu (vbool32_t mask, vint16mf2_t maskedoff, vint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vint16m1_t __riscv_vnclip_mu (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vint16m2_t __riscv_vnclip_mu (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vint16m4_t __riscv_vnclip_mu (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vint32mf2_t __riscv_vnclip_mu (vbool64_t mask, vint32mf2_t maskedoff, vint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vint32m1_t __riscv_vnclip_mu (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vint32m2_t __riscv_vnclip_mu (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vint32m4_t __riscv_vnclip_mu (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, vuint8mf8_t shift, unsigned int vxrm, size_t vl);
vuint8mf8_t __riscv_vnclipu_mu (vbool64_t mask, vuint8mf8_t maskedoff, vuint16mf4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, vuint8mf4_t shift, unsigned int vxrm, size_t vl);
vuint8mf4_t __riscv_vnclipu_mu (vbool32_t mask, vuint8mf4_t maskedoff, vuint16mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, vuint8mf2_t shift, unsigned int vxrm, size_t vl);
vuint8mf2_t __riscv_vnclipu_mu (vbool16_t mask, vuint8mf2_t maskedoff, vuint16m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t shift, unsigned int vxrm, size_t vl);
vuint8m1_t __riscv_vnclipu_mu (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t shift, unsigned int vxrm, size_t vl);
vuint8m2_t __riscv_vnclipu_mu (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t shift, unsigned int vxrm, size_t vl);
vuint8m4_t __riscv_vnclipu_mu (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, vuint16mf4_t shift, unsigned int vxrm, size_t vl);
vuint16mf4_t __riscv_vnclipu_mu (vbool64_t mask, vuint16mf4_t maskedoff, vuint32mf2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, vuint16mf2_t shift, unsigned int vxrm, size_t vl);
vuint16mf2_t __riscv_vnclipu_mu (vbool32_t mask, vuint16mf2_t maskedoff, vuint32m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t shift, unsigned int vxrm, size_t vl);
vuint16m1_t __riscv_vnclipu_mu (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t shift, unsigned int vxrm, size_t vl);
vuint16m2_t __riscv_vnclipu_mu (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t shift, unsigned int vxrm, size_t vl);
vuint16m4_t __riscv_vnclipu_mu (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, vuint32mf2_t shift, unsigned int vxrm, size_t vl);
vuint32mf2_t __riscv_vnclipu_mu (vbool64_t mask, vuint32mf2_t maskedoff, vuint64m1_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t shift, unsigned int vxrm, size_t vl);
vuint32m1_t __riscv_vnclipu_mu (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t shift, unsigned int vxrm, size_t vl);
vuint32m2_t __riscv_vnclipu_mu (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, size_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t shift, unsigned int vxrm, size_t vl);
vuint32m4_t __riscv_vnclipu_mu (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, size_t shift, unsigned int vxrm, size_t vl);
----
