<!--NOTE: This file is generated by rvv_intrinsic_gen.py-->

### RVV C extension types:

**Prototypes:**
``` C
vint8m1_t
vint8m2_t
vint8m4_t
vint8m8_t
vint16m1_t
vint16m2_t
vint16m4_t
vint16m8_t
vint32m1_t
vint32m2_t
vint32m4_t
vint32m8_t
vint64m1_t
vint64m2_t
vint64m4_t
vint64m8_t
vuint8m1_t
vuint8m2_t
vuint8m4_t
vuint8m8_t
vuint16m1_t
vuint16m2_t
vuint16m4_t
vuint16m8_t
vuint32m1_t
vuint32m2_t
vuint32m4_t
vuint32m8_t
vuint64m1_t
vuint64m2_t
vuint64m4_t
vuint64m8_t
vfloat16m1_t
vfloat16m2_t
vfloat16m4_t
vfloat16m8_t
vfloat32m1_t
vfloat32m2_t
vfloat32m4_t
vfloat32m8_t
vfloat64m1_t
vfloat64m2_t
vfloat64m4_t
vfloat64m8_t
```
### RVV C extension mask types:
- The Syntax is `vbool<MLEN>_t`
 - `vbool1_t`
 - `vbool2_t`
 - `vbool4_t`
 - `vbool8_t`
 - `vbool16_t`
 - `vbool32_t`
 - `vbool64_t`

# RVV intrinsic Functions:

## Configuration-Setting Functions:

### Set `vl` and `vtype` Functions:

**Prototypes:**
``` C
size_t vsetvl_8m1 (size_t avl);
size_t vsetvl_8m2 (size_t avl);
size_t vsetvl_8m4 (size_t avl);
size_t vsetvl_8m8 (size_t avl);
size_t vsetvl_16m1 (size_t avl);
size_t vsetvl_16m2 (size_t avl);
size_t vsetvl_16m4 (size_t avl);
size_t vsetvl_16m8 (size_t avl);
size_t vsetvl_32m1 (size_t avl);
size_t vsetvl_32m2 (size_t avl);
size_t vsetvl_32m4 (size_t avl);
size_t vsetvl_32m8 (size_t avl);
size_t vsetvl_64m1 (size_t avl);
size_t vsetvl_64m2 (size_t avl);
size_t vsetvl_64m4 (size_t avl);
size_t vsetvl_64m8 (size_t avl);
```
### Set the vl to VLMAX with specific vtype:

**Prototypes:**
``` C
size_t vsetvlmax_8m1 ();
size_t vsetvlmax_8m2 ();
size_t vsetvlmax_8m4 ();
size_t vsetvlmax_8m8 ();
size_t vsetvlmax_16m1 ();
size_t vsetvlmax_16m2 ();
size_t vsetvlmax_16m4 ();
size_t vsetvlmax_16m8 ();
size_t vsetvlmax_32m1 ();
size_t vsetvlmax_32m2 ();
size_t vsetvlmax_32m4 ();
size_t vsetvlmax_32m8 ();
size_t vsetvlmax_64m1 ();
size_t vsetvlmax_64m2 ();
size_t vsetvlmax_64m4 ();
size_t vsetvlmax_64m8 ();
```
### Read the vl:

**Prototypes:**
``` C
size_t vreadvl ();
```
## Vector Loads and Stores Functions:

### Vector Unit-Stride Load Functions:

**Prototypes:**
``` C
vint8m1_t vloadb_i8m1 (const int8_t *base);
vint8m2_t vloadb_i8m2 (const int8_t *base);
vint8m4_t vloadb_i8m4 (const int8_t *base);
vint8m8_t vloadb_i8m8 (const int8_t *base);
vint16m1_t vloadb_i16m1 (const int8_t *base);
vint16m2_t vloadb_i16m2 (const int8_t *base);
vint16m4_t vloadb_i16m4 (const int8_t *base);
vint16m8_t vloadb_i16m8 (const int8_t *base);
vint32m1_t vloadb_i32m1 (const int8_t *base);
vint32m2_t vloadb_i32m2 (const int8_t *base);
vint32m4_t vloadb_i32m4 (const int8_t *base);
vint32m8_t vloadb_i32m8 (const int8_t *base);
vint64m1_t vloadb_i64m1 (const int8_t *base);
vint64m2_t vloadb_i64m2 (const int8_t *base);
vint64m4_t vloadb_i64m4 (const int8_t *base);
vint64m8_t vloadb_i64m8 (const int8_t *base);
vuint8m1_t vloadb_u8m1 (const uint8_t *base);
vuint8m2_t vloadb_u8m2 (const uint8_t *base);
vuint8m4_t vloadb_u8m4 (const uint8_t *base);
vuint8m8_t vloadb_u8m8 (const uint8_t *base);
vuint16m1_t vloadb_u16m1 (const uint8_t *base);
vuint16m2_t vloadb_u16m2 (const uint8_t *base);
vuint16m4_t vloadb_u16m4 (const uint8_t *base);
vuint16m8_t vloadb_u16m8 (const uint8_t *base);
vuint32m1_t vloadb_u32m1 (const uint8_t *base);
vuint32m2_t vloadb_u32m2 (const uint8_t *base);
vuint32m4_t vloadb_u32m4 (const uint8_t *base);
vuint32m8_t vloadb_u32m8 (const uint8_t *base);
vuint64m1_t vloadb_u64m1 (const uint8_t *base);
vuint64m2_t vloadb_u64m2 (const uint8_t *base);
vuint64m4_t vloadb_u64m4 (const uint8_t *base);
vuint64m8_t vloadb_u64m8 (const uint8_t *base);
vint16m1_t vloadh_i16m1 (const int16_t *base);
vint16m2_t vloadh_i16m2 (const int16_t *base);
vint16m4_t vloadh_i16m4 (const int16_t *base);
vint16m8_t vloadh_i16m8 (const int16_t *base);
vint32m1_t vloadh_i32m1 (const int16_t *base);
vint32m2_t vloadh_i32m2 (const int16_t *base);
vint32m4_t vloadh_i32m4 (const int16_t *base);
vint32m8_t vloadh_i32m8 (const int16_t *base);
vint64m1_t vloadh_i64m1 (const int16_t *base);
vint64m2_t vloadh_i64m2 (const int16_t *base);
vint64m4_t vloadh_i64m4 (const int16_t *base);
vint64m8_t vloadh_i64m8 (const int16_t *base);
vuint16m1_t vloadh_u16m1 (const uint16_t *base);
vuint16m2_t vloadh_u16m2 (const uint16_t *base);
vuint16m4_t vloadh_u16m4 (const uint16_t *base);
vuint16m8_t vloadh_u16m8 (const uint16_t *base);
vuint32m1_t vloadh_u32m1 (const uint16_t *base);
vuint32m2_t vloadh_u32m2 (const uint16_t *base);
vuint32m4_t vloadh_u32m4 (const uint16_t *base);
vuint32m8_t vloadh_u32m8 (const uint16_t *base);
vuint64m1_t vloadh_u64m1 (const uint16_t *base);
vuint64m2_t vloadh_u64m2 (const uint16_t *base);
vuint64m4_t vloadh_u64m4 (const uint16_t *base);
vuint64m8_t vloadh_u64m8 (const uint16_t *base);
vint32m1_t vloadw_i32m1 (const int32_t *base);
vint32m2_t vloadw_i32m2 (const int32_t *base);
vint32m4_t vloadw_i32m4 (const int32_t *base);
vint32m8_t vloadw_i32m8 (const int32_t *base);
vint64m1_t vloadw_i64m1 (const int32_t *base);
vint64m2_t vloadw_i64m2 (const int32_t *base);
vint64m4_t vloadw_i64m4 (const int32_t *base);
vint64m8_t vloadw_i64m8 (const int32_t *base);
vuint32m1_t vloadw_u32m1 (const uint32_t *base);
vuint32m2_t vloadw_u32m2 (const uint32_t *base);
vuint32m4_t vloadw_u32m4 (const uint32_t *base);
vuint32m8_t vloadw_u32m8 (const uint32_t *base);
vuint64m1_t vloadw_u64m1 (const uint32_t *base);
vuint64m2_t vloadw_u64m2 (const uint32_t *base);
vuint64m4_t vloadw_u64m4 (const uint32_t *base);
vuint64m8_t vloadw_u64m8 (const uint32_t *base);
vint8m1_t vload_i8m1 (const int8_t *base);
vint8m2_t vload_i8m2 (const int8_t *base);
vint8m4_t vload_i8m4 (const int8_t *base);
vint8m8_t vload_i8m8 (const int8_t *base);
vint16m1_t vload_i16m1 (const int16_t *base);
vint16m2_t vload_i16m2 (const int16_t *base);
vint16m4_t vload_i16m4 (const int16_t *base);
vint16m8_t vload_i16m8 (const int16_t *base);
vint32m1_t vload_i32m1 (const int32_t *base);
vint32m2_t vload_i32m2 (const int32_t *base);
vint32m4_t vload_i32m4 (const int32_t *base);
vint32m8_t vload_i32m8 (const int32_t *base);
vint64m1_t vload_i64m1 (const int64_t *base);
vint64m2_t vload_i64m2 (const int64_t *base);
vint64m4_t vload_i64m4 (const int64_t *base);
vint64m8_t vload_i64m8 (const int64_t *base);
vuint8m1_t vload_u8m1 (const uint8_t *base);
vuint8m2_t vload_u8m2 (const uint8_t *base);
vuint8m4_t vload_u8m4 (const uint8_t *base);
vuint8m8_t vload_u8m8 (const uint8_t *base);
vuint16m1_t vload_u16m1 (const uint16_t *base);
vuint16m2_t vload_u16m2 (const uint16_t *base);
vuint16m4_t vload_u16m4 (const uint16_t *base);
vuint16m8_t vload_u16m8 (const uint16_t *base);
vuint32m1_t vload_u32m1 (const uint32_t *base);
vuint32m2_t vload_u32m2 (const uint32_t *base);
vuint32m4_t vload_u32m4 (const uint32_t *base);
vuint32m8_t vload_u32m8 (const uint32_t *base);
vuint64m1_t vload_u64m1 (const uint64_t *base);
vuint64m2_t vload_u64m2 (const uint64_t *base);
vuint64m4_t vload_u64m4 (const uint64_t *base);
vuint64m8_t vload_u64m8 (const uint64_t *base);
vfloat16m1_t vload_f16m1 (const float16_t *base);
vfloat16m2_t vload_f16m2 (const float16_t *base);
vfloat16m4_t vload_f16m4 (const float16_t *base);
vfloat16m8_t vload_f16m8 (const float16_t *base);
vfloat32m1_t vload_f32m1 (const float32_t *base);
vfloat32m2_t vload_f32m2 (const float32_t *base);
vfloat32m4_t vload_f32m4 (const float32_t *base);
vfloat32m8_t vload_f32m8 (const float32_t *base);
vfloat64m1_t vload_f64m1 (const float64_t *base);
vfloat64m2_t vload_f64m2 (const float64_t *base);
vfloat64m4_t vload_f64m4 (const float64_t *base);
vfloat64m8_t vload_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vload_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vload_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vload_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vload_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vload_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vload_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vload_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vload_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vload_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vload_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vload_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vload_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vload_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vload_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vload_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vload_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vload_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vload_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vload_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vload_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vload_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vload_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vload_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vload_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vload_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vload_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vload_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vload_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vload_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vload_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vload_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vload_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vload_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vload_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vload_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vload_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vload_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vload_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vload_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vload_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vload_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vload_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vload_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vload_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
### Vector Unit-Stride Store Functions:

**Prototypes:**
``` C
void vstoreb_i8m1 (int8_t *base, vint8m1_t value);
void vstoreb_i8m2 (int8_t *base, vint8m2_t value);
void vstoreb_i8m4 (int8_t *base, vint8m4_t value);
void vstoreb_i8m8 (int8_t *base, vint8m8_t value);
void vstoreb_i16m1 (int8_t *base, vint16m1_t value);
void vstoreb_i16m2 (int8_t *base, vint16m2_t value);
void vstoreb_i16m4 (int8_t *base, vint16m4_t value);
void vstoreb_i16m8 (int8_t *base, vint16m8_t value);
void vstoreb_i32m1 (int8_t *base, vint32m1_t value);
void vstoreb_i32m2 (int8_t *base, vint32m2_t value);
void vstoreb_i32m4 (int8_t *base, vint32m4_t value);
void vstoreb_i32m8 (int8_t *base, vint32m8_t value);
void vstoreb_i64m1 (int8_t *base, vint64m1_t value);
void vstoreb_i64m2 (int8_t *base, vint64m2_t value);
void vstoreb_i64m4 (int8_t *base, vint64m4_t value);
void vstoreb_i64m8 (int8_t *base, vint64m8_t value);
void vstoreb_u8m1 (uint8_t *base, vuint8m1_t value);
void vstoreb_u8m2 (uint8_t *base, vuint8m2_t value);
void vstoreb_u8m4 (uint8_t *base, vuint8m4_t value);
void vstoreb_u8m8 (uint8_t *base, vuint8m8_t value);
void vstoreb_u16m1 (uint8_t *base, vuint16m1_t value);
void vstoreb_u16m2 (uint8_t *base, vuint16m2_t value);
void vstoreb_u16m4 (uint8_t *base, vuint16m4_t value);
void vstoreb_u16m8 (uint8_t *base, vuint16m8_t value);
void vstoreb_u32m1 (uint8_t *base, vuint32m1_t value);
void vstoreb_u32m2 (uint8_t *base, vuint32m2_t value);
void vstoreb_u32m4 (uint8_t *base, vuint32m4_t value);
void vstoreb_u32m8 (uint8_t *base, vuint32m8_t value);
void vstoreb_u64m1 (uint8_t *base, vuint64m1_t value);
void vstoreb_u64m2 (uint8_t *base, vuint64m2_t value);
void vstoreb_u64m4 (uint8_t *base, vuint64m4_t value);
void vstoreb_u64m8 (uint8_t *base, vuint64m8_t value);
void vstoreh_i16m1 (int16_t *base, vint16m1_t value);
void vstoreh_i16m2 (int16_t *base, vint16m2_t value);
void vstoreh_i16m4 (int16_t *base, vint16m4_t value);
void vstoreh_i16m8 (int16_t *base, vint16m8_t value);
void vstoreh_i32m1 (int16_t *base, vint32m1_t value);
void vstoreh_i32m2 (int16_t *base, vint32m2_t value);
void vstoreh_i32m4 (int16_t *base, vint32m4_t value);
void vstoreh_i32m8 (int16_t *base, vint32m8_t value);
void vstoreh_i64m1 (int16_t *base, vint64m1_t value);
void vstoreh_i64m2 (int16_t *base, vint64m2_t value);
void vstoreh_i64m4 (int16_t *base, vint64m4_t value);
void vstoreh_i64m8 (int16_t *base, vint64m8_t value);
void vstoreh_u16m1 (uint16_t *base, vuint16m1_t value);
void vstoreh_u16m2 (uint16_t *base, vuint16m2_t value);
void vstoreh_u16m4 (uint16_t *base, vuint16m4_t value);
void vstoreh_u16m8 (uint16_t *base, vuint16m8_t value);
void vstoreh_u32m1 (uint16_t *base, vuint32m1_t value);
void vstoreh_u32m2 (uint16_t *base, vuint32m2_t value);
void vstoreh_u32m4 (uint16_t *base, vuint32m4_t value);
void vstoreh_u32m8 (uint16_t *base, vuint32m8_t value);
void vstoreh_u64m1 (uint16_t *base, vuint64m1_t value);
void vstoreh_u64m2 (uint16_t *base, vuint64m2_t value);
void vstoreh_u64m4 (uint16_t *base, vuint64m4_t value);
void vstoreh_u64m8 (uint16_t *base, vuint64m8_t value);
void vstorew_i32m1 (int32_t *base, vint32m1_t value);
void vstorew_i32m2 (int32_t *base, vint32m2_t value);
void vstorew_i32m4 (int32_t *base, vint32m4_t value);
void vstorew_i32m8 (int32_t *base, vint32m8_t value);
void vstorew_i64m1 (int32_t *base, vint64m1_t value);
void vstorew_i64m2 (int32_t *base, vint64m2_t value);
void vstorew_i64m4 (int32_t *base, vint64m4_t value);
void vstorew_i64m8 (int32_t *base, vint64m8_t value);
void vstorew_u32m1 (uint32_t *base, vuint32m1_t value);
void vstorew_u32m2 (uint32_t *base, vuint32m2_t value);
void vstorew_u32m4 (uint32_t *base, vuint32m4_t value);
void vstorew_u32m8 (uint32_t *base, vuint32m8_t value);
void vstorew_u64m1 (uint32_t *base, vuint64m1_t value);
void vstorew_u64m2 (uint32_t *base, vuint64m2_t value);
void vstorew_u64m4 (uint32_t *base, vuint64m4_t value);
void vstorew_u64m8 (uint32_t *base, vuint64m8_t value);
void vstore_i8m1 (int8_t *base, vint8m1_t value);
void vstore_i8m2 (int8_t *base, vint8m2_t value);
void vstore_i8m4 (int8_t *base, vint8m4_t value);
void vstore_i8m8 (int8_t *base, vint8m8_t value);
void vstore_i16m1 (int16_t *base, vint16m1_t value);
void vstore_i16m2 (int16_t *base, vint16m2_t value);
void vstore_i16m4 (int16_t *base, vint16m4_t value);
void vstore_i16m8 (int16_t *base, vint16m8_t value);
void vstore_i32m1 (int32_t *base, vint32m1_t value);
void vstore_i32m2 (int32_t *base, vint32m2_t value);
void vstore_i32m4 (int32_t *base, vint32m4_t value);
void vstore_i32m8 (int32_t *base, vint32m8_t value);
void vstore_i64m1 (int64_t *base, vint64m1_t value);
void vstore_i64m2 (int64_t *base, vint64m2_t value);
void vstore_i64m4 (int64_t *base, vint64m4_t value);
void vstore_i64m8 (int64_t *base, vint64m8_t value);
void vstore_u8m1 (uint8_t *base, vuint8m1_t value);
void vstore_u8m2 (uint8_t *base, vuint8m2_t value);
void vstore_u8m4 (uint8_t *base, vuint8m4_t value);
void vstore_u8m8 (uint8_t *base, vuint8m8_t value);
void vstore_u16m1 (uint16_t *base, vuint16m1_t value);
void vstore_u16m2 (uint16_t *base, vuint16m2_t value);
void vstore_u16m4 (uint16_t *base, vuint16m4_t value);
void vstore_u16m8 (uint16_t *base, vuint16m8_t value);
void vstore_u32m1 (uint32_t *base, vuint32m1_t value);
void vstore_u32m2 (uint32_t *base, vuint32m2_t value);
void vstore_u32m4 (uint32_t *base, vuint32m4_t value);
void vstore_u32m8 (uint32_t *base, vuint32m8_t value);
void vstore_u64m1 (uint64_t *base, vuint64m1_t value);
void vstore_u64m2 (uint64_t *base, vuint64m2_t value);
void vstore_u64m4 (uint64_t *base, vuint64m4_t value);
void vstore_u64m8 (uint64_t *base, vuint64m8_t value);
void vstore_f16m1 (float16_t *base, vfloat16m1_t value);
void vstore_f16m2 (float16_t *base, vfloat16m2_t value);
void vstore_f16m4 (float16_t *base, vfloat16m4_t value);
void vstore_f16m8 (float16_t *base, vfloat16m8_t value);
void vstore_f32m1 (float32_t *base, vfloat32m1_t value);
void vstore_f32m2 (float32_t *base, vfloat32m2_t value);
void vstore_f32m4 (float32_t *base, vfloat32m4_t value);
void vstore_f32m8 (float32_t *base, vfloat32m8_t value);
void vstore_f64m1 (float64_t *base, vfloat64m1_t value);
void vstore_f64m2 (float64_t *base, vfloat64m2_t value);
void vstore_f64m4 (float64_t *base, vfloat64m4_t value);
void vstore_f64m8 (float64_t *base, vfloat64m8_t value);
// masked functions
void vstoreb_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstoreb_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstoreb_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstoreb_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstoreb_i16m1_mask (int8_t *base, vbool16_t mask, vint16m1_t value);
void vstoreb_i16m2_mask (int8_t *base, vbool8_t mask, vint16m2_t value);
void vstoreb_i16m4_mask (int8_t *base, vbool4_t mask, vint16m4_t value);
void vstoreb_i16m8_mask (int8_t *base, vbool2_t mask, vint16m8_t value);
void vstoreb_i32m1_mask (int8_t *base, vbool32_t mask, vint32m1_t value);
void vstoreb_i32m2_mask (int8_t *base, vbool16_t mask, vint32m2_t value);
void vstoreb_i32m4_mask (int8_t *base, vbool8_t mask, vint32m4_t value);
void vstoreb_i32m8_mask (int8_t *base, vbool4_t mask, vint32m8_t value);
void vstoreb_i64m1_mask (int8_t *base, vbool64_t mask, vint64m1_t value);
void vstoreb_i64m2_mask (int8_t *base, vbool32_t mask, vint64m2_t value);
void vstoreb_i64m4_mask (int8_t *base, vbool16_t mask, vint64m4_t value);
void vstoreb_i64m8_mask (int8_t *base, vbool8_t mask, vint64m8_t value);
void vstoreb_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstoreb_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstoreb_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstoreb_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstoreb_u16m1_mask (uint8_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreb_u16m2_mask (uint8_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreb_u16m4_mask (uint8_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreb_u16m8_mask (uint8_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreb_u32m1_mask (uint8_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreb_u32m2_mask (uint8_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreb_u32m4_mask (uint8_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreb_u32m8_mask (uint8_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreb_u64m1_mask (uint8_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreb_u64m2_mask (uint8_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreb_u64m4_mask (uint8_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreb_u64m8_mask (uint8_t *base, vbool8_t mask, vuint64m8_t value);
void vstoreh_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstoreh_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstoreh_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstoreh_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstoreh_i32m1_mask (int16_t *base, vbool32_t mask, vint32m1_t value);
void vstoreh_i32m2_mask (int16_t *base, vbool16_t mask, vint32m2_t value);
void vstoreh_i32m4_mask (int16_t *base, vbool8_t mask, vint32m4_t value);
void vstoreh_i32m8_mask (int16_t *base, vbool4_t mask, vint32m8_t value);
void vstoreh_i64m1_mask (int16_t *base, vbool64_t mask, vint64m1_t value);
void vstoreh_i64m2_mask (int16_t *base, vbool32_t mask, vint64m2_t value);
void vstoreh_i64m4_mask (int16_t *base, vbool16_t mask, vint64m4_t value);
void vstoreh_i64m8_mask (int16_t *base, vbool8_t mask, vint64m8_t value);
void vstoreh_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstoreh_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstoreh_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstoreh_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstoreh_u32m1_mask (uint16_t *base, vbool32_t mask, vuint32m1_t value);
void vstoreh_u32m2_mask (uint16_t *base, vbool16_t mask, vuint32m2_t value);
void vstoreh_u32m4_mask (uint16_t *base, vbool8_t mask, vuint32m4_t value);
void vstoreh_u32m8_mask (uint16_t *base, vbool4_t mask, vuint32m8_t value);
void vstoreh_u64m1_mask (uint16_t *base, vbool64_t mask, vuint64m1_t value);
void vstoreh_u64m2_mask (uint16_t *base, vbool32_t mask, vuint64m2_t value);
void vstoreh_u64m4_mask (uint16_t *base, vbool16_t mask, vuint64m4_t value);
void vstoreh_u64m8_mask (uint16_t *base, vbool8_t mask, vuint64m8_t value);
void vstorew_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstorew_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstorew_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstorew_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstorew_i64m1_mask (int32_t *base, vbool64_t mask, vint64m1_t value);
void vstorew_i64m2_mask (int32_t *base, vbool32_t mask, vint64m2_t value);
void vstorew_i64m4_mask (int32_t *base, vbool16_t mask, vint64m4_t value);
void vstorew_i64m8_mask (int32_t *base, vbool8_t mask, vint64m8_t value);
void vstorew_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstorew_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstorew_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstorew_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstorew_u64m1_mask (uint32_t *base, vbool64_t mask, vuint64m1_t value);
void vstorew_u64m2_mask (uint32_t *base, vbool32_t mask, vuint64m2_t value);
void vstorew_u64m4_mask (uint32_t *base, vbool16_t mask, vuint64m4_t value);
void vstorew_u64m8_mask (uint32_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_i8m1_mask (int8_t *base, vbool8_t mask, vint8m1_t value);
void vstore_i8m2_mask (int8_t *base, vbool4_t mask, vint8m2_t value);
void vstore_i8m4_mask (int8_t *base, vbool2_t mask, vint8m4_t value);
void vstore_i8m8_mask (int8_t *base, vbool1_t mask, vint8m8_t value);
void vstore_i16m1_mask (int16_t *base, vbool16_t mask, vint16m1_t value);
void vstore_i16m2_mask (int16_t *base, vbool8_t mask, vint16m2_t value);
void vstore_i16m4_mask (int16_t *base, vbool4_t mask, vint16m4_t value);
void vstore_i16m8_mask (int16_t *base, vbool2_t mask, vint16m8_t value);
void vstore_i32m1_mask (int32_t *base, vbool32_t mask, vint32m1_t value);
void vstore_i32m2_mask (int32_t *base, vbool16_t mask, vint32m2_t value);
void vstore_i32m4_mask (int32_t *base, vbool8_t mask, vint32m4_t value);
void vstore_i32m8_mask (int32_t *base, vbool4_t mask, vint32m8_t value);
void vstore_i64m1_mask (int64_t *base, vbool64_t mask, vint64m1_t value);
void vstore_i64m2_mask (int64_t *base, vbool32_t mask, vint64m2_t value);
void vstore_i64m4_mask (int64_t *base, vbool16_t mask, vint64m4_t value);
void vstore_i64m8_mask (int64_t *base, vbool8_t mask, vint64m8_t value);
void vstore_u8m1_mask (uint8_t *base, vbool8_t mask, vuint8m1_t value);
void vstore_u8m2_mask (uint8_t *base, vbool4_t mask, vuint8m2_t value);
void vstore_u8m4_mask (uint8_t *base, vbool2_t mask, vuint8m4_t value);
void vstore_u8m8_mask (uint8_t *base, vbool1_t mask, vuint8m8_t value);
void vstore_u16m1_mask (uint16_t *base, vbool16_t mask, vuint16m1_t value);
void vstore_u16m2_mask (uint16_t *base, vbool8_t mask, vuint16m2_t value);
void vstore_u16m4_mask (uint16_t *base, vbool4_t mask, vuint16m4_t value);
void vstore_u16m8_mask (uint16_t *base, vbool2_t mask, vuint16m8_t value);
void vstore_u32m1_mask (uint32_t *base, vbool32_t mask, vuint32m1_t value);
void vstore_u32m2_mask (uint32_t *base, vbool16_t mask, vuint32m2_t value);
void vstore_u32m4_mask (uint32_t *base, vbool8_t mask, vuint32m4_t value);
void vstore_u32m8_mask (uint32_t *base, vbool4_t mask, vuint32m8_t value);
void vstore_u64m1_mask (uint64_t *base, vbool64_t mask, vuint64m1_t value);
void vstore_u64m2_mask (uint64_t *base, vbool32_t mask, vuint64m2_t value);
void vstore_u64m4_mask (uint64_t *base, vbool16_t mask, vuint64m4_t value);
void vstore_u64m8_mask (uint64_t *base, vbool8_t mask, vuint64m8_t value);
void vstore_f16m1_mask (float16_t *base, vbool16_t mask, vfloat16m1_t value);
void vstore_f16m2_mask (float16_t *base, vbool8_t mask, vfloat16m2_t value);
void vstore_f16m4_mask (float16_t *base, vbool4_t mask, vfloat16m4_t value);
void vstore_f16m8_mask (float16_t *base, vbool2_t mask, vfloat16m8_t value);
void vstore_f32m1_mask (float32_t *base, vbool32_t mask, vfloat32m1_t value);
void vstore_f32m2_mask (float32_t *base, vbool16_t mask, vfloat32m2_t value);
void vstore_f32m4_mask (float32_t *base, vbool8_t mask, vfloat32m4_t value);
void vstore_f32m8_mask (float32_t *base, vbool4_t mask, vfloat32m8_t value);
void vstore_f64m1_mask (float64_t *base, vbool64_t mask, vfloat64m1_t value);
void vstore_f64m2_mask (float64_t *base, vbool32_t mask, vfloat64m2_t value);
void vstore_f64m4_mask (float64_t *base, vbool16_t mask, vfloat64m4_t value);
void vstore_f64m8_mask (float64_t *base, vbool8_t mask, vfloat64m8_t value);
```
### Vector Strided Load Functions:

**Prototypes:**
``` C
vint8m1_t vloadsb_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1 (const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2 (const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4 (const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8 (const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1 (const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2 (const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4 (const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8 (const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1 (const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2 (const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4 (const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8 (const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1 (const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2 (const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4 (const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8 (const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1 (const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2 (const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4 (const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8 (const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1 (const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2 (const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4 (const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8 (const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1 (const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2 (const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4 (const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8 (const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1 (const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2 (const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4 (const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8 (const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1 (const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2 (const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4 (const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8 (const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1 (const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2 (const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4 (const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8 (const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1 (const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2 (const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4 (const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8 (const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1 (const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2 (const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4 (const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8 (const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1 (const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2 (const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4 (const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8 (const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1 (const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2 (const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4 (const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8 (const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1 (const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2 (const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4 (const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8 (const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1 (const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2 (const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4 (const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8 (const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1 (const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2 (const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4 (const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8 (const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1 (const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2 (const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4 (const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8 (const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1 (const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2 (const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4 (const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8 (const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1 (const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2 (const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4 (const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8 (const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1 (const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2 (const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4 (const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8 (const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1 (const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2 (const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4 (const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8 (const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1 (const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2 (const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4 (const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8 (const float64_t *base, ptrdiff_t bstride);
// masked functions
vint8m1_t vloadsb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloadsb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloadsb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloadsb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m2_t vloadsb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m4_t vloadsb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m8_t vloadsb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m1_t vloadsb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m2_t vloadsb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m4_t vloadsb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint32m8_t vloadsb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m1_t vloadsb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m2_t vloadsb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m4_t vloadsb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint64m8_t vloadsb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vuint8m1_t vloadsb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloadsb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloadsb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloadsb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vint16m1_t vloadsh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloadsh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloadsh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloadsh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m2_t vloadsh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m4_t vloadsh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m8_t vloadsh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m1_t vloadsh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m2_t vloadsh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m4_t vloadsh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint64m8_t vloadsh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vuint16m1_t vloadsh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloadsh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloadsh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloadsh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vint32m1_t vloadsw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloadsw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloadsw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloadsw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloadsw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m2_t vloadsw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m4_t vloadsw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m8_t vloadsw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vuint32m1_t vloadsw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloadsw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloadsw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloadsw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloadsw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m2_t vloadsw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m4_t vloadsw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m8_t vloadsw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vint8m1_t vloads_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m2_t vloads_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m4_t vloads_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint8m8_t vloads_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, ptrdiff_t bstride);
vint16m1_t vloads_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m2_t vloads_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m4_t vloads_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint16m8_t vloads_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, ptrdiff_t bstride);
vint32m1_t vloads_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m2_t vloads_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m4_t vloads_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint32m8_t vloads_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, ptrdiff_t bstride);
vint64m1_t vloads_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m2_t vloads_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m4_t vloads_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vint64m8_t vloads_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, ptrdiff_t bstride);
vuint8m1_t vloads_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m2_t vloads_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m4_t vloads_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint8m8_t vloads_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, ptrdiff_t bstride);
vuint16m1_t vloads_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m2_t vloads_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m4_t vloads_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint16m8_t vloads_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, ptrdiff_t bstride);
vuint32m1_t vloads_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m2_t vloads_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m4_t vloads_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint32m8_t vloads_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, ptrdiff_t bstride);
vuint64m1_t vloads_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m2_t vloads_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m4_t vloads_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vuint64m8_t vloads_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, ptrdiff_t bstride);
vfloat16m1_t vloads_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m2_t vloads_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m4_t vloads_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat16m8_t vloads_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, ptrdiff_t bstride);
vfloat32m1_t vloads_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m2_t vloads_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m4_t vloads_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat32m8_t vloads_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, ptrdiff_t bstride);
vfloat64m1_t vloads_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m2_t vloads_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m4_t vloads_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, ptrdiff_t bstride);
vfloat64m8_t vloads_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, ptrdiff_t bstride);
```
### Vector Strided Store Functions:

**Prototypes:**
``` C
void vstoresb_i8m1 (int8_t *base, intptr_t bstride, vint8m1_t value);
void vstoresb_i8m2 (int8_t *base, intptr_t bstride, vint8m2_t value);
void vstoresb_i8m4 (int8_t *base, intptr_t bstride, vint8m4_t value);
void vstoresb_i8m8 (int8_t *base, intptr_t bstride, vint8m8_t value);
void vstoresb_i16m1 (int8_t *base, intptr_t bstride, vint16m1_t value);
void vstoresb_i16m2 (int8_t *base, intptr_t bstride, vint16m2_t value);
void vstoresb_i16m4 (int8_t *base, intptr_t bstride, vint16m4_t value);
void vstoresb_i16m8 (int8_t *base, intptr_t bstride, vint16m8_t value);
void vstoresb_i32m1 (int8_t *base, intptr_t bstride, vint32m1_t value);
void vstoresb_i32m2 (int8_t *base, intptr_t bstride, vint32m2_t value);
void vstoresb_i32m4 (int8_t *base, intptr_t bstride, vint32m4_t value);
void vstoresb_i32m8 (int8_t *base, intptr_t bstride, vint32m8_t value);
void vstoresb_i64m1 (int8_t *base, intptr_t bstride, vint64m1_t value);
void vstoresb_i64m2 (int8_t *base, intptr_t bstride, vint64m2_t value);
void vstoresb_i64m4 (int8_t *base, intptr_t bstride, vint64m4_t value);
void vstoresb_i64m8 (int8_t *base, intptr_t bstride, vint64m8_t value);
void vstoresb_u8m1 (uint8_t *base, intptr_t bstride, vuint8m1_t value);
void vstoresb_u8m2 (uint8_t *base, intptr_t bstride, vuint8m2_t value);
void vstoresb_u8m4 (uint8_t *base, intptr_t bstride, vuint8m4_t value);
void vstoresb_u8m8 (uint8_t *base, intptr_t bstride, vuint8m8_t value);
void vstoresb_u16m1 (uint8_t *base, intptr_t bstride, vuint16m1_t value);
void vstoresb_u16m2 (uint8_t *base, intptr_t bstride, vuint16m2_t value);
void vstoresb_u16m4 (uint8_t *base, intptr_t bstride, vuint16m4_t value);
void vstoresb_u16m8 (uint8_t *base, intptr_t bstride, vuint16m8_t value);
void vstoresb_u32m1 (uint8_t *base, intptr_t bstride, vuint32m1_t value);
void vstoresb_u32m2 (uint8_t *base, intptr_t bstride, vuint32m2_t value);
void vstoresb_u32m4 (uint8_t *base, intptr_t bstride, vuint32m4_t value);
void vstoresb_u32m8 (uint8_t *base, intptr_t bstride, vuint32m8_t value);
void vstoresb_u64m1 (uint8_t *base, intptr_t bstride, vuint64m1_t value);
void vstoresb_u64m2 (uint8_t *base, intptr_t bstride, vuint64m2_t value);
void vstoresb_u64m4 (uint8_t *base, intptr_t bstride, vuint64m4_t value);
void vstoresb_u64m8 (uint8_t *base, intptr_t bstride, vuint64m8_t value);
void vstoresh_i16m1 (int16_t *base, intptr_t bstride, vint16m1_t value);
void vstoresh_i16m2 (int16_t *base, intptr_t bstride, vint16m2_t value);
void vstoresh_i16m4 (int16_t *base, intptr_t bstride, vint16m4_t value);
void vstoresh_i16m8 (int16_t *base, intptr_t bstride, vint16m8_t value);
void vstoresh_i32m1 (int16_t *base, intptr_t bstride, vint32m1_t value);
void vstoresh_i32m2 (int16_t *base, intptr_t bstride, vint32m2_t value);
void vstoresh_i32m4 (int16_t *base, intptr_t bstride, vint32m4_t value);
void vstoresh_i32m8 (int16_t *base, intptr_t bstride, vint32m8_t value);
void vstoresh_i64m1 (int16_t *base, intptr_t bstride, vint64m1_t value);
void vstoresh_i64m2 (int16_t *base, intptr_t bstride, vint64m2_t value);
void vstoresh_i64m4 (int16_t *base, intptr_t bstride, vint64m4_t value);
void vstoresh_i64m8 (int16_t *base, intptr_t bstride, vint64m8_t value);
void vstoresh_u16m1 (uint16_t *base, intptr_t bstride, vuint16m1_t value);
void vstoresh_u16m2 (uint16_t *base, intptr_t bstride, vuint16m2_t value);
void vstoresh_u16m4 (uint16_t *base, intptr_t bstride, vuint16m4_t value);
void vstoresh_u16m8 (uint16_t *base, intptr_t bstride, vuint16m8_t value);
void vstoresh_u32m1 (uint16_t *base, intptr_t bstride, vuint32m1_t value);
void vstoresh_u32m2 (uint16_t *base, intptr_t bstride, vuint32m2_t value);
void vstoresh_u32m4 (uint16_t *base, intptr_t bstride, vuint32m4_t value);
void vstoresh_u32m8 (uint16_t *base, intptr_t bstride, vuint32m8_t value);
void vstoresh_u64m1 (uint16_t *base, intptr_t bstride, vuint64m1_t value);
void vstoresh_u64m2 (uint16_t *base, intptr_t bstride, vuint64m2_t value);
void vstoresh_u64m4 (uint16_t *base, intptr_t bstride, vuint64m4_t value);
void vstoresh_u64m8 (uint16_t *base, intptr_t bstride, vuint64m8_t value);
void vstoresw_i32m1 (int32_t *base, intptr_t bstride, vint32m1_t value);
void vstoresw_i32m2 (int32_t *base, intptr_t bstride, vint32m2_t value);
void vstoresw_i32m4 (int32_t *base, intptr_t bstride, vint32m4_t value);
void vstoresw_i32m8 (int32_t *base, intptr_t bstride, vint32m8_t value);
void vstoresw_i64m1 (int32_t *base, intptr_t bstride, vint64m1_t value);
void vstoresw_i64m2 (int32_t *base, intptr_t bstride, vint64m2_t value);
void vstoresw_i64m4 (int32_t *base, intptr_t bstride, vint64m4_t value);
void vstoresw_i64m8 (int32_t *base, intptr_t bstride, vint64m8_t value);
void vstoresw_u32m1 (uint32_t *base, intptr_t bstride, vuint32m1_t value);
void vstoresw_u32m2 (uint32_t *base, intptr_t bstride, vuint32m2_t value);
void vstoresw_u32m4 (uint32_t *base, intptr_t bstride, vuint32m4_t value);
void vstoresw_u32m8 (uint32_t *base, intptr_t bstride, vuint32m8_t value);
void vstoresw_u64m1 (uint32_t *base, intptr_t bstride, vuint64m1_t value);
void vstoresw_u64m2 (uint32_t *base, intptr_t bstride, vuint64m2_t value);
void vstoresw_u64m4 (uint32_t *base, intptr_t bstride, vuint64m4_t value);
void vstoresw_u64m8 (uint32_t *base, intptr_t bstride, vuint64m8_t value);
void vstores_i8m1 (int8_t *base, intptr_t bstride, vint8m1_t value);
void vstores_i8m2 (int8_t *base, intptr_t bstride, vint8m2_t value);
void vstores_i8m4 (int8_t *base, intptr_t bstride, vint8m4_t value);
void vstores_i8m8 (int8_t *base, intptr_t bstride, vint8m8_t value);
void vstores_i16m1 (int16_t *base, intptr_t bstride, vint16m1_t value);
void vstores_i16m2 (int16_t *base, intptr_t bstride, vint16m2_t value);
void vstores_i16m4 (int16_t *base, intptr_t bstride, vint16m4_t value);
void vstores_i16m8 (int16_t *base, intptr_t bstride, vint16m8_t value);
void vstores_i32m1 (int32_t *base, intptr_t bstride, vint32m1_t value);
void vstores_i32m2 (int32_t *base, intptr_t bstride, vint32m2_t value);
void vstores_i32m4 (int32_t *base, intptr_t bstride, vint32m4_t value);
void vstores_i32m8 (int32_t *base, intptr_t bstride, vint32m8_t value);
void vstores_i64m1 (int64_t *base, intptr_t bstride, vint64m1_t value);
void vstores_i64m2 (int64_t *base, intptr_t bstride, vint64m2_t value);
void vstores_i64m4 (int64_t *base, intptr_t bstride, vint64m4_t value);
void vstores_i64m8 (int64_t *base, intptr_t bstride, vint64m8_t value);
void vstores_u8m1 (uint8_t *base, intptr_t bstride, vuint8m1_t value);
void vstores_u8m2 (uint8_t *base, intptr_t bstride, vuint8m2_t value);
void vstores_u8m4 (uint8_t *base, intptr_t bstride, vuint8m4_t value);
void vstores_u8m8 (uint8_t *base, intptr_t bstride, vuint8m8_t value);
void vstores_u16m1 (uint16_t *base, intptr_t bstride, vuint16m1_t value);
void vstores_u16m2 (uint16_t *base, intptr_t bstride, vuint16m2_t value);
void vstores_u16m4 (uint16_t *base, intptr_t bstride, vuint16m4_t value);
void vstores_u16m8 (uint16_t *base, intptr_t bstride, vuint16m8_t value);
void vstores_u32m1 (uint32_t *base, intptr_t bstride, vuint32m1_t value);
void vstores_u32m2 (uint32_t *base, intptr_t bstride, vuint32m2_t value);
void vstores_u32m4 (uint32_t *base, intptr_t bstride, vuint32m4_t value);
void vstores_u32m8 (uint32_t *base, intptr_t bstride, vuint32m8_t value);
void vstores_u64m1 (uint64_t *base, intptr_t bstride, vuint64m1_t value);
void vstores_u64m2 (uint64_t *base, intptr_t bstride, vuint64m2_t value);
void vstores_u64m4 (uint64_t *base, intptr_t bstride, vuint64m4_t value);
void vstores_u64m8 (uint64_t *base, intptr_t bstride, vuint64m8_t value);
void vstores_f16m1 (float16_t *base, intptr_t bstride, vfloat16m1_t value);
void vstores_f16m2 (float16_t *base, intptr_t bstride, vfloat16m2_t value);
void vstores_f16m4 (float16_t *base, intptr_t bstride, vfloat16m4_t value);
void vstores_f16m8 (float16_t *base, intptr_t bstride, vfloat16m8_t value);
void vstores_f32m1 (float32_t *base, intptr_t bstride, vfloat32m1_t value);
void vstores_f32m2 (float32_t *base, intptr_t bstride, vfloat32m2_t value);
void vstores_f32m4 (float32_t *base, intptr_t bstride, vfloat32m4_t value);
void vstores_f32m8 (float32_t *base, intptr_t bstride, vfloat32m8_t value);
void vstores_f64m1 (float64_t *base, intptr_t bstride, vfloat64m1_t value);
void vstores_f64m2 (float64_t *base, intptr_t bstride, vfloat64m2_t value);
void vstores_f64m4 (float64_t *base, intptr_t bstride, vfloat64m4_t value);
void vstores_f64m8 (float64_t *base, intptr_t bstride, vfloat64m8_t value);
// masked functions
void vstoresb_i8m1_mask (int8_t *base, intptr_t bstride, vbool8_t mask, vint8m1_t value);
void vstoresb_i8m2_mask (int8_t *base, intptr_t bstride, vbool4_t mask, vint8m2_t value);
void vstoresb_i8m4_mask (int8_t *base, intptr_t bstride, vbool2_t mask, vint8m4_t value);
void vstoresb_i8m8_mask (int8_t *base, intptr_t bstride, vbool1_t mask, vint8m8_t value);
void vstoresb_i16m1_mask (int8_t *base, intptr_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresb_i16m2_mask (int8_t *base, intptr_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresb_i16m4_mask (int8_t *base, intptr_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresb_i16m8_mask (int8_t *base, intptr_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresb_i32m1_mask (int8_t *base, intptr_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresb_i32m2_mask (int8_t *base, intptr_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresb_i32m4_mask (int8_t *base, intptr_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresb_i32m8_mask (int8_t *base, intptr_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresb_i64m1_mask (int8_t *base, intptr_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresb_i64m2_mask (int8_t *base, intptr_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresb_i64m4_mask (int8_t *base, intptr_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresb_i64m8_mask (int8_t *base, intptr_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresb_u8m1_mask (uint8_t *base, intptr_t bstride, vbool8_t mask, vuint8m1_t value);
void vstoresb_u8m2_mask (uint8_t *base, intptr_t bstride, vbool4_t mask, vuint8m2_t value);
void vstoresb_u8m4_mask (uint8_t *base, intptr_t bstride, vbool2_t mask, vuint8m4_t value);
void vstoresb_u8m8_mask (uint8_t *base, intptr_t bstride, vbool1_t mask, vuint8m8_t value);
void vstoresb_u16m1_mask (uint8_t *base, intptr_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresb_u16m2_mask (uint8_t *base, intptr_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresb_u16m4_mask (uint8_t *base, intptr_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresb_u16m8_mask (uint8_t *base, intptr_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresb_u32m1_mask (uint8_t *base, intptr_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresb_u32m2_mask (uint8_t *base, intptr_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresb_u32m4_mask (uint8_t *base, intptr_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresb_u32m8_mask (uint8_t *base, intptr_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresb_u64m1_mask (uint8_t *base, intptr_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresb_u64m2_mask (uint8_t *base, intptr_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresb_u64m4_mask (uint8_t *base, intptr_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresb_u64m8_mask (uint8_t *base, intptr_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresh_i16m1_mask (int16_t *base, intptr_t bstride, vbool16_t mask, vint16m1_t value);
void vstoresh_i16m2_mask (int16_t *base, intptr_t bstride, vbool8_t mask, vint16m2_t value);
void vstoresh_i16m4_mask (int16_t *base, intptr_t bstride, vbool4_t mask, vint16m4_t value);
void vstoresh_i16m8_mask (int16_t *base, intptr_t bstride, vbool2_t mask, vint16m8_t value);
void vstoresh_i32m1_mask (int16_t *base, intptr_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresh_i32m2_mask (int16_t *base, intptr_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresh_i32m4_mask (int16_t *base, intptr_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresh_i32m8_mask (int16_t *base, intptr_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresh_i64m1_mask (int16_t *base, intptr_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresh_i64m2_mask (int16_t *base, intptr_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresh_i64m4_mask (int16_t *base, intptr_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresh_i64m8_mask (int16_t *base, intptr_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresh_u16m1_mask (uint16_t *base, intptr_t bstride, vbool16_t mask, vuint16m1_t value);
void vstoresh_u16m2_mask (uint16_t *base, intptr_t bstride, vbool8_t mask, vuint16m2_t value);
void vstoresh_u16m4_mask (uint16_t *base, intptr_t bstride, vbool4_t mask, vuint16m4_t value);
void vstoresh_u16m8_mask (uint16_t *base, intptr_t bstride, vbool2_t mask, vuint16m8_t value);
void vstoresh_u32m1_mask (uint16_t *base, intptr_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresh_u32m2_mask (uint16_t *base, intptr_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresh_u32m4_mask (uint16_t *base, intptr_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresh_u32m8_mask (uint16_t *base, intptr_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresh_u64m1_mask (uint16_t *base, intptr_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresh_u64m2_mask (uint16_t *base, intptr_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresh_u64m4_mask (uint16_t *base, intptr_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresh_u64m8_mask (uint16_t *base, intptr_t bstride, vbool8_t mask, vuint64m8_t value);
void vstoresw_i32m1_mask (int32_t *base, intptr_t bstride, vbool32_t mask, vint32m1_t value);
void vstoresw_i32m2_mask (int32_t *base, intptr_t bstride, vbool16_t mask, vint32m2_t value);
void vstoresw_i32m4_mask (int32_t *base, intptr_t bstride, vbool8_t mask, vint32m4_t value);
void vstoresw_i32m8_mask (int32_t *base, intptr_t bstride, vbool4_t mask, vint32m8_t value);
void vstoresw_i64m1_mask (int32_t *base, intptr_t bstride, vbool64_t mask, vint64m1_t value);
void vstoresw_i64m2_mask (int32_t *base, intptr_t bstride, vbool32_t mask, vint64m2_t value);
void vstoresw_i64m4_mask (int32_t *base, intptr_t bstride, vbool16_t mask, vint64m4_t value);
void vstoresw_i64m8_mask (int32_t *base, intptr_t bstride, vbool8_t mask, vint64m8_t value);
void vstoresw_u32m1_mask (uint32_t *base, intptr_t bstride, vbool32_t mask, vuint32m1_t value);
void vstoresw_u32m2_mask (uint32_t *base, intptr_t bstride, vbool16_t mask, vuint32m2_t value);
void vstoresw_u32m4_mask (uint32_t *base, intptr_t bstride, vbool8_t mask, vuint32m4_t value);
void vstoresw_u32m8_mask (uint32_t *base, intptr_t bstride, vbool4_t mask, vuint32m8_t value);
void vstoresw_u64m1_mask (uint32_t *base, intptr_t bstride, vbool64_t mask, vuint64m1_t value);
void vstoresw_u64m2_mask (uint32_t *base, intptr_t bstride, vbool32_t mask, vuint64m2_t value);
void vstoresw_u64m4_mask (uint32_t *base, intptr_t bstride, vbool16_t mask, vuint64m4_t value);
void vstoresw_u64m8_mask (uint32_t *base, intptr_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_i8m1_mask (int8_t *base, intptr_t bstride, vbool8_t mask, vint8m1_t value);
void vstores_i8m2_mask (int8_t *base, intptr_t bstride, vbool4_t mask, vint8m2_t value);
void vstores_i8m4_mask (int8_t *base, intptr_t bstride, vbool2_t mask, vint8m4_t value);
void vstores_i8m8_mask (int8_t *base, intptr_t bstride, vbool1_t mask, vint8m8_t value);
void vstores_i16m1_mask (int16_t *base, intptr_t bstride, vbool16_t mask, vint16m1_t value);
void vstores_i16m2_mask (int16_t *base, intptr_t bstride, vbool8_t mask, vint16m2_t value);
void vstores_i16m4_mask (int16_t *base, intptr_t bstride, vbool4_t mask, vint16m4_t value);
void vstores_i16m8_mask (int16_t *base, intptr_t bstride, vbool2_t mask, vint16m8_t value);
void vstores_i32m1_mask (int32_t *base, intptr_t bstride, vbool32_t mask, vint32m1_t value);
void vstores_i32m2_mask (int32_t *base, intptr_t bstride, vbool16_t mask, vint32m2_t value);
void vstores_i32m4_mask (int32_t *base, intptr_t bstride, vbool8_t mask, vint32m4_t value);
void vstores_i32m8_mask (int32_t *base, intptr_t bstride, vbool4_t mask, vint32m8_t value);
void vstores_i64m1_mask (int64_t *base, intptr_t bstride, vbool64_t mask, vint64m1_t value);
void vstores_i64m2_mask (int64_t *base, intptr_t bstride, vbool32_t mask, vint64m2_t value);
void vstores_i64m4_mask (int64_t *base, intptr_t bstride, vbool16_t mask, vint64m4_t value);
void vstores_i64m8_mask (int64_t *base, intptr_t bstride, vbool8_t mask, vint64m8_t value);
void vstores_u8m1_mask (uint8_t *base, intptr_t bstride, vbool8_t mask, vuint8m1_t value);
void vstores_u8m2_mask (uint8_t *base, intptr_t bstride, vbool4_t mask, vuint8m2_t value);
void vstores_u8m4_mask (uint8_t *base, intptr_t bstride, vbool2_t mask, vuint8m4_t value);
void vstores_u8m8_mask (uint8_t *base, intptr_t bstride, vbool1_t mask, vuint8m8_t value);
void vstores_u16m1_mask (uint16_t *base, intptr_t bstride, vbool16_t mask, vuint16m1_t value);
void vstores_u16m2_mask (uint16_t *base, intptr_t bstride, vbool8_t mask, vuint16m2_t value);
void vstores_u16m4_mask (uint16_t *base, intptr_t bstride, vbool4_t mask, vuint16m4_t value);
void vstores_u16m8_mask (uint16_t *base, intptr_t bstride, vbool2_t mask, vuint16m8_t value);
void vstores_u32m1_mask (uint32_t *base, intptr_t bstride, vbool32_t mask, vuint32m1_t value);
void vstores_u32m2_mask (uint32_t *base, intptr_t bstride, vbool16_t mask, vuint32m2_t value);
void vstores_u32m4_mask (uint32_t *base, intptr_t bstride, vbool8_t mask, vuint32m4_t value);
void vstores_u32m8_mask (uint32_t *base, intptr_t bstride, vbool4_t mask, vuint32m8_t value);
void vstores_u64m1_mask (uint64_t *base, intptr_t bstride, vbool64_t mask, vuint64m1_t value);
void vstores_u64m2_mask (uint64_t *base, intptr_t bstride, vbool32_t mask, vuint64m2_t value);
void vstores_u64m4_mask (uint64_t *base, intptr_t bstride, vbool16_t mask, vuint64m4_t value);
void vstores_u64m8_mask (uint64_t *base, intptr_t bstride, vbool8_t mask, vuint64m8_t value);
void vstores_f16m1_mask (float16_t *base, intptr_t bstride, vbool16_t mask, vfloat16m1_t value);
void vstores_f16m2_mask (float16_t *base, intptr_t bstride, vbool8_t mask, vfloat16m2_t value);
void vstores_f16m4_mask (float16_t *base, intptr_t bstride, vbool4_t mask, vfloat16m4_t value);
void vstores_f16m8_mask (float16_t *base, intptr_t bstride, vbool2_t mask, vfloat16m8_t value);
void vstores_f32m1_mask (float32_t *base, intptr_t bstride, vbool32_t mask, vfloat32m1_t value);
void vstores_f32m2_mask (float32_t *base, intptr_t bstride, vbool16_t mask, vfloat32m2_t value);
void vstores_f32m4_mask (float32_t *base, intptr_t bstride, vbool8_t mask, vfloat32m4_t value);
void vstores_f32m8_mask (float32_t *base, intptr_t bstride, vbool4_t mask, vfloat32m8_t value);
void vstores_f64m1_mask (float64_t *base, intptr_t bstride, vbool64_t mask, vfloat64m1_t value);
void vstores_f64m2_mask (float64_t *base, intptr_t bstride, vbool32_t mask, vfloat64m2_t value);
void vstores_f64m4_mask (float64_t *base, intptr_t bstride, vbool16_t mask, vfloat64m4_t value);
void vstores_f64m8_mask (float64_t *base, intptr_t bstride, vbool8_t mask, vfloat64m8_t value);
```
### Vector Indexed Load Functions:

**Prototypes:**
``` C
vint8m1_t vloadxb_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1 (const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2 (const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4 (const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8 (const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1 (const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2 (const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4 (const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8 (const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1 (const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2 (const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4 (const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8 (const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1 (const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2 (const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4 (const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8 (const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1 (const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2 (const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4 (const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8 (const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1 (const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2 (const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4 (const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8 (const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1 (const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2 (const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4 (const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8 (const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1 (const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2 (const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4 (const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8 (const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1 (const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2 (const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4 (const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8 (const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1 (const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2 (const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4 (const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8 (const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1 (const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2 (const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4 (const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8 (const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1 (const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2 (const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4 (const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8 (const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1 (const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2 (const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4 (const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8 (const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1 (const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2 (const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4 (const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8 (const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1 (const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2 (const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4 (const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8 (const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1 (const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2 (const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4 (const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8 (const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1 (const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2 (const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4 (const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8 (const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1 (const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2 (const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4 (const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8 (const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1 (const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2 (const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4 (const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8 (const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1 (const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2 (const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4 (const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8 (const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1 (const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2 (const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4 (const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8 (const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1 (const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2 (const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4 (const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8 (const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1 (const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2 (const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4 (const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8 (const float64_t *base, vuint64m8_t bindex);
// masked functions
vint8m1_t vloadxb_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadxb_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadxb_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadxb_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadxb_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base, vuint16m1_t bindex);
vint16m2_t vloadxb_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base, vuint16m2_t bindex);
vint16m4_t vloadxb_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base, vuint16m4_t bindex);
vint16m8_t vloadxb_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base, vuint16m8_t bindex);
vint32m1_t vloadxb_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base, vuint32m1_t bindex);
vint32m2_t vloadxb_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base, vuint32m2_t bindex);
vint32m4_t vloadxb_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base, vuint32m4_t bindex);
vint32m8_t vloadxb_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base, vuint32m8_t bindex);
vint64m1_t vloadxb_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base, vuint64m1_t bindex);
vint64m2_t vloadxb_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base, vuint64m2_t bindex);
vint64m4_t vloadxb_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base, vuint64m4_t bindex);
vint64m8_t vloadxb_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base, vuint64m8_t bindex);
vuint8m1_t vloadxb_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadxb_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadxb_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadxb_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadxb_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxb_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxb_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxb_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxb_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxb_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxb_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxb_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxb_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxb_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxb_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxb_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base, vuint64m8_t bindex);
vint16m1_t vloadxh_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadxh_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadxh_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadxh_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadxh_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base, vuint32m1_t bindex);
vint32m2_t vloadxh_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base, vuint32m2_t bindex);
vint32m4_t vloadxh_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base, vuint32m4_t bindex);
vint32m8_t vloadxh_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base, vuint32m8_t bindex);
vint64m1_t vloadxh_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base, vuint64m1_t bindex);
vint64m2_t vloadxh_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base, vuint64m2_t bindex);
vint64m4_t vloadxh_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base, vuint64m4_t bindex);
vint64m8_t vloadxh_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base, vuint64m8_t bindex);
vuint16m1_t vloadxh_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadxh_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadxh_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadxh_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadxh_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxh_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxh_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxh_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxh_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxh_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxh_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxh_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base, vuint64m8_t bindex);
vint32m1_t vloadxw_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadxw_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadxw_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadxw_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadxw_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base, vuint64m1_t bindex);
vint64m2_t vloadxw_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base, vuint64m2_t bindex);
vint64m4_t vloadxw_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base, vuint64m4_t bindex);
vint64m8_t vloadxw_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base, vuint64m8_t bindex);
vuint32m1_t vloadxw_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadxw_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadxw_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadxw_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadxw_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base, vuint64m1_t bindex);
vuint64m2_t vloadxw_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base, vuint64m2_t bindex);
vuint64m4_t vloadxw_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base, vuint64m4_t bindex);
vuint64m8_t vloadxw_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base, vuint64m8_t bindex);
vint8m1_t vloadx_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base, vuint8m1_t bindex);
vint8m2_t vloadx_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base, vuint8m2_t bindex);
vint8m4_t vloadx_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base, vuint8m4_t bindex);
vint8m8_t vloadx_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base, vuint8m8_t bindex);
vint16m1_t vloadx_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base, vuint16m1_t bindex);
vint16m2_t vloadx_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base, vuint16m2_t bindex);
vint16m4_t vloadx_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base, vuint16m4_t bindex);
vint16m8_t vloadx_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base, vuint16m8_t bindex);
vint32m1_t vloadx_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base, vuint32m1_t bindex);
vint32m2_t vloadx_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base, vuint32m2_t bindex);
vint32m4_t vloadx_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base, vuint32m4_t bindex);
vint32m8_t vloadx_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base, vuint32m8_t bindex);
vint64m1_t vloadx_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base, vuint64m1_t bindex);
vint64m2_t vloadx_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base, vuint64m2_t bindex);
vint64m4_t vloadx_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base, vuint64m4_t bindex);
vint64m8_t vloadx_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base, vuint64m8_t bindex);
vuint8m1_t vloadx_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base, vuint8m1_t bindex);
vuint8m2_t vloadx_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base, vuint8m2_t bindex);
vuint8m4_t vloadx_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base, vuint8m4_t bindex);
vuint8m8_t vloadx_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base, vuint8m8_t bindex);
vuint16m1_t vloadx_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base, vuint16m1_t bindex);
vuint16m2_t vloadx_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base, vuint16m2_t bindex);
vuint16m4_t vloadx_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base, vuint16m4_t bindex);
vuint16m8_t vloadx_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base, vuint16m8_t bindex);
vuint32m1_t vloadx_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base, vuint32m1_t bindex);
vuint32m2_t vloadx_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base, vuint32m2_t bindex);
vuint32m4_t vloadx_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base, vuint32m4_t bindex);
vuint32m8_t vloadx_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base, vuint32m8_t bindex);
vuint64m1_t vloadx_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base, vuint64m1_t bindex);
vuint64m2_t vloadx_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base, vuint64m2_t bindex);
vuint64m4_t vloadx_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base, vuint64m4_t bindex);
vuint64m8_t vloadx_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base, vuint64m8_t bindex);
vfloat16m1_t vloadx_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base, vuint16m1_t bindex);
vfloat16m2_t vloadx_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base, vuint16m2_t bindex);
vfloat16m4_t vloadx_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base, vuint16m4_t bindex);
vfloat16m8_t vloadx_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base, vuint16m8_t bindex);
vfloat32m1_t vloadx_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base, vuint32m1_t bindex);
vfloat32m2_t vloadx_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base, vuint32m2_t bindex);
vfloat32m4_t vloadx_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base, vuint32m4_t bindex);
vfloat32m8_t vloadx_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base, vuint32m8_t bindex);
vfloat64m1_t vloadx_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base, vuint64m1_t bindex);
vfloat64m2_t vloadx_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base, vuint64m2_t bindex);
vfloat64m4_t vloadx_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base, vuint64m4_t bindex);
vfloat64m8_t vloadx_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base, vuint64m8_t bindex);
```
### Vector Indexed Store Functions:

**Prototypes:**
``` C
void vstorexb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorexb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorexb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorexb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorexb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorexb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorexb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorexb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorexb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorexh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorexh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorexh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorexh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorexh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorexh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorexh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorexh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorexw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorexw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorexw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorexw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorexw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorexw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorexw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorexw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorexw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorexw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorexw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorexw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorexw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorexw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorexw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorexw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstorex_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstorex_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstorex_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstorex_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstorex_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstorex_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstorex_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstorex_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstorex_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstorex_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstorex_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstorex_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstorex_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstorex_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstorex_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstorex_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstorex_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstorex_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstorex_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstorex_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstorex_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstorex_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstorex_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstorex_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstorex_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstorex_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstorex_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstorex_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstorex_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstorex_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstorex_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstorex_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstorex_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstorex_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstorex_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstorex_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstorex_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstorex_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstorex_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstorex_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstorex_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstorex_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstorex_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
void vstoreuxb_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreuxb_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreuxb_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreuxb_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreuxb_i16m1 (int8_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxb_i16m2 (int8_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxb_i16m4 (int8_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxb_i16m8 (int8_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxb_i32m1 (int8_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxb_i32m2 (int8_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxb_i32m4 (int8_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxb_i32m8 (int8_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxb_i64m1 (int8_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxb_i64m2 (int8_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxb_i64m4 (int8_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxb_i64m8 (int8_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxb_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreuxb_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreuxb_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreuxb_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreuxb_u16m1 (uint8_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxb_u16m2 (uint8_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxb_u16m4 (uint8_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxb_u16m8 (uint8_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxb_u32m1 (uint8_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxb_u32m2 (uint8_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxb_u32m4 (uint8_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxb_u32m8 (uint8_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxb_u64m1 (uint8_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxb_u64m2 (uint8_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxb_u64m4 (uint8_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxb_u64m8 (uint8_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxh_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreuxh_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreuxh_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreuxh_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreuxh_i32m1 (int16_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxh_i32m2 (int16_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxh_i32m4 (int16_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxh_i32m8 (int16_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxh_i64m1 (int16_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxh_i64m2 (int16_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxh_i64m4 (int16_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxh_i64m8 (int16_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxh_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreuxh_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreuxh_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreuxh_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreuxh_u32m1 (uint16_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxh_u32m2 (uint16_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxh_u32m4 (uint16_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxh_u32m8 (uint16_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxh_u64m1 (uint16_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxh_u64m2 (uint16_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxh_u64m4 (uint16_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxh_u64m8 (uint16_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreuxw_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreuxw_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreuxw_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreuxw_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreuxw_i64m1 (int32_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreuxw_i64m2 (int32_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreuxw_i64m4 (int32_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreuxw_i64m8 (int32_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreuxw_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreuxw_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreuxw_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreuxw_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreuxw_u64m1 (uint32_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreuxw_u64m2 (uint32_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreuxw_u64m4 (uint32_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreuxw_u64m8 (uint32_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_i8m1 (int8_t *base, vuint8m1_t bindex, vint8m1_t value);
void vstoreux_i8m2 (int8_t *base, vuint8m2_t bindex, vint8m2_t value);
void vstoreux_i8m4 (int8_t *base, vuint8m4_t bindex, vint8m4_t value);
void vstoreux_i8m8 (int8_t *base, vuint8m8_t bindex, vint8m8_t value);
void vstoreux_i16m1 (int16_t *base, vuint16m1_t bindex, vint16m1_t value);
void vstoreux_i16m2 (int16_t *base, vuint16m2_t bindex, vint16m2_t value);
void vstoreux_i16m4 (int16_t *base, vuint16m4_t bindex, vint16m4_t value);
void vstoreux_i16m8 (int16_t *base, vuint16m8_t bindex, vint16m8_t value);
void vstoreux_i32m1 (int32_t *base, vuint32m1_t bindex, vint32m1_t value);
void vstoreux_i32m2 (int32_t *base, vuint32m2_t bindex, vint32m2_t value);
void vstoreux_i32m4 (int32_t *base, vuint32m4_t bindex, vint32m4_t value);
void vstoreux_i32m8 (int32_t *base, vuint32m8_t bindex, vint32m8_t value);
void vstoreux_i64m1 (int64_t *base, vuint64m1_t bindex, vint64m1_t value);
void vstoreux_i64m2 (int64_t *base, vuint64m2_t bindex, vint64m2_t value);
void vstoreux_i64m4 (int64_t *base, vuint64m4_t bindex, vint64m4_t value);
void vstoreux_i64m8 (int64_t *base, vuint64m8_t bindex, vint64m8_t value);
void vstoreux_u8m1 (uint8_t *base, vuint8m1_t bindex, vuint8m1_t value);
void vstoreux_u8m2 (uint8_t *base, vuint8m2_t bindex, vuint8m2_t value);
void vstoreux_u8m4 (uint8_t *base, vuint8m4_t bindex, vuint8m4_t value);
void vstoreux_u8m8 (uint8_t *base, vuint8m8_t bindex, vuint8m8_t value);
void vstoreux_u16m1 (uint16_t *base, vuint16m1_t bindex, vuint16m1_t value);
void vstoreux_u16m2 (uint16_t *base, vuint16m2_t bindex, vuint16m2_t value);
void vstoreux_u16m4 (uint16_t *base, vuint16m4_t bindex, vuint16m4_t value);
void vstoreux_u16m8 (uint16_t *base, vuint16m8_t bindex, vuint16m8_t value);
void vstoreux_u32m1 (uint32_t *base, vuint32m1_t bindex, vuint32m1_t value);
void vstoreux_u32m2 (uint32_t *base, vuint32m2_t bindex, vuint32m2_t value);
void vstoreux_u32m4 (uint32_t *base, vuint32m4_t bindex, vuint32m4_t value);
void vstoreux_u32m8 (uint32_t *base, vuint32m8_t bindex, vuint32m8_t value);
void vstoreux_u64m1 (uint64_t *base, vuint64m1_t bindex, vuint64m1_t value);
void vstoreux_u64m2 (uint64_t *base, vuint64m2_t bindex, vuint64m2_t value);
void vstoreux_u64m4 (uint64_t *base, vuint64m4_t bindex, vuint64m4_t value);
void vstoreux_u64m8 (uint64_t *base, vuint64m8_t bindex, vuint64m8_t value);
void vstoreux_f16m1 (float16_t *base, vuint16m1_t bindex, vfloat16m1_t value);
void vstoreux_f16m2 (float16_t *base, vuint16m2_t bindex, vfloat16m2_t value);
void vstoreux_f16m4 (float16_t *base, vuint16m4_t bindex, vfloat16m4_t value);
void vstoreux_f16m8 (float16_t *base, vuint16m8_t bindex, vfloat16m8_t value);
void vstoreux_f32m1 (float32_t *base, vuint32m1_t bindex, vfloat32m1_t value);
void vstoreux_f32m2 (float32_t *base, vuint32m2_t bindex, vfloat32m2_t value);
void vstoreux_f32m4 (float32_t *base, vuint32m4_t bindex, vfloat32m4_t value);
void vstoreux_f32m8 (float32_t *base, vuint32m8_t bindex, vfloat32m8_t value);
void vstoreux_f64m1 (float64_t *base, vuint64m1_t bindex, vfloat64m1_t value);
void vstoreux_f64m2 (float64_t *base, vuint64m2_t bindex, vfloat64m2_t value);
void vstoreux_f64m4 (float64_t *base, vuint64m4_t bindex, vfloat64m4_t value);
void vstoreux_f64m8 (float64_t *base, vuint64m8_t bindex, vfloat64m8_t value);
// masked functions
void vstorexb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorexb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorexb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorexb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorexb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorexb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorexb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorexb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorexb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorexh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorexh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorexh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorexh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorexh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorexh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorexh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorexh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorexw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorexw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorexw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorexw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorexw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorexw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorexw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorexw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorexw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorexw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorexw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorexw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorexw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorexw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorexw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorexw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstorex_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstorex_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstorex_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstorex_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstorex_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstorex_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstorex_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstorex_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstorex_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstorex_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstorex_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstorex_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstorex_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstorex_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstorex_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstorex_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstorex_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstorex_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstorex_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstorex_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstorex_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstorex_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstorex_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstorex_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstorex_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstorex_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstorex_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstorex_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstorex_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstorex_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstorex_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstorex_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstorex_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstorex_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstorex_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstorex_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstorex_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstorex_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstorex_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstorex_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstorex_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstorex_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstorex_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
void vstoreuxb_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreuxb_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreuxb_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreuxb_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreuxb_i16m1_mask (int8_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxb_i16m2_mask (int8_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxb_i16m4_mask (int8_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxb_i16m8_mask (int8_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxb_i32m1_mask (int8_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxb_i32m2_mask (int8_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxb_i32m4_mask (int8_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxb_i32m8_mask (int8_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxb_i64m1_mask (int8_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxb_i64m2_mask (int8_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxb_i64m4_mask (int8_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxb_i64m8_mask (int8_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxb_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreuxb_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreuxb_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreuxb_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreuxb_u16m1_mask (uint8_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxb_u16m2_mask (uint8_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxb_u16m4_mask (uint8_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxb_u16m8_mask (uint8_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxb_u32m1_mask (uint8_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxb_u32m2_mask (uint8_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxb_u32m4_mask (uint8_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxb_u32m8_mask (uint8_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxb_u64m1_mask (uint8_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxb_u64m2_mask (uint8_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxb_u64m4_mask (uint8_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxb_u64m8_mask (uint8_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxh_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreuxh_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreuxh_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreuxh_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreuxh_i32m1_mask (int16_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxh_i32m2_mask (int16_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxh_i32m4_mask (int16_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxh_i32m8_mask (int16_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxh_i64m1_mask (int16_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxh_i64m2_mask (int16_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxh_i64m4_mask (int16_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxh_i64m8_mask (int16_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxh_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreuxh_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreuxh_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreuxh_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreuxh_u32m1_mask (uint16_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxh_u32m2_mask (uint16_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxh_u32m4_mask (uint16_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxh_u32m8_mask (uint16_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxh_u64m1_mask (uint16_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxh_u64m2_mask (uint16_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxh_u64m4_mask (uint16_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxh_u64m8_mask (uint16_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreuxw_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreuxw_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreuxw_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreuxw_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreuxw_i64m1_mask (int32_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreuxw_i64m2_mask (int32_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreuxw_i64m4_mask (int32_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreuxw_i64m8_mask (int32_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreuxw_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreuxw_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreuxw_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreuxw_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreuxw_u64m1_mask (uint32_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreuxw_u64m2_mask (uint32_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreuxw_u64m4_mask (uint32_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreuxw_u64m8_mask (uint32_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_i8m1_mask (int8_t *base, vuint8m1_t bindex, vbool8_t mask, vint8m1_t value);
void vstoreux_i8m2_mask (int8_t *base, vuint8m2_t bindex, vbool4_t mask, vint8m2_t value);
void vstoreux_i8m4_mask (int8_t *base, vuint8m4_t bindex, vbool2_t mask, vint8m4_t value);
void vstoreux_i8m8_mask (int8_t *base, vuint8m8_t bindex, vbool1_t mask, vint8m8_t value);
void vstoreux_i16m1_mask (int16_t *base, vuint16m1_t bindex, vbool16_t mask, vint16m1_t value);
void vstoreux_i16m2_mask (int16_t *base, vuint16m2_t bindex, vbool8_t mask, vint16m2_t value);
void vstoreux_i16m4_mask (int16_t *base, vuint16m4_t bindex, vbool4_t mask, vint16m4_t value);
void vstoreux_i16m8_mask (int16_t *base, vuint16m8_t bindex, vbool2_t mask, vint16m8_t value);
void vstoreux_i32m1_mask (int32_t *base, vuint32m1_t bindex, vbool32_t mask, vint32m1_t value);
void vstoreux_i32m2_mask (int32_t *base, vuint32m2_t bindex, vbool16_t mask, vint32m2_t value);
void vstoreux_i32m4_mask (int32_t *base, vuint32m4_t bindex, vbool8_t mask, vint32m4_t value);
void vstoreux_i32m8_mask (int32_t *base, vuint32m8_t bindex, vbool4_t mask, vint32m8_t value);
void vstoreux_i64m1_mask (int64_t *base, vuint64m1_t bindex, vbool64_t mask, vint64m1_t value);
void vstoreux_i64m2_mask (int64_t *base, vuint64m2_t bindex, vbool32_t mask, vint64m2_t value);
void vstoreux_i64m4_mask (int64_t *base, vuint64m4_t bindex, vbool16_t mask, vint64m4_t value);
void vstoreux_i64m8_mask (int64_t *base, vuint64m8_t bindex, vbool8_t mask, vint64m8_t value);
void vstoreux_u8m1_mask (uint8_t *base, vuint8m1_t bindex, vbool8_t mask, vuint8m1_t value);
void vstoreux_u8m2_mask (uint8_t *base, vuint8m2_t bindex, vbool4_t mask, vuint8m2_t value);
void vstoreux_u8m4_mask (uint8_t *base, vuint8m4_t bindex, vbool2_t mask, vuint8m4_t value);
void vstoreux_u8m8_mask (uint8_t *base, vuint8m8_t bindex, vbool1_t mask, vuint8m8_t value);
void vstoreux_u16m1_mask (uint16_t *base, vuint16m1_t bindex, vbool16_t mask, vuint16m1_t value);
void vstoreux_u16m2_mask (uint16_t *base, vuint16m2_t bindex, vbool8_t mask, vuint16m2_t value);
void vstoreux_u16m4_mask (uint16_t *base, vuint16m4_t bindex, vbool4_t mask, vuint16m4_t value);
void vstoreux_u16m8_mask (uint16_t *base, vuint16m8_t bindex, vbool2_t mask, vuint16m8_t value);
void vstoreux_u32m1_mask (uint32_t *base, vuint32m1_t bindex, vbool32_t mask, vuint32m1_t value);
void vstoreux_u32m2_mask (uint32_t *base, vuint32m2_t bindex, vbool16_t mask, vuint32m2_t value);
void vstoreux_u32m4_mask (uint32_t *base, vuint32m4_t bindex, vbool8_t mask, vuint32m4_t value);
void vstoreux_u32m8_mask (uint32_t *base, vuint32m8_t bindex, vbool4_t mask, vuint32m8_t value);
void vstoreux_u64m1_mask (uint64_t *base, vuint64m1_t bindex, vbool64_t mask, vuint64m1_t value);
void vstoreux_u64m2_mask (uint64_t *base, vuint64m2_t bindex, vbool32_t mask, vuint64m2_t value);
void vstoreux_u64m4_mask (uint64_t *base, vuint64m4_t bindex, vbool16_t mask, vuint64m4_t value);
void vstoreux_u64m8_mask (uint64_t *base, vuint64m8_t bindex, vbool8_t mask, vuint64m8_t value);
void vstoreux_f16m1_mask (float16_t *base, vuint16m1_t bindex, vbool16_t mask, vfloat16m1_t value);
void vstoreux_f16m2_mask (float16_t *base, vuint16m2_t bindex, vbool8_t mask, vfloat16m2_t value);
void vstoreux_f16m4_mask (float16_t *base, vuint16m4_t bindex, vbool4_t mask, vfloat16m4_t value);
void vstoreux_f16m8_mask (float16_t *base, vuint16m8_t bindex, vbool2_t mask, vfloat16m8_t value);
void vstoreux_f32m1_mask (float32_t *base, vuint32m1_t bindex, vbool32_t mask, vfloat32m1_t value);
void vstoreux_f32m2_mask (float32_t *base, vuint32m2_t bindex, vbool16_t mask, vfloat32m2_t value);
void vstoreux_f32m4_mask (float32_t *base, vuint32m4_t bindex, vbool8_t mask, vfloat32m4_t value);
void vstoreux_f32m8_mask (float32_t *base, vuint32m8_t bindex, vbool4_t mask, vfloat32m8_t value);
void vstoreux_f64m1_mask (float64_t *base, vuint64m1_t bindex, vbool64_t mask, vfloat64m1_t value);
void vstoreux_f64m2_mask (float64_t *base, vuint64m2_t bindex, vbool32_t mask, vfloat64m2_t value);
void vstoreux_f64m4_mask (float64_t *base, vuint64m4_t bindex, vbool16_t mask, vfloat64m4_t value);
void vstoreux_f64m8_mask (float64_t *base, vuint64m8_t bindex, vbool8_t mask, vfloat64m8_t value);
```
### Unit-stride Fault-Only-First Loads Functions:

**Prototypes:**
``` C
vint8m1_t vloadbff_i8m1 (const int8_t *base);
vint8m2_t vloadbff_i8m2 (const int8_t *base);
vint8m4_t vloadbff_i8m4 (const int8_t *base);
vint8m8_t vloadbff_i8m8 (const int8_t *base);
vint16m1_t vloadbff_i16m1 (const int8_t *base);
vint16m2_t vloadbff_i16m2 (const int8_t *base);
vint16m4_t vloadbff_i16m4 (const int8_t *base);
vint16m8_t vloadbff_i16m8 (const int8_t *base);
vint32m1_t vloadbff_i32m1 (const int8_t *base);
vint32m2_t vloadbff_i32m2 (const int8_t *base);
vint32m4_t vloadbff_i32m4 (const int8_t *base);
vint32m8_t vloadbff_i32m8 (const int8_t *base);
vint64m1_t vloadbff_i64m1 (const int8_t *base);
vint64m2_t vloadbff_i64m2 (const int8_t *base);
vint64m4_t vloadbff_i64m4 (const int8_t *base);
vint64m8_t vloadbff_i64m8 (const int8_t *base);
vuint8m1_t vloadbff_u8m1 (const uint8_t *base);
vuint8m2_t vloadbff_u8m2 (const uint8_t *base);
vuint8m4_t vloadbff_u8m4 (const uint8_t *base);
vuint8m8_t vloadbff_u8m8 (const uint8_t *base);
vuint16m1_t vloadbff_u16m1 (const uint8_t *base);
vuint16m2_t vloadbff_u16m2 (const uint8_t *base);
vuint16m4_t vloadbff_u16m4 (const uint8_t *base);
vuint16m8_t vloadbff_u16m8 (const uint8_t *base);
vuint32m1_t vloadbff_u32m1 (const uint8_t *base);
vuint32m2_t vloadbff_u32m2 (const uint8_t *base);
vuint32m4_t vloadbff_u32m4 (const uint8_t *base);
vuint32m8_t vloadbff_u32m8 (const uint8_t *base);
vuint64m1_t vloadbff_u64m1 (const uint8_t *base);
vuint64m2_t vloadbff_u64m2 (const uint8_t *base);
vuint64m4_t vloadbff_u64m4 (const uint8_t *base);
vuint64m8_t vloadbff_u64m8 (const uint8_t *base);
vint16m1_t vloadhff_i16m1 (const int16_t *base);
vint16m2_t vloadhff_i16m2 (const int16_t *base);
vint16m4_t vloadhff_i16m4 (const int16_t *base);
vint16m8_t vloadhff_i16m8 (const int16_t *base);
vint32m1_t vloadhff_i32m1 (const int16_t *base);
vint32m2_t vloadhff_i32m2 (const int16_t *base);
vint32m4_t vloadhff_i32m4 (const int16_t *base);
vint32m8_t vloadhff_i32m8 (const int16_t *base);
vint64m1_t vloadhff_i64m1 (const int16_t *base);
vint64m2_t vloadhff_i64m2 (const int16_t *base);
vint64m4_t vloadhff_i64m4 (const int16_t *base);
vint64m8_t vloadhff_i64m8 (const int16_t *base);
vuint16m1_t vloadhff_u16m1 (const uint16_t *base);
vuint16m2_t vloadhff_u16m2 (const uint16_t *base);
vuint16m4_t vloadhff_u16m4 (const uint16_t *base);
vuint16m8_t vloadhff_u16m8 (const uint16_t *base);
vuint32m1_t vloadhff_u32m1 (const uint16_t *base);
vuint32m2_t vloadhff_u32m2 (const uint16_t *base);
vuint32m4_t vloadhff_u32m4 (const uint16_t *base);
vuint32m8_t vloadhff_u32m8 (const uint16_t *base);
vuint64m1_t vloadhff_u64m1 (const uint16_t *base);
vuint64m2_t vloadhff_u64m2 (const uint16_t *base);
vuint64m4_t vloadhff_u64m4 (const uint16_t *base);
vuint64m8_t vloadhff_u64m8 (const uint16_t *base);
vint32m1_t vloadwff_i32m1 (const int32_t *base);
vint32m2_t vloadwff_i32m2 (const int32_t *base);
vint32m4_t vloadwff_i32m4 (const int32_t *base);
vint32m8_t vloadwff_i32m8 (const int32_t *base);
vint64m1_t vloadwff_i64m1 (const int32_t *base);
vint64m2_t vloadwff_i64m2 (const int32_t *base);
vint64m4_t vloadwff_i64m4 (const int32_t *base);
vint64m8_t vloadwff_i64m8 (const int32_t *base);
vuint32m1_t vloadwff_u32m1 (const uint32_t *base);
vuint32m2_t vloadwff_u32m2 (const uint32_t *base);
vuint32m4_t vloadwff_u32m4 (const uint32_t *base);
vuint32m8_t vloadwff_u32m8 (const uint32_t *base);
vuint64m1_t vloadwff_u64m1 (const uint32_t *base);
vuint64m2_t vloadwff_u64m2 (const uint32_t *base);
vuint64m4_t vloadwff_u64m4 (const uint32_t *base);
vuint64m8_t vloadwff_u64m8 (const uint32_t *base);
vint8m1_t vloadff_i8m1 (const int8_t *base);
vint8m2_t vloadff_i8m2 (const int8_t *base);
vint8m4_t vloadff_i8m4 (const int8_t *base);
vint8m8_t vloadff_i8m8 (const int8_t *base);
vint16m1_t vloadff_i16m1 (const int16_t *base);
vint16m2_t vloadff_i16m2 (const int16_t *base);
vint16m4_t vloadff_i16m4 (const int16_t *base);
vint16m8_t vloadff_i16m8 (const int16_t *base);
vint32m1_t vloadff_i32m1 (const int32_t *base);
vint32m2_t vloadff_i32m2 (const int32_t *base);
vint32m4_t vloadff_i32m4 (const int32_t *base);
vint32m8_t vloadff_i32m8 (const int32_t *base);
vint64m1_t vloadff_i64m1 (const int64_t *base);
vint64m2_t vloadff_i64m2 (const int64_t *base);
vint64m4_t vloadff_i64m4 (const int64_t *base);
vint64m8_t vloadff_i64m8 (const int64_t *base);
vuint8m1_t vloadff_u8m1 (const uint8_t *base);
vuint8m2_t vloadff_u8m2 (const uint8_t *base);
vuint8m4_t vloadff_u8m4 (const uint8_t *base);
vuint8m8_t vloadff_u8m8 (const uint8_t *base);
vuint16m1_t vloadff_u16m1 (const uint16_t *base);
vuint16m2_t vloadff_u16m2 (const uint16_t *base);
vuint16m4_t vloadff_u16m4 (const uint16_t *base);
vuint16m8_t vloadff_u16m8 (const uint16_t *base);
vuint32m1_t vloadff_u32m1 (const uint32_t *base);
vuint32m2_t vloadff_u32m2 (const uint32_t *base);
vuint32m4_t vloadff_u32m4 (const uint32_t *base);
vuint32m8_t vloadff_u32m8 (const uint32_t *base);
vuint64m1_t vloadff_u64m1 (const uint64_t *base);
vuint64m2_t vloadff_u64m2 (const uint64_t *base);
vuint64m4_t vloadff_u64m4 (const uint64_t *base);
vuint64m8_t vloadff_u64m8 (const uint64_t *base);
vfloat16m1_t vloadff_f16m1 (const float16_t *base);
vfloat16m2_t vloadff_f16m2 (const float16_t *base);
vfloat16m4_t vloadff_f16m4 (const float16_t *base);
vfloat16m8_t vloadff_f16m8 (const float16_t *base);
vfloat32m1_t vloadff_f32m1 (const float32_t *base);
vfloat32m2_t vloadff_f32m2 (const float32_t *base);
vfloat32m4_t vloadff_f32m4 (const float32_t *base);
vfloat32m8_t vloadff_f32m8 (const float32_t *base);
vfloat64m1_t vloadff_f64m1 (const float64_t *base);
vfloat64m2_t vloadff_f64m2 (const float64_t *base);
vfloat64m4_t vloadff_f64m4 (const float64_t *base);
vfloat64m8_t vloadff_f64m8 (const float64_t *base);
// masked functions
vint8m1_t vloadbff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadbff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadbff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadbff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadbff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int8_t *base);
vint16m2_t vloadbff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int8_t *base);
vint16m4_t vloadbff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int8_t *base);
vint16m8_t vloadbff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int8_t *base);
vint32m1_t vloadbff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int8_t *base);
vint32m2_t vloadbff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int8_t *base);
vint32m4_t vloadbff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int8_t *base);
vint32m8_t vloadbff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int8_t *base);
vint64m1_t vloadbff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int8_t *base);
vint64m2_t vloadbff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int8_t *base);
vint64m4_t vloadbff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int8_t *base);
vint64m8_t vloadbff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int8_t *base);
vuint8m1_t vloadbff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadbff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadbff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadbff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadbff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint8_t *base);
vuint16m2_t vloadbff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint8_t *base);
vuint16m4_t vloadbff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint8_t *base);
vuint16m8_t vloadbff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint8_t *base);
vuint32m1_t vloadbff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint8_t *base);
vuint32m2_t vloadbff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint8_t *base);
vuint32m4_t vloadbff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint8_t *base);
vuint32m8_t vloadbff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint8_t *base);
vuint64m1_t vloadbff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint8_t *base);
vuint64m2_t vloadbff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint8_t *base);
vuint64m4_t vloadbff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint8_t *base);
vuint64m8_t vloadbff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint8_t *base);
vint16m1_t vloadhff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadhff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadhff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadhff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadhff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int16_t *base);
vint32m2_t vloadhff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int16_t *base);
vint32m4_t vloadhff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int16_t *base);
vint32m8_t vloadhff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int16_t *base);
vint64m1_t vloadhff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int16_t *base);
vint64m2_t vloadhff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int16_t *base);
vint64m4_t vloadhff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int16_t *base);
vint64m8_t vloadhff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int16_t *base);
vuint16m1_t vloadhff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadhff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadhff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadhff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadhff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint16_t *base);
vuint32m2_t vloadhff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint16_t *base);
vuint32m4_t vloadhff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint16_t *base);
vuint32m8_t vloadhff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint16_t *base);
vuint64m1_t vloadhff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint16_t *base);
vuint64m2_t vloadhff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint16_t *base);
vuint64m4_t vloadhff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint16_t *base);
vuint64m8_t vloadhff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint16_t *base);
vint32m1_t vloadwff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadwff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadwff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadwff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadwff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int32_t *base);
vint64m2_t vloadwff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int32_t *base);
vint64m4_t vloadwff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int32_t *base);
vint64m8_t vloadwff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int32_t *base);
vuint32m1_t vloadwff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadwff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadwff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadwff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadwff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint32_t *base);
vuint64m2_t vloadwff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint32_t *base);
vuint64m4_t vloadwff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint32_t *base);
vuint64m8_t vloadwff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint32_t *base);
vint8m1_t vloadff_i8m1_mask (vbool8_t mask, vint8m1_t maskedoff, const int8_t *base);
vint8m2_t vloadff_i8m2_mask (vbool4_t mask, vint8m2_t maskedoff, const int8_t *base);
vint8m4_t vloadff_i8m4_mask (vbool2_t mask, vint8m4_t maskedoff, const int8_t *base);
vint8m8_t vloadff_i8m8_mask (vbool1_t mask, vint8m8_t maskedoff, const int8_t *base);
vint16m1_t vloadff_i16m1_mask (vbool16_t mask, vint16m1_t maskedoff, const int16_t *base);
vint16m2_t vloadff_i16m2_mask (vbool8_t mask, vint16m2_t maskedoff, const int16_t *base);
vint16m4_t vloadff_i16m4_mask (vbool4_t mask, vint16m4_t maskedoff, const int16_t *base);
vint16m8_t vloadff_i16m8_mask (vbool2_t mask, vint16m8_t maskedoff, const int16_t *base);
vint32m1_t vloadff_i32m1_mask (vbool32_t mask, vint32m1_t maskedoff, const int32_t *base);
vint32m2_t vloadff_i32m2_mask (vbool16_t mask, vint32m2_t maskedoff, const int32_t *base);
vint32m4_t vloadff_i32m4_mask (vbool8_t mask, vint32m4_t maskedoff, const int32_t *base);
vint32m8_t vloadff_i32m8_mask (vbool4_t mask, vint32m8_t maskedoff, const int32_t *base);
vint64m1_t vloadff_i64m1_mask (vbool64_t mask, vint64m1_t maskedoff, const int64_t *base);
vint64m2_t vloadff_i64m2_mask (vbool32_t mask, vint64m2_t maskedoff, const int64_t *base);
vint64m4_t vloadff_i64m4_mask (vbool16_t mask, vint64m4_t maskedoff, const int64_t *base);
vint64m8_t vloadff_i64m8_mask (vbool8_t mask, vint64m8_t maskedoff, const int64_t *base);
vuint8m1_t vloadff_u8m1_mask (vbool8_t mask, vuint8m1_t maskedoff, const uint8_t *base);
vuint8m2_t vloadff_u8m2_mask (vbool4_t mask, vuint8m2_t maskedoff, const uint8_t *base);
vuint8m4_t vloadff_u8m4_mask (vbool2_t mask, vuint8m4_t maskedoff, const uint8_t *base);
vuint8m8_t vloadff_u8m8_mask (vbool1_t mask, vuint8m8_t maskedoff, const uint8_t *base);
vuint16m1_t vloadff_u16m1_mask (vbool16_t mask, vuint16m1_t maskedoff, const uint16_t *base);
vuint16m2_t vloadff_u16m2_mask (vbool8_t mask, vuint16m2_t maskedoff, const uint16_t *base);
vuint16m4_t vloadff_u16m4_mask (vbool4_t mask, vuint16m4_t maskedoff, const uint16_t *base);
vuint16m8_t vloadff_u16m8_mask (vbool2_t mask, vuint16m8_t maskedoff, const uint16_t *base);
vuint32m1_t vloadff_u32m1_mask (vbool32_t mask, vuint32m1_t maskedoff, const uint32_t *base);
vuint32m2_t vloadff_u32m2_mask (vbool16_t mask, vuint32m2_t maskedoff, const uint32_t *base);
vuint32m4_t vloadff_u32m4_mask (vbool8_t mask, vuint32m4_t maskedoff, const uint32_t *base);
vuint32m8_t vloadff_u32m8_mask (vbool4_t mask, vuint32m8_t maskedoff, const uint32_t *base);
vuint64m1_t vloadff_u64m1_mask (vbool64_t mask, vuint64m1_t maskedoff, const uint64_t *base);
vuint64m2_t vloadff_u64m2_mask (vbool32_t mask, vuint64m2_t maskedoff, const uint64_t *base);
vuint64m4_t vloadff_u64m4_mask (vbool16_t mask, vuint64m4_t maskedoff, const uint64_t *base);
vuint64m8_t vloadff_u64m8_mask (vbool8_t mask, vuint64m8_t maskedoff, const uint64_t *base);
vfloat16m1_t vloadff_f16m1_mask (vbool16_t mask, vfloat16m1_t maskedoff, const float16_t *base);
vfloat16m2_t vloadff_f16m2_mask (vbool8_t mask, vfloat16m2_t maskedoff, const float16_t *base);
vfloat16m4_t vloadff_f16m4_mask (vbool4_t mask, vfloat16m4_t maskedoff, const float16_t *base);
vfloat16m8_t vloadff_f16m8_mask (vbool2_t mask, vfloat16m8_t maskedoff, const float16_t *base);
vfloat32m1_t vloadff_f32m1_mask (vbool32_t mask, vfloat32m1_t maskedoff, const float32_t *base);
vfloat32m2_t vloadff_f32m2_mask (vbool16_t mask, vfloat32m2_t maskedoff, const float32_t *base);
vfloat32m4_t vloadff_f32m4_mask (vbool8_t mask, vfloat32m4_t maskedoff, const float32_t *base);
vfloat32m8_t vloadff_f32m8_mask (vbool4_t mask, vfloat32m8_t maskedoff, const float32_t *base);
vfloat64m1_t vloadff_f64m1_mask (vbool64_t mask, vfloat64m1_t maskedoff, const float64_t *base);
vfloat64m2_t vloadff_f64m2_mask (vbool32_t mask, vfloat64m2_t maskedoff, const float64_t *base);
vfloat64m4_t vloadff_f64m4_mask (vbool16_t mask, vfloat64m4_t maskedoff, const float64_t *base);
vfloat64m8_t vloadff_f64m8_mask (vbool8_t mask, vfloat64m8_t maskedoff, const float64_t *base);
```
## Vector Integer Arithmetic Functions:

### Vector Single-Width Integer Add and Subtract Functions:

**Prototypes:**
``` C
vint8m1_t vadd[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vadd[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vadd[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vadd[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vadd[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vadd[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vadd[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vadd[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vadd[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vadd[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vadd[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vadd[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vadd[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vadd[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vadd[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vadd[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vadd[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsub[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsub[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsub[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsub[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsub[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsub[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsub[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsub[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsub[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsub[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsub[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsub[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsub[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsub[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsub[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vsub[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vrsub[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vrsub[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vrsub[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vrsub[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vrsub[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vrsub[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vrsub[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vrsub[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vrsub[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vrsub[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vrsub[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vrsub[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vrsub[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vrsub[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vrsub[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vadd[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vadd[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vadd[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vadd[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vadd[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vadd[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vadd[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vadd[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vadd[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vadd[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vadd[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vadd[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vadd[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vadd[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vadd[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vadd[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vadd[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vadd[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vadd[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vadd[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vadd[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vadd[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vadd[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vadd[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vadd[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vadd[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vadd[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vadd[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vadd[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vadd[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vadd[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vadd[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vadd[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vadd[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vadd[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vadd[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vadd[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vadd[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vadd[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vadd[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vadd[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vadd[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vadd[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vadd[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vadd[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vadd[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vadd[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vadd[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vadd[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vadd[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vadd[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vadd[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vadd[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vadd[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vadd[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vadd[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vadd[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vadd[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vadd[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vadd[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vadd[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vadd[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vadd[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vadd[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsub[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsub[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsub[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsub[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsub[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsub[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsub[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsub[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsub[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsub[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsub[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsub[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsub[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsub[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsub[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsub[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsub[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsub[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsub[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsub[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsub[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsub[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsub[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsub[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsub[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsub[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsub[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsub[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsub[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsub[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsub[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsub[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsub[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsub[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsub[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsub[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsub[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsub[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsub[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsub[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsub[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsub[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsub[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsub[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsub[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsub[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsub[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsub[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsub[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsub[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsub[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsub[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsub[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsub[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsub[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsub[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsub[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsub[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsub[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsub[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsub[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsub[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsub[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsub[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrsub[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrsub[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrsub[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrsub[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrsub[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrsub[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrsub[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrsub[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrsub[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrsub[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrsub[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrsub[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrsub[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrsub[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrsub[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrsub[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrsub[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrsub[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrsub[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrsub[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrsub[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrsub[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrsub[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrsub[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrsub[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrsub[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrsub[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrsub[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrsub[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrsub[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrsub[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrsub[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Widening Integer Add/Subtract Functions:

**Prototypes:**
``` C
vint16m2_t vwadd[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint16m2_t vwadd[_wv_i8m1] (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd[_ws_i8m1] (vint16m2_t op1, int8_t op2);
vint16m4_t vwadd[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint16m4_t vwadd[_wv_i8m2] (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd[_ws_i8m2] (vint16m4_t op1, int8_t op2);
vint16m8_t vwadd[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint16m8_t vwadd[_wv_i8m4] (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd[_ws_i8m4] (vint16m8_t op1, int8_t op2);
vint32m2_t vwadd[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint32m2_t vwadd[_wv_i16m1] (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd[_ws_i16m1] (vint32m2_t op1, int16_t op2);
vint32m4_t vwadd[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint32m4_t vwadd[_wv_i16m2] (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd[_ws_i16m2] (vint32m4_t op1, int16_t op2);
vint32m8_t vwadd[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint32m8_t vwadd[_wv_i16m4] (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd[_ws_i16m4] (vint32m8_t op1, int16_t op2);
vint64m2_t vwadd[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint64m2_t vwadd[_wv_i32m1] (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd[_ws_i32m1] (vint64m2_t op1, int32_t op2);
vint64m4_t vwadd[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint64m4_t vwadd[_wv_i32m2] (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd[_ws_i32m2] (vint64m4_t op1, int32_t op2);
vint64m8_t vwadd[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint64m8_t vwadd[_wv_i32m4] (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd[_ws_i32m4] (vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd[_wv_u8m1] (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd[_ws_u8m1] (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd[_wv_u8m2] (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd[_ws_u8m2] (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd[_wv_u8m4] (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd[_ws_u8m4] (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd[_wv_u16m1] (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd[_ws_u16m1] (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd[_wv_u16m2] (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd[_ws_u16m2] (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd[_wv_u16m4] (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd[_ws_u16m4] (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd[_wv_u32m1] (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd[_ws_u32m1] (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd[_wv_u32m2] (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd[_ws_u32m2] (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd[_wv_u32m4] (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd[_ws_u32m4] (vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint16m2_t vwsub[_wv_i8m1] (vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub[_ws_i8m1] (vint16m2_t op1, int8_t op2);
vint16m4_t vwsub[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint16m4_t vwsub[_wv_i8m2] (vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub[_ws_i8m2] (vint16m4_t op1, int8_t op2);
vint16m8_t vwsub[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint16m8_t vwsub[_wv_i8m4] (vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub[_ws_i8m4] (vint16m8_t op1, int8_t op2);
vint32m2_t vwsub[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint32m2_t vwsub[_wv_i16m1] (vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub[_ws_i16m1] (vint32m2_t op1, int16_t op2);
vint32m4_t vwsub[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint32m4_t vwsub[_wv_i16m2] (vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub[_ws_i16m2] (vint32m4_t op1, int16_t op2);
vint32m8_t vwsub[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint32m8_t vwsub[_wv_i16m4] (vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub[_ws_i16m4] (vint32m8_t op1, int16_t op2);
vint64m2_t vwsub[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint64m2_t vwsub[_wv_i32m1] (vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub[_ws_i32m1] (vint64m2_t op1, int32_t op2);
vint64m4_t vwsub[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint64m4_t vwsub[_wv_i32m2] (vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub[_ws_i32m2] (vint64m4_t op1, int32_t op2);
vint64m8_t vwsub[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint64m8_t vwsub[_wv_i32m4] (vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub[_ws_i32m4] (vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub[_wv_u8m1] (vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub[_ws_u8m1] (vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub[_wv_u8m2] (vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub[_ws_u8m2] (vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub[_wv_u8m4] (vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub[_ws_u8m4] (vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub[_wv_u16m1] (vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub[_ws_u16m1] (vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub[_wv_u16m2] (vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub[_ws_u16m2] (vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub[_wv_u16m4] (vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub[_ws_u16m4] (vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub[_wv_u32m1] (vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub[_ws_u32m1] (vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub[_wv_u32m2] (vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub[_ws_u32m2] (vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub[_wv_u32m4] (vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub[_ws_u32m4] (vuint64m8_t op1, uint32_t op2);
// masked functions
vint16m2_t vwadd[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwadd[_vs_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwadd[_wv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwadd[_ws_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwadd[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwadd[_vs_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwadd[_wv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwadd[_ws_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwadd[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwadd[_vs_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwadd[_wv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwadd[_ws_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwadd[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwadd[_vs_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwadd[_wv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwadd[_ws_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwadd[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwadd[_vs_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwadd[_wv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwadd[_ws_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwadd[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwadd[_vs_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwadd[_wv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwadd[_ws_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwadd[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwadd[_vs_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwadd[_wv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwadd[_ws_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwadd[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwadd[_vs_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwadd[_wv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwadd[_ws_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwadd[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwadd[_vs_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwadd[_wv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwadd[_ws_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwadd[_vv_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwadd[_vs_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwadd[_wv_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwadd[_ws_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwadd[_vv_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwadd[_vs_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwadd[_wv_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwadd[_ws_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwadd[_vv_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwadd[_vs_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwadd[_wv_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwadd[_ws_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwadd[_vv_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwadd[_vs_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwadd[_wv_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwadd[_ws_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwadd[_vv_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwadd[_vs_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwadd[_wv_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwadd[_ws_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwadd[_vv_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwadd[_vs_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwadd[_wv_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwadd[_ws_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwadd[_vv_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwadd[_vs_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwadd[_wv_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwadd[_ws_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwadd[_vv_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwadd[_vs_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwadd[_wv_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwadd[_ws_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwadd[_vv_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwadd[_vs_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwadd[_wv_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwadd[_ws_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
vint16m2_t vwsub[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwsub[_vs_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m2_t vwsub[_wv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint16m2_t vwsub[_ws_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int8_t op2);
vint16m4_t vwsub[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwsub[_vs_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m4_t vwsub[_wv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint16m4_t vwsub[_ws_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int8_t op2);
vint16m8_t vwsub[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwsub[_vs_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint16m8_t vwsub[_wv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint16m8_t vwsub[_ws_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int8_t op2);
vint32m2_t vwsub[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwsub[_vs_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m2_t vwsub[_wv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint32m2_t vwsub[_ws_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int16_t op2);
vint32m4_t vwsub[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwsub[_vs_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m4_t vwsub[_wv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint32m4_t vwsub[_ws_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int16_t op2);
vint32m8_t vwsub[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwsub[_vs_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint32m8_t vwsub[_wv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint32m8_t vwsub[_ws_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int16_t op2);
vint64m2_t vwsub[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwsub[_vs_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m2_t vwsub[_wv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint64m2_t vwsub[_ws_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int32_t op2);
vint64m4_t vwsub[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwsub[_vs_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m4_t vwsub[_wv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint64m4_t vwsub[_ws_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int32_t op2);
vint64m8_t vwsub[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwsub[_vs_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vint64m8_t vwsub[_wv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint64m8_t vwsub[_ws_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int32_t op2);
vuint16m2_t vwsub[_vv_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwsub[_vs_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m2_t vwsub[_wv_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint16m2_t vwsub[_ws_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint16m4_t vwsub[_vv_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwsub[_vs_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m4_t vwsub[_wv_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint16m4_t vwsub[_ws_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint16m8_t vwsub[_vv_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwsub[_vs_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint16m8_t vwsub[_wv_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint16m8_t vwsub[_ws_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint32m2_t vwsub[_vv_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwsub[_vs_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m2_t vwsub[_wv_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint32m2_t vwsub[_ws_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint32m4_t vwsub[_vv_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwsub[_vs_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m4_t vwsub[_wv_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint32m4_t vwsub[_ws_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint32m8_t vwsub[_vv_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwsub[_vs_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint32m8_t vwsub[_wv_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint32m8_t vwsub[_ws_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint64m2_t vwsub[_vv_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwsub[_vs_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m2_t vwsub[_wv_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint64m2_t vwsub[_ws_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint64m4_t vwsub[_vv_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwsub[_vs_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m4_t vwsub[_wv_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint64m4_t vwsub[_ws_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint64m8_t vwsub[_vv_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwsub[_vs_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint64m8_t vwsub[_wv_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint64m8_t vwsub[_ws_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
### Vector Integer Add-with-Carry / Subtract-with-Borrow Functions:

**Prototypes:**
``` C
vint8m1_t vadc_vvm[_i8m1] (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vint8m1_t vadc_vsm[_i8m1] (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vint8m2_t vadc_vvm[_i8m2] (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vint8m2_t vadc_vsm[_i8m2] (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vint8m4_t vadc_vvm[_i8m4] (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vint8m4_t vadc_vsm[_i8m4] (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vint8m8_t vadc_vvm[_i8m8] (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vint8m8_t vadc_vsm[_i8m8] (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vint16m1_t vadc_vvm[_i16m1] (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vint16m1_t vadc_vsm[_i16m1] (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vint16m2_t vadc_vvm[_i16m2] (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vint16m2_t vadc_vsm[_i16m2] (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vint16m4_t vadc_vvm[_i16m4] (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vint16m4_t vadc_vsm[_i16m4] (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vint16m8_t vadc_vvm[_i16m8] (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vint16m8_t vadc_vsm[_i16m8] (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vint32m1_t vadc_vvm[_i32m1] (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vint32m1_t vadc_vsm[_i32m1] (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vint32m2_t vadc_vvm[_i32m2] (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vint32m2_t vadc_vsm[_i32m2] (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vint32m4_t vadc_vvm[_i32m4] (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vint32m4_t vadc_vsm[_i32m4] (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vint32m8_t vadc_vvm[_i32m8] (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vint32m8_t vadc_vsm[_i32m8] (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vint64m1_t vadc_vvm[_i64m1] (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vint64m1_t vadc_vsm[_i64m1] (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vint64m2_t vadc_vvm[_i64m2] (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vint64m2_t vadc_vsm[_i64m2] (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vint64m4_t vadc_vvm[_i64m4] (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vint64m4_t vadc_vsm[_i64m4] (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vint64m8_t vadc_vvm[_i64m8] (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vint64m8_t vadc_vsm[_i64m8] (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vuint8m1_t vadc_vvm[_u8m1] (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vuint8m1_t vadc_vsm[_u8m1] (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vuint8m2_t vadc_vvm[_u8m2] (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vuint8m2_t vadc_vsm[_u8m2] (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vuint8m4_t vadc_vvm[_u8m4] (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vuint8m4_t vadc_vsm[_u8m4] (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vuint8m8_t vadc_vvm[_u8m8] (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vuint8m8_t vadc_vsm[_u8m8] (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vuint16m1_t vadc_vvm[_u16m1] (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vuint16m1_t vadc_vsm[_u16m1] (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vuint16m2_t vadc_vvm[_u16m2] (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vuint16m2_t vadc_vsm[_u16m2] (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vuint16m4_t vadc_vvm[_u16m4] (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vuint16m4_t vadc_vsm[_u16m4] (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vuint16m8_t vadc_vvm[_u16m8] (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vuint16m8_t vadc_vsm[_u16m8] (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vuint32m1_t vadc_vvm[_u32m1] (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vuint32m1_t vadc_vsm[_u32m1] (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vuint32m2_t vadc_vvm[_u32m2] (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vuint32m2_t vadc_vsm[_u32m2] (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vuint32m4_t vadc_vvm[_u32m4] (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vuint32m4_t vadc_vsm[_u32m4] (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vuint32m8_t vadc_vvm[_u32m8] (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vuint32m8_t vadc_vsm[_u32m8] (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vuint64m1_t vadc_vvm[_u64m1] (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vuint64m1_t vadc_vsm[_u64m1] (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vuint64m2_t vadc_vvm[_u64m2] (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vuint64m2_t vadc_vsm[_u64m2] (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vuint64m4_t vadc_vvm[_u64m4] (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vuint64m4_t vadc_vsm[_u64m4] (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vuint64m8_t vadc_vvm[_u64m8] (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vuint64m8_t vadc_vsm[_u64m8] (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vvm[_i8m1] (vint8m1_t op1, vint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_i8m1] (vint8m1_t op1, int8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmadc_vs[_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vmadc_vvm[_i8m2] (vint8m2_t op1, vint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_i8m2] (vint8m2_t op1, int8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmadc_vs[_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vmadc_vvm[_i8m4] (vint8m4_t op1, vint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm[_i8m4] (vint8m4_t op1, int8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv[_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmadc_vs[_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vmadc_vvm[_i8m8] (vint8m8_t op1, vint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm[_i8m8] (vint8m8_t op1, int8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv[_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmadc_vs[_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vmadc_vvm[_i16m1] (vint16m1_t op1, vint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_i16m1] (vint16m1_t op1, int16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmadc_vs[_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vmadc_vvm[_i16m2] (vint16m2_t op1, vint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_i16m2] (vint16m2_t op1, int16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmadc_vs[_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vmadc_vvm[_i16m4] (vint16m4_t op1, vint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_i16m4] (vint16m4_t op1, int16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmadc_vs[_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vmadc_vvm[_i16m8] (vint16m8_t op1, vint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm[_i16m8] (vint16m8_t op1, int16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv[_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmadc_vs[_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vmadc_vvm[_i32m1] (vint32m1_t op1, vint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm[_i32m1] (vint32m1_t op1, int32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv[_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmadc_vs[_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vmadc_vvm[_i32m2] (vint32m2_t op1, vint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_i32m2] (vint32m2_t op1, int32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmadc_vs[_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vmadc_vvm[_i32m4] (vint32m4_t op1, vint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_i32m4] (vint32m4_t op1, int32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmadc_vs[_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vmadc_vvm[_i32m8] (vint32m8_t op1, vint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_i32m8] (vint32m8_t op1, int32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmadc_vs[_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vmadc_vvm[_i64m1] (vint64m1_t op1, vint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm[_i64m1] (vint64m1_t op1, int64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv[_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmadc_vs[_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vmadc_vvm[_i64m2] (vint64m2_t op1, vint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm[_i64m2] (vint64m2_t op1, int64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv[_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmadc_vs[_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vmadc_vvm[_i64m4] (vint64m4_t op1, vint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_i64m4] (vint64m4_t op1, int64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmadc_vs[_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vmadc_vvm[_i64m8] (vint64m8_t op1, vint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_i64m8] (vint64m8_t op1, int64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmadc_vs[_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vmadc_vvm[_u8m1] (vuint8m1_t op1, vuint8m1_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_u8m1] (vuint8m1_t op1, uint8_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmadc_vs[_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vmadc_vvm[_u8m2] (vuint8m2_t op1, vuint8m2_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_u8m2] (vuint8m2_t op1, uint8_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmadc_vs[_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vmadc_vvm[_u8m4] (vuint8m4_t op1, vuint8m4_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm[_u8m4] (vuint8m4_t op1, uint8_t op2, vbool2_t carryin);
vbool2_t vmadc_vv[_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmadc_vs[_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vmadc_vvm[_u8m8] (vuint8m8_t op1, vuint8m8_t op2, vbool1_t carryin);
vbool1_t vmadc_vsm[_u8m8] (vuint8m8_t op1, uint8_t op2, vbool1_t carryin);
vbool1_t vmadc_vv[_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmadc_vs[_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vmadc_vvm[_u16m1] (vuint16m1_t op1, vuint16m1_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_u16m1] (vuint16m1_t op1, uint16_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmadc_vs[_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vmadc_vvm[_u16m2] (vuint16m2_t op1, vuint16m2_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_u16m2] (vuint16m2_t op1, uint16_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmadc_vs[_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vmadc_vvm[_u16m4] (vuint16m4_t op1, vuint16m4_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_u16m4] (vuint16m4_t op1, uint16_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmadc_vs[_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vmadc_vvm[_u16m8] (vuint16m8_t op1, vuint16m8_t op2, vbool2_t carryin);
vbool2_t vmadc_vsm[_u16m8] (vuint16m8_t op1, uint16_t op2, vbool2_t carryin);
vbool2_t vmadc_vv[_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmadc_vs[_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vmadc_vvm[_u32m1] (vuint32m1_t op1, vuint32m1_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm[_u32m1] (vuint32m1_t op1, uint32_t op2, vbool32_t carryin);
vbool32_t vmadc_vv[_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmadc_vs[_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vmadc_vvm[_u32m2] (vuint32m2_t op1, vuint32m2_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_u32m2] (vuint32m2_t op1, uint32_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmadc_vs[_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vmadc_vvm[_u32m4] (vuint32m4_t op1, vuint32m4_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_u32m4] (vuint32m4_t op1, uint32_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmadc_vs[_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vmadc_vvm[_u32m8] (vuint32m8_t op1, vuint32m8_t op2, vbool4_t carryin);
vbool4_t vmadc_vsm[_u32m8] (vuint32m8_t op1, uint32_t op2, vbool4_t carryin);
vbool4_t vmadc_vv[_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmadc_vs[_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vmadc_vvm[_u64m1] (vuint64m1_t op1, vuint64m1_t op2, vbool64_t carryin);
vbool64_t vmadc_vsm[_u64m1] (vuint64m1_t op1, uint64_t op2, vbool64_t carryin);
vbool64_t vmadc_vv[_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmadc_vs[_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vmadc_vvm[_u64m2] (vuint64m2_t op1, vuint64m2_t op2, vbool32_t carryin);
vbool32_t vmadc_vsm[_u64m2] (vuint64m2_t op1, uint64_t op2, vbool32_t carryin);
vbool32_t vmadc_vv[_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmadc_vs[_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vmadc_vvm[_u64m4] (vuint64m4_t op1, vuint64m4_t op2, vbool16_t carryin);
vbool16_t vmadc_vsm[_u64m4] (vuint64m4_t op1, uint64_t op2, vbool16_t carryin);
vbool16_t vmadc_vv[_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmadc_vs[_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vmadc_vvm[_u64m8] (vuint64m8_t op1, vuint64m8_t op2, vbool8_t carryin);
vbool8_t vmadc_vsm[_u64m8] (vuint64m8_t op1, uint64_t op2, vbool8_t carryin);
vbool8_t vmadc_vv[_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmadc_vs[_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsbc_vvm[_i8m1] (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vint8m1_t vsbc_vsm[_i8m1] (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vint8m2_t vsbc_vvm[_i8m2] (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vint8m2_t vsbc_vsm[_i8m2] (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vint8m4_t vsbc_vvm[_i8m4] (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vint8m4_t vsbc_vsm[_i8m4] (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vint8m8_t vsbc_vvm[_i8m8] (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vint8m8_t vsbc_vsm[_i8m8] (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vint16m1_t vsbc_vvm[_i16m1] (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vint16m1_t vsbc_vsm[_i16m1] (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vint16m2_t vsbc_vvm[_i16m2] (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vint16m2_t vsbc_vsm[_i16m2] (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vint16m4_t vsbc_vvm[_i16m4] (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vint16m4_t vsbc_vsm[_i16m4] (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vint16m8_t vsbc_vvm[_i16m8] (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vint16m8_t vsbc_vsm[_i16m8] (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vint32m1_t vsbc_vvm[_i32m1] (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vint32m1_t vsbc_vsm[_i32m1] (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vint32m2_t vsbc_vvm[_i32m2] (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vint32m2_t vsbc_vsm[_i32m2] (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vint32m4_t vsbc_vvm[_i32m4] (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vint32m4_t vsbc_vsm[_i32m4] (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vint32m8_t vsbc_vvm[_i32m8] (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vint32m8_t vsbc_vsm[_i32m8] (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vint64m1_t vsbc_vvm[_i64m1] (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vint64m1_t vsbc_vsm[_i64m1] (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vint64m2_t vsbc_vvm[_i64m2] (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vint64m2_t vsbc_vsm[_i64m2] (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vint64m4_t vsbc_vvm[_i64m4] (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vint64m4_t vsbc_vsm[_i64m4] (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vint64m8_t vsbc_vvm[_i64m8] (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vint64m8_t vsbc_vsm[_i64m8] (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vvm[_u8m1] (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vuint8m1_t vsbc_vsm[_u8m1] (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vuint8m2_t vsbc_vvm[_u8m2] (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vuint8m2_t vsbc_vsm[_u8m2] (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vuint8m4_t vsbc_vvm[_u8m4] (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vuint8m4_t vsbc_vsm[_u8m4] (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vuint8m8_t vsbc_vvm[_u8m8] (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vuint8m8_t vsbc_vsm[_u8m8] (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vuint16m1_t vsbc_vvm[_u16m1] (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vuint16m1_t vsbc_vsm[_u16m1] (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vuint16m2_t vsbc_vvm[_u16m2] (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vuint16m2_t vsbc_vsm[_u16m2] (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vuint16m4_t vsbc_vvm[_u16m4] (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vuint16m4_t vsbc_vsm[_u16m4] (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vuint16m8_t vsbc_vvm[_u16m8] (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vuint16m8_t vsbc_vsm[_u16m8] (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vuint32m1_t vsbc_vvm[_u32m1] (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vuint32m1_t vsbc_vsm[_u32m1] (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vuint32m2_t vsbc_vvm[_u32m2] (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vuint32m2_t vsbc_vsm[_u32m2] (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vuint32m4_t vsbc_vvm[_u32m4] (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vuint32m4_t vsbc_vsm[_u32m4] (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vuint32m8_t vsbc_vvm[_u32m8] (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vuint32m8_t vsbc_vsm[_u32m8] (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vuint64m1_t vsbc_vvm[_u64m1] (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vuint64m1_t vsbc_vsm[_u64m1] (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vuint64m2_t vsbc_vvm[_u64m2] (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vuint64m2_t vsbc_vsm[_u64m2] (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vuint64m4_t vsbc_vvm[_u64m4] (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vuint64m4_t vsbc_vsm[_u64m4] (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vuint64m8_t vsbc_vvm[_u64m8] (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vuint64m8_t vsbc_vsm[_u64m8] (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vvm[_i8m1] (vint8m1_t op1, vint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_i8m1] (vint8m1_t op1, int8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vmsbc_vs[_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vmsbc_vvm[_i8m2] (vint8m2_t op1, vint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_i8m2] (vint8m2_t op1, int8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vmsbc_vs[_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vmsbc_vvm[_i8m4] (vint8m4_t op1, vint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm[_i8m4] (vint8m4_t op1, int8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv[_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vmsbc_vs[_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vmsbc_vvm[_i8m8] (vint8m8_t op1, vint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm[_i8m8] (vint8m8_t op1, int8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv[_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vmsbc_vs[_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vmsbc_vvm[_i16m1] (vint16m1_t op1, vint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_i16m1] (vint16m1_t op1, int16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vmsbc_vs[_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vmsbc_vvm[_i16m2] (vint16m2_t op1, vint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_i16m2] (vint16m2_t op1, int16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vmsbc_vs[_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vmsbc_vvm[_i16m4] (vint16m4_t op1, vint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_i16m4] (vint16m4_t op1, int16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vmsbc_vs[_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vmsbc_vvm[_i16m8] (vint16m8_t op1, vint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm[_i16m8] (vint16m8_t op1, int16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv[_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vmsbc_vs[_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vmsbc_vvm[_i32m1] (vint32m1_t op1, vint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm[_i32m1] (vint32m1_t op1, int32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv[_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vmsbc_vs[_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vmsbc_vvm[_i32m2] (vint32m2_t op1, vint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_i32m2] (vint32m2_t op1, int32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vmsbc_vs[_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vmsbc_vvm[_i32m4] (vint32m4_t op1, vint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_i32m4] (vint32m4_t op1, int32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vmsbc_vs[_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vmsbc_vvm[_i32m8] (vint32m8_t op1, vint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_i32m8] (vint32m8_t op1, int32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vmsbc_vs[_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vmsbc_vvm[_i64m1] (vint64m1_t op1, vint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm[_i64m1] (vint64m1_t op1, int64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv[_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vmsbc_vs[_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vmsbc_vvm[_i64m2] (vint64m2_t op1, vint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm[_i64m2] (vint64m2_t op1, int64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv[_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vmsbc_vs[_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vmsbc_vvm[_i64m4] (vint64m4_t op1, vint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_i64m4] (vint64m4_t op1, int64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vmsbc_vs[_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vmsbc_vvm[_i64m8] (vint64m8_t op1, vint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_i64m8] (vint64m8_t op1, int64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vmsbc_vs[_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vmsbc_vvm[_u8m1] (vuint8m1_t op1, vuint8m1_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_u8m1] (vuint8m1_t op1, uint8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vmsbc_vs[_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vmsbc_vvm[_u8m2] (vuint8m2_t op1, vuint8m2_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_u8m2] (vuint8m2_t op1, uint8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vmsbc_vs[_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vmsbc_vvm[_u8m4] (vuint8m4_t op1, vuint8m4_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm[_u8m4] (vuint8m4_t op1, uint8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv[_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vmsbc_vs[_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vmsbc_vvm[_u8m8] (vuint8m8_t op1, vuint8m8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vsm[_u8m8] (vuint8m8_t op1, uint8_t op2, vbool1_t borrowin);
vbool1_t vmsbc_vv[_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vmsbc_vs[_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vmsbc_vvm[_u16m1] (vuint16m1_t op1, vuint16m1_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_u16m1] (vuint16m1_t op1, uint16_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vmsbc_vs[_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vmsbc_vvm[_u16m2] (vuint16m2_t op1, vuint16m2_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_u16m2] (vuint16m2_t op1, uint16_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vmsbc_vs[_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vmsbc_vvm[_u16m4] (vuint16m4_t op1, vuint16m4_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_u16m4] (vuint16m4_t op1, uint16_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vmsbc_vs[_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vmsbc_vvm[_u16m8] (vuint16m8_t op1, vuint16m8_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vsm[_u16m8] (vuint16m8_t op1, uint16_t op2, vbool2_t borrowin);
vbool2_t vmsbc_vv[_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vmsbc_vs[_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vmsbc_vvm[_u32m1] (vuint32m1_t op1, vuint32m1_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm[_u32m1] (vuint32m1_t op1, uint32_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv[_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vmsbc_vs[_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vmsbc_vvm[_u32m2] (vuint32m2_t op1, vuint32m2_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_u32m2] (vuint32m2_t op1, uint32_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vmsbc_vs[_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vmsbc_vvm[_u32m4] (vuint32m4_t op1, vuint32m4_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_u32m4] (vuint32m4_t op1, uint32_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vmsbc_vs[_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vmsbc_vvm[_u32m8] (vuint32m8_t op1, vuint32m8_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vsm[_u32m8] (vuint32m8_t op1, uint32_t op2, vbool4_t borrowin);
vbool4_t vmsbc_vv[_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vmsbc_vs[_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vmsbc_vvm[_u64m1] (vuint64m1_t op1, vuint64m1_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vsm[_u64m1] (vuint64m1_t op1, uint64_t op2, vbool64_t borrowin);
vbool64_t vmsbc_vv[_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vmsbc_vs[_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vmsbc_vvm[_u64m2] (vuint64m2_t op1, vuint64m2_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vsm[_u64m2] (vuint64m2_t op1, uint64_t op2, vbool32_t borrowin);
vbool32_t vmsbc_vv[_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vmsbc_vs[_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vmsbc_vvm[_u64m4] (vuint64m4_t op1, vuint64m4_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vsm[_u64m4] (vuint64m4_t op1, uint64_t op2, vbool16_t borrowin);
vbool16_t vmsbc_vv[_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vmsbc_vs[_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vmsbc_vvm[_u64m8] (vuint64m8_t op1, vuint64m8_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vsm[_u64m8] (vuint64m8_t op1, uint64_t op2, vbool8_t borrowin);
vbool8_t vmsbc_vv[_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vmsbc_vs[_u64m8] (vuint64m8_t op1, uint64_t op2);
```
### Vector Bitwise Logical Functions:

**Prototypes:**
``` C
vint8m1_t vand[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vand[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vand[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vand[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vand[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vand[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vand[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vand[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vand[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vand[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vand[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vand[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vand[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vand[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vand[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vand[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vand[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vand[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vand[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vand[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vand[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vand[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vand[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vand[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vand[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vand[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vand[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vand[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vand[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vand[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vand[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vand[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vand[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vor[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vor[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vor[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vor[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vor[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vor[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vor[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vor[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vor[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vor[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vor[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vor[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vor[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vor[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vor[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vor[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vor[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vor[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vor[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vor[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vor[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vor[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vor[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vor[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vor[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vor[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vor[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vor[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vor[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vor[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vor[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vor[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vor[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vxor[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vxor[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vxor[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vxor[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vxor[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vxor[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vxor[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vxor[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vxor[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vxor[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vxor[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vxor[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vxor[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vxor[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vxor[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vxor[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vxor[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vxor[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vxor[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vxor[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vxor[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vxor[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vxor[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vxor[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vxor[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vxor[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vxor[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vxor[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vxor[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vxor[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vxor[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vxor[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vxor[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vand[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vand[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vand[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vand[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vand[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vand[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vand[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vand[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vand[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vand[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vand[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vand[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vand[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vand[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vand[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vand[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vand[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vand[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vand[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vand[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vand[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vand[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vand[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vand[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vand[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vand[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vand[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vand[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vand[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vand[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vand[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vand[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vand[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vand[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vand[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vand[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vand[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vand[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vand[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vand[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vand[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vand[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vand[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vand[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vand[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vand[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vand[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vand[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vand[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vand[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vand[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vand[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vand[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vand[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vand[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vand[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vand[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vand[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vand[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vand[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vand[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vand[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vand[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vand[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vor[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vor[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vor[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vor[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vor[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vor[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vor[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vor[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vor[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vor[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vor[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vor[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vor[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vor[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vor[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vor[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vor[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vor[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vor[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vor[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vor[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vor[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vor[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vor[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vor[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vor[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vor[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vor[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vor[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vor[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vor[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vor[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vor[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vor[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vor[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vor[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vor[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vor[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vor[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vor[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vor[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vor[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vor[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vor[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vor[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vor[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vor[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vor[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vor[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vor[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vor[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vor[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vor[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vor[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vor[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vor[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vor[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vor[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vor[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vor[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vor[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vor[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vor[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vor[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vxor[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vxor[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vxor[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vxor[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vxor[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vxor[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vxor[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vxor[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vxor[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vxor[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vxor[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vxor[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vxor[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vxor[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vxor[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vxor[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vxor[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vxor[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vxor[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vxor[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vxor[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vxor[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vxor[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vxor[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vxor[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vxor[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vxor[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vxor[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vxor[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vxor[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vxor[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vxor[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vxor[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vxor[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vxor[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vxor[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vxor[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vxor[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vxor[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vxor[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vxor[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vxor[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vxor[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vxor[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vxor[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vxor[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vxor[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vxor[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vxor[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vxor[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vxor[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vxor[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vxor[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vxor[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vxor[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vxor[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vxor[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vxor[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vxor[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vxor[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vxor[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vxor[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vxor[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vxor[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Single-Width Bit Shift Functions:

**Prototypes:**
``` C
vint8m1_t vsll[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsll[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsll[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsll[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsll[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsll[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsll[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsll[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsll[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsll[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsll[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsll[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsll[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsll[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsll[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsll[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsll[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsll[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsll[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsll[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsll[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsll[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsll[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsll[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsll[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsll[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsll[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsll[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsll[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsll[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsll[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsll[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vsll[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsll[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsll[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsll[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsll[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsll[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsll[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsll[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsll[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsll[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsll[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsll[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsll[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsll[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsll[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsll[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsll[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsll[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsll[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsll[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsll[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsll[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsll[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsll[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsrl[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsrl[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsrl[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsrl[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsrl[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsrl[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsrl[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsrl[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsrl[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsrl[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsrl[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsrl[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsrl[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsrl[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsrl[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsrl[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsrl[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsrl[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsrl[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsrl[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsrl[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsrl[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsrl[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsrl[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsrl[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsrl[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsrl[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsrl[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsrl[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsrl[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsrl[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsrl[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vsrl[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsrl[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsrl[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsrl[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsrl[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsrl[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsrl[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsrl[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsrl[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsrl[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsrl[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsrl[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsrl[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsrl[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsrl[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsrl[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsrl[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsrl[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsrl[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsrl[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsrl[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsrl[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsrl[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsrl[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vsra[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsra[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsra[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsra[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsra[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsra[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsra[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsra[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsra[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsra[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsra[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsra[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsra[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsra[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsra[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsra[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsra[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsra[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsra[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsra[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsra[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsra[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsra[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsra[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsra[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsra[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsra[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsra[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsra[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsra[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsra[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsra[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vsra[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsra[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsra[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsra[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsra[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsra[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsra[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsra[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsra[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsra[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsra[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsra[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsra[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsra[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsra[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsra[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsra[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsra[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsra[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsra[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsra[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsra[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsra[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsra[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsra[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsra[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsra[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsra[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsra[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsra[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsra[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsra[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vsll[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsll[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsll[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsll[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsll[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsll[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsll[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsll[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsll[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsll[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsll[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsll[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsll[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsll[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsll[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsll[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsll[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsll[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsll[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsll[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsll[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsll[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsll[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsll[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsll[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsll[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsll[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsll[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsll[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsll[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsll[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsll[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsll[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsll[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsll[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsll[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsll[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsll[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsll[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsll[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsll[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsll[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsll[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsll[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsll[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsll[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsll[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsll[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsll[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsll[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsll[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsll[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsll[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsll[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsll[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsll[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsll[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsll[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsll[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsll[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsll[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsll[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsll[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsll[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsrl[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsrl[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsrl[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsrl[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsrl[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsrl[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsrl[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsrl[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsrl[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsrl[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsrl[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsrl[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsrl[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsrl[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsrl[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsrl[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsrl[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsrl[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsrl[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsrl[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsrl[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsrl[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsrl[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsrl[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsrl[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsrl[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsrl[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsrl[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsrl[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsrl[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsrl[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsrl[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsrl[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsrl[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsrl[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsrl[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsrl[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsrl[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsrl[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsrl[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsrl[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsrl[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsrl[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsrl[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsrl[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsrl[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsrl[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsrl[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsrl[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsrl[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsrl[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsrl[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsrl[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsrl[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsrl[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsrl[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsrl[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsrl[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsrl[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsrl[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsrl[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsrl[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsrl[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsrl[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vsra[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsra[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsra[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsra[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsra[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsra[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsra[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsra[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsra[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsra[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsra[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsra[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsra[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsra[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsra[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsra[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsra[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsra[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsra[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsra[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsra[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsra[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsra[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsra[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsra[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsra[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsra[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsra[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsra[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsra[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsra[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsra[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsra[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsra[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsra[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsra[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsra[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsra[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsra[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsra[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsra[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsra[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsra[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsra[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsra[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsra[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsra[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsra[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsra[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsra[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsra[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsra[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsra[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsra[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsra[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsra[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsra[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsra[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsra[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsra[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsra[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsra[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsra[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsra[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Narrowing Integer Right Shift Functions:

**Prototypes:**
``` C
vuint8m1_t vnsrl[_wv_u16m2] (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl[_ws_u16m2] (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl[_wv_u16m4] (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl[_ws_u16m4] (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl[_wv_u16m8] (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl[_ws_u16m8] (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl[_wv_u32m2] (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnsrl[_ws_u32m2] (vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnsrl[_wv_u32m4] (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnsrl[_ws_u32m4] (vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnsrl[_wv_u32m8] (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnsrl[_ws_u32m8] (vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnsrl[_wv_u64m2] (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnsrl[_ws_u64m2] (vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnsrl[_wv_u64m4] (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnsrl[_ws_u64m4] (vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnsrl[_wv_u64m8] (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnsrl[_ws_u64m8] (vuint64m8_t op1, uint32_t op2);
vint8m1_t vnsra[_wv_i16m2] (vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnsra[_ws_i16m2] (vint16m2_t op1, int8_t op2);
vint8m2_t vnsra[_wv_i16m4] (vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnsra[_ws_i16m4] (vint16m4_t op1, int8_t op2);
vint8m4_t vnsra[_wv_i16m8] (vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnsra[_ws_i16m8] (vint16m8_t op1, int8_t op2);
vint16m1_t vnsra[_wv_i32m2] (vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnsra[_ws_i32m2] (vint32m2_t op1, int16_t op2);
vint16m2_t vnsra[_wv_i32m4] (vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnsra[_ws_i32m4] (vint32m4_t op1, int16_t op2);
vint16m4_t vnsra[_wv_i32m8] (vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnsra[_ws_i32m8] (vint32m8_t op1, int16_t op2);
vint32m1_t vnsra[_wv_i64m2] (vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnsra[_ws_i64m2] (vint64m2_t op1, int32_t op2);
vint32m2_t vnsra[_wv_i64m4] (vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnsra[_ws_i64m4] (vint64m4_t op1, int32_t op2);
vint32m4_t vnsra[_wv_i64m8] (vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnsra[_ws_i64m8] (vint64m8_t op1, int32_t op2);
// masked functions
vuint8m1_t vnsrl[_wv_u16m2]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnsrl[_ws_u16m2]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnsrl[_wv_u16m4]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnsrl[_ws_u16m4]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnsrl[_wv_u16m8]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnsrl[_ws_u16m8]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnsrl[_wv_u32m2]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnsrl[_ws_u32m2]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnsrl[_wv_u32m4]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnsrl[_ws_u32m4]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnsrl[_wv_u32m8]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnsrl[_ws_u32m8]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnsrl[_wv_u64m2]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnsrl[_ws_u64m2]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnsrl[_wv_u64m4]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnsrl[_ws_u64m4]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnsrl[_wv_u64m8]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnsrl[_ws_u64m8]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint32_t op2);
vint8m1_t vnsra[_wv_i16m2]_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnsra[_ws_i16m2]_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, int8_t op2);
vint8m2_t vnsra[_wv_i16m4]_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnsra[_ws_i16m4]_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, int8_t op2);
vint8m4_t vnsra[_wv_i16m8]_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnsra[_ws_i16m8]_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, int8_t op2);
vint16m1_t vnsra[_wv_i32m2]_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnsra[_ws_i32m2]_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, int16_t op2);
vint16m2_t vnsra[_wv_i32m4]_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnsra[_ws_i32m4]_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, int16_t op2);
vint16m4_t vnsra[_wv_i32m8]_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnsra[_ws_i32m8]_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, int16_t op2);
vint32m1_t vnsra[_wv_i64m2]_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnsra[_ws_i64m2]_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, int32_t op2);
vint32m2_t vnsra[_wv_i64m4]_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnsra[_ws_i64m4]_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, int32_t op2);
vint32m4_t vnsra[_wv_i64m8]_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnsra[_ws_i64m8]_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, int32_t op2);
```
### Vector Integer Comparison Functions:

**Prototypes:**
``` C
vbool8_t vseteq[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vseteq[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vseteq[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vseteq[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vseteq[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vseteq[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vseteq[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vseteq[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vseteq[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vseteq[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vseteq[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vseteq[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vseteq[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vseteq[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vseteq[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vseteq[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vseteq[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vsetne[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vsetne[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vsetne[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vsetne[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vsetne[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vsetne[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vsetne[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vsetne[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vsetne[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vsetne[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vsetne[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vsetne[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vsetne[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vsetne[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vsetne[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vsetne[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vsetlt[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vsetlt[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vsetlt[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vsetlt[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vsetlt[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vsetlt[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vsetlt[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vsetlt[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vsetlt[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vsetlt[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vsetlt[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vsetlt[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vsetlt[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vsetlt[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vsetlt[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vsetlt[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vsetle[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vsetle[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vsetle[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vsetle[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vsetle[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vsetle[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vsetle[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vsetle[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vsetle[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vsetle[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vsetle[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vsetle[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vsetle[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vsetle[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vsetle[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vsetle[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vsetgt[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vsetgt[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vsetgt[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vsetgt[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vsetgt[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vsetgt[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vsetgt[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vsetgt[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vsetgt[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vsetgt[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vsetgt[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vsetgt[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vsetgt[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vsetgt[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vsetgt[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vsetgt[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vbool4_t vsetge[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vbool2_t vsetge[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vbool1_t vsetge[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vbool16_t vsetge[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vbool8_t vsetge[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vbool4_t vsetge[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vbool2_t vsetge[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vbool32_t vsetge[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vbool16_t vsetge[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vbool8_t vsetge[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vbool4_t vsetge[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vbool64_t vsetge[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vbool32_t vsetge[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vbool16_t vsetge[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vbool8_t vsetge[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vbool8_t vsetge[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vbool8_t vseteq[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vseteq[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vseteq[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vseteq[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vseteq[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vseteq[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vseteq[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vseteq[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vseteq[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vseteq[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vseteq[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vseteq[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vseteq[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vseteq[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vseteq[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vseteq[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vseteq[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vseteq[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vseteq[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vseteq[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vseteq[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vseteq[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vseteq[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vseteq[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vseteq[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vseteq[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vseteq[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vseteq[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vseteq[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vseteq[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vseteq[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vseteq[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vseteq[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vseteq[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vseteq[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vseteq[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vseteq[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vseteq[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vseteq[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vseteq[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vseteq[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vseteq[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vseteq[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vseteq[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vseteq[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vseteq[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vseteq[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vseteq[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vseteq[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vseteq[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vseteq[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vseteq[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vseteq[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vseteq[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vseteq[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vseteq[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vseteq[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vseteq[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vseteq[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vseteq[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vseteq[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vseteq[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vseteq[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vseteq[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetne[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetne[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetne[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetne[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetne[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetne[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetne[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetne[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetne[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetne[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetne[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetne[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetne[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetne[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetne[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetne[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetne[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetne[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetne[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetne[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetne[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetne[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetne[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetne[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetne[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetne[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetne[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetne[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetne[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetne[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetne[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetne[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetne[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetne[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetne[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetne[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetne[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetne[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetne[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetne[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetne[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetne[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetne[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetne[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetne[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetne[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetne[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetne[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetne[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetne[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetne[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetne[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetne[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetne[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetne[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetne[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetne[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetne[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetne[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetne[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetne[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetne[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetne[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetne[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetlt[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetlt[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetlt[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetlt[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetlt[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetlt[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetlt[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetlt[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetlt[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetlt[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetlt[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetlt[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetlt[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetlt[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetlt[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetlt[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetlt[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetlt[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetlt[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetlt[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetlt[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetlt[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetlt[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetlt[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetlt[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetlt[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetlt[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetlt[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetlt[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetlt[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetlt[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetlt[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetlt[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetlt[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetlt[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetlt[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetlt[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetlt[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetlt[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetlt[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetlt[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetlt[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetlt[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetlt[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetlt[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetlt[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetlt[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetlt[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetlt[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetlt[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetlt[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetlt[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetlt[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetlt[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetlt[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetlt[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetlt[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetlt[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetlt[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetlt[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetlt[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetlt[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetlt[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetlt[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetle[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetle[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetle[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetle[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetle[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetle[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetle[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetle[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetle[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetle[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetle[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetle[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetle[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetle[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetle[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetle[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetle[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetle[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetle[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetle[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetle[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetle[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetle[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetle[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetle[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetle[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetle[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetle[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetle[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetle[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetle[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetle[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetle[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetle[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetle[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetle[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetle[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetle[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetle[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetle[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetle[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetle[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetle[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetle[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetle[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetle[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetle[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetle[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetle[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetle[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetle[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetle[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetle[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetle[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetle[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetle[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetle[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetle[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetle[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetle[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetle[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetle[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetle[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetle[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetgt[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetgt[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetgt[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetgt[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetgt[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetgt[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetgt[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetgt[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetgt[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetgt[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetgt[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetgt[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetgt[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetgt[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetgt[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetgt[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetgt[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetgt[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetgt[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetgt[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetgt[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetgt[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetgt[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetgt[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetgt[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetgt[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetgt[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetgt[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetgt[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetgt[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetgt[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetgt[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetgt[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetgt[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetgt[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetgt[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetgt[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetgt[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetgt[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetgt[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetgt[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetgt[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetgt[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetgt[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetgt[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetgt[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetgt[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetgt[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetgt[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetgt[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetgt[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetgt[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetgt[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetgt[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetgt[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetgt[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetgt[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetgt[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetgt[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetgt[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetgt[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetgt[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetgt[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetgt[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vbool8_t vsetge[_vv_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vbool8_t vsetge[_vs_i8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vint8m1_t op1, int8_t op2);
vbool4_t vsetge[_vv_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vbool4_t vsetge[_vs_i8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vint8m2_t op1, int8_t op2);
vbool2_t vsetge[_vv_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vbool2_t vsetge[_vs_i8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vint8m4_t op1, int8_t op2);
vbool1_t vsetge[_vv_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vbool1_t vsetge[_vs_i8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vint8m8_t op1, int8_t op2);
vbool16_t vsetge[_vv_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vbool16_t vsetge[_vs_i16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vint16m1_t op1, int16_t op2);
vbool8_t vsetge[_vv_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vbool8_t vsetge[_vs_i16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vint16m2_t op1, int16_t op2);
vbool4_t vsetge[_vv_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vbool4_t vsetge[_vs_i16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vint16m4_t op1, int16_t op2);
vbool2_t vsetge[_vv_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vbool2_t vsetge[_vs_i16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vint16m8_t op1, int16_t op2);
vbool32_t vsetge[_vv_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vbool32_t vsetge[_vs_i32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vint32m1_t op1, int32_t op2);
vbool16_t vsetge[_vv_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vbool16_t vsetge[_vs_i32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vint32m2_t op1, int32_t op2);
vbool8_t vsetge[_vv_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vbool8_t vsetge[_vs_i32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vint32m4_t op1, int32_t op2);
vbool4_t vsetge[_vv_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vbool4_t vsetge[_vs_i32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vint32m8_t op1, int32_t op2);
vbool64_t vsetge[_vv_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vbool64_t vsetge[_vs_i64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vint64m1_t op1, int64_t op2);
vbool32_t vsetge[_vv_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vbool32_t vsetge[_vs_i64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vint64m2_t op1, int64_t op2);
vbool16_t vsetge[_vv_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vbool16_t vsetge[_vs_i64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vint64m4_t op1, int64_t op2);
vbool8_t vsetge[_vv_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vbool8_t vsetge[_vs_i64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vint64m8_t op1, int64_t op2);
vbool8_t vsetge[_vv_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vbool8_t vsetge[_vs_u8m1]_mask (vbool8_t mask, vbool8_t maskedoff, vuint8m1_t op1, uint8_t op2);
vbool4_t vsetge[_vv_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vbool4_t vsetge[_vs_u8m2]_mask (vbool4_t mask, vbool4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vbool2_t vsetge[_vv_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vbool2_t vsetge[_vs_u8m4]_mask (vbool2_t mask, vbool2_t maskedoff, vuint8m4_t op1, uint8_t op2);
vbool1_t vsetge[_vv_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vbool1_t vsetge[_vs_u8m8]_mask (vbool1_t mask, vbool1_t maskedoff, vuint8m8_t op1, uint8_t op2);
vbool16_t vsetge[_vv_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vbool16_t vsetge[_vs_u16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vuint16m1_t op1, uint16_t op2);
vbool8_t vsetge[_vv_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vbool8_t vsetge[_vs_u16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vuint16m2_t op1, uint16_t op2);
vbool4_t vsetge[_vv_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vbool4_t vsetge[_vs_u16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vbool2_t vsetge[_vv_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vbool2_t vsetge[_vs_u16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vuint16m8_t op1, uint16_t op2);
vbool32_t vsetge[_vv_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vbool32_t vsetge[_vs_u32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vuint32m1_t op1, uint32_t op2);
vbool16_t vsetge[_vv_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vbool16_t vsetge[_vs_u32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vuint32m2_t op1, uint32_t op2);
vbool8_t vsetge[_vv_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vbool8_t vsetge[_vs_u32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vbool4_t vsetge[_vv_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vbool4_t vsetge[_vs_u32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vuint32m8_t op1, uint32_t op2);
vbool64_t vsetge[_vv_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vbool64_t vsetge[_vs_u64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vuint64m1_t op1, uint64_t op2);
vbool32_t vsetge[_vv_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vbool32_t vsetge[_vs_u64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vuint64m2_t op1, uint64_t op2);
vbool16_t vsetge[_vv_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vbool16_t vsetge[_vs_u64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vuint64m4_t op1, uint64_t op2);
vbool8_t vsetge[_vv_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vbool8_t vsetge[_vs_u64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Integer Min/Max Functions:

**Prototypes:**
``` C
vint8m1_t vmin[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vmin[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vmin[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vmin[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vmin[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vmin[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vmin[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vmin[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vmin[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vmin[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vmin[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vmin[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vmin[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vmin[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vmin[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vmin[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vmin[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vmax[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vmax[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vmax[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vmax[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vmax[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vmax[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vmax[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vmax[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vmax[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vmax[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vmax[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vmax[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vmax[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vmax[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vmax[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vmax[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmin[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmin[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmin[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmin[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmin[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmin[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmin[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmin[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmin[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmin[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmin[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmin[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmin[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmin[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmin[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmin[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmin[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmin[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmin[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmin[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmin[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmin[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmin[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmin[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmin[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmin[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmin[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmin[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmin[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmin[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmin[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmin[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmin[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmin[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmin[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmin[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmin[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmin[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmin[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmin[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmin[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmin[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmin[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmin[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmin[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmin[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmin[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmin[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmin[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmin[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmin[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmin[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmin[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmin[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmin[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmin[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmin[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmin[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmin[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmin[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmin[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmin[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmin[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmin[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmax[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmax[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmax[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmax[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmax[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmax[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmax[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmax[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmax[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmax[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmax[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmax[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmax[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmax[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmax[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmax[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmax[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmax[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmax[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmax[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmax[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmax[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmax[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmax[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmax[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmax[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmax[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmax[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmax[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmax[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmax[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmax[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmax[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmax[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmax[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmax[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmax[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmax[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmax[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmax[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmax[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmax[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmax[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmax[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmax[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmax[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmax[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmax[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmax[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmax[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmax[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmax[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmax[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmax[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmax[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmax[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmax[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmax[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmax[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmax[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmax[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmax[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmax[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmax[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Single-Width Integer Multiply Functions:

**Prototypes:**
``` C
vint8m1_t vmul[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vmul[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vmul[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vmul[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vmul[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vmul[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vmul[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vmul[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vmul[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vmul[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vmul[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vmul[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vmul[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vmul[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vmul[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vmul[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vmul[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vmulh[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vmulh[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vmulh[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vmulh[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vmulh[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vmulh[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vmulh[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vmulh[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vmulh[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vmulh[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vmulh[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vmulh[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vmulh[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vmulh[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vmulh[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu[_vv_i8m1] (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu[_vs_i8m1] (vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu[_vv_i8m2] (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu[_vs_i8m2] (vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu[_vv_i8m4] (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu[_vs_i8m4] (vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu[_vv_i8m8] (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu[_vs_i8m8] (vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu[_vv_i16m1] (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu[_vs_i16m1] (vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu[_vv_i16m2] (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu[_vs_i16m2] (vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu[_vv_i16m4] (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu[_vs_i16m4] (vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu[_vv_i16m8] (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu[_vs_i16m8] (vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu[_vv_i32m1] (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu[_vs_i32m1] (vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu[_vv_i32m2] (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu[_vs_i32m2] (vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu[_vv_i32m4] (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu[_vs_i32m4] (vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu[_vv_i32m8] (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu[_vs_i32m8] (vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu[_vv_i64m1] (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu[_vs_i64m1] (vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu[_vv_i64m2] (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu[_vs_i64m2] (vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu[_vv_i64m4] (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu[_vs_i64m4] (vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu[_vv_i64m8] (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu[_vs_i64m8] (vint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vmul[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmul[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmul[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmul[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmul[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmul[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmul[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmul[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmul[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmul[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmul[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmul[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmul[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmul[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmul[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmul[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmul[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmul[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmul[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmul[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmul[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmul[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmul[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmul[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmul[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmul[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmul[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmul[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmul[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmul[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmul[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmul[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmul[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmul[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmul[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmul[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmul[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmul[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmul[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmul[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmul[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmul[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmul[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmul[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmul[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmul[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmul[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmul[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmul[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmul[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmul[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmul[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmul[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmul[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmul[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmul[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmul[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmul[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmul[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmul[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmul[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmul[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmul[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmul[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulh[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmulh[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vmulh[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmulh[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vmulh[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmulh[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vmulh[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmulh[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vmulh[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmulh[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vmulh[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmulh[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vmulh[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmulh[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vmulh[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmulh[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vmulh[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmulh[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vmulh[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmulh[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vmulh[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmulh[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vmulh[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmulh[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vmulh[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmulh[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vmulh[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmulh[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vmulh[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmulh[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vmulh[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmulh[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vmulh[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmulh[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmulh[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmulh[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmulh[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmulh[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmulh[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmulh[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmulh[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmulh[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmulh[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmulh[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmulh[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmulh[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmulh[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmulh[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmulh[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmulh[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmulh[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmulh[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmulh[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmulh[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmulh[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmulh[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmulh[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmulh[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmulh[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmulh[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmulh[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmulh[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmulh[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmulh[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vmulhsu[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vmulhsu[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vmulhsu[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vmulhsu[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vmulhsu[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vmulhsu[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vmulhsu[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vmulhsu[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vmulhsu[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vmulhsu[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vmulhsu[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vmulhsu[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vmulhsu[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vmulhsu[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vmulhsu[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vmulhsu[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vmulhsu[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vmulhsu[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vmulhsu[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vmulhsu[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vmulhsu[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vmulhsu[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vmulhsu[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vmulhsu[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vmulhsu[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vmulhsu[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vmulhsu[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vmulhsu[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vmulhsu[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vmulhsu[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vmulhsu[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vmulhsu[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
```
### Vector Integer Divide Functions:

**Prototypes:**
``` C
vint8m1_t vdiv[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vdiv[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vdiv[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vdiv[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vdiv[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vdiv[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vdiv[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vdiv[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vdiv[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vdiv[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vdiv[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vdiv[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vdiv[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vdiv[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vdiv[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vdiv[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vrem[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vrem[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vrem[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vrem[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vrem[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vrem[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vrem[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vrem[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vrem[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vrem[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vrem[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vrem[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vrem[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vrem[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vrem[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vrem[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vdiv[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vdiv[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vdiv[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vdiv[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vdiv[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vdiv[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vdiv[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vdiv[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vdiv[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vdiv[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vdiv[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vdiv[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vdiv[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vdiv[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vdiv[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vdiv[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vdiv[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vdiv[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vdiv[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vdiv[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vdiv[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vdiv[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vdiv[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vdiv[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vdiv[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vdiv[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vdiv[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vdiv[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vdiv[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vdiv[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vdiv[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vdiv[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vdiv[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vdiv[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vdiv[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vdiv[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vdiv[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vdiv[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vdiv[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vdiv[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vdiv[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vdiv[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vdiv[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vdiv[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vdiv[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vdiv[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vdiv[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vdiv[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vdiv[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vdiv[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vdiv[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vdiv[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vdiv[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vdiv[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vdiv[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vdiv[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vdiv[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vdiv[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vdiv[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vdiv[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vdiv[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vdiv[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vdiv[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vdiv[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vrem[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vrem[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vrem[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vrem[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vrem[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vrem[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vrem[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vrem[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vrem[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vrem[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vrem[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vrem[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vrem[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vrem[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vrem[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vrem[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vrem[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vrem[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vrem[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vrem[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vrem[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vrem[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vrem[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vrem[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vrem[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vrem[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vrem[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vrem[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vrem[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vrem[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vrem[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vrem[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vrem[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrem[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrem[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrem[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrem[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrem[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrem[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrem[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrem[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrem[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrem[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrem[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrem[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrem[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrem[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrem[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrem[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrem[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrem[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrem[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrem[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrem[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrem[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrem[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrem[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrem[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrem[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrem[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrem[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrem[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrem[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrem[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Widening Integer Multiply Functions:

**Prototypes:**
``` C
vint16m2_t vwmul[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint16m4_t vwmul[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint16m8_t vwmul[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint32m2_t vwmul[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint32m4_t vwmul[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint32m8_t vwmul[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint64m2_t vwmul[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint64m4_t vwmul[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint64m8_t vwmul[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu[_vv_i8m1] (vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu[_vs_i8m1] (vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu[_vv_i8m2] (vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu[_vs_i8m2] (vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu[_vv_i8m4] (vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu[_vs_i8m4] (vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu[_vv_i16m1] (vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu[_vs_i16m1] (vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu[_vv_i16m2] (vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu[_vs_i16m2] (vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu[_vv_i16m4] (vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu[_vs_i16m4] (vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu[_vv_i32m1] (vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu[_vs_i32m1] (vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu[_vv_i32m2] (vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu[_vs_i32m2] (vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu[_vv_i32m4] (vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu[_vs_i32m4] (vint32m4_t op1, uint32_t op2);
// masked functions
vint16m2_t vwmul[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmul[_vs_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, int8_t op2);
vint16m4_t vwmul[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmul[_vs_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, int8_t op2);
vint16m8_t vwmul[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmul[_vs_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, int8_t op2);
vint32m2_t vwmul[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmul[_vs_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, int16_t op2);
vint32m4_t vwmul[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmul[_vs_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, int16_t op2);
vint32m8_t vwmul[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmul[_vs_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, int16_t op2);
vint64m2_t vwmul[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmul[_vs_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, int32_t op2);
vint64m4_t vwmul[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmul[_vs_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, int32_t op2);
vint64m8_t vwmul[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmul[_vs_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, int32_t op2);
vuint16m2_t vwmul[_vv_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmul[_vs_u8m1]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint16m4_t vwmul[_vv_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmul[_vs_u8m2]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint16m8_t vwmul[_vv_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmul[_vs_u8m4]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint32m2_t vwmul[_vv_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmul[_vs_u16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint32m4_t vwmul[_vv_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmul[_vs_u16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint32m8_t vwmul[_vv_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmul[_vs_u16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint64m2_t vwmul[_vv_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmul[_vs_u32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint64m4_t vwmul[_vv_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmul[_vs_u32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint64m8_t vwmul[_vv_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmul[_vs_u32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t op1, uint32_t op2);
vint16m2_t vwmulsu[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmulsu[_vs_i8m1]_mask (vbool8_t mask, vint16m2_t maskedoff, vint8m1_t op1, uint8_t op2);
vint16m4_t vwmulsu[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmulsu[_vs_i8m2]_mask (vbool4_t mask, vint16m4_t maskedoff, vint8m2_t op1, uint8_t op2);
vint16m8_t vwmulsu[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmulsu[_vs_i8m4]_mask (vbool2_t mask, vint16m8_t maskedoff, vint8m4_t op1, uint8_t op2);
vint32m2_t vwmulsu[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmulsu[_vs_i16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t op1, uint16_t op2);
vint32m4_t vwmulsu[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmulsu[_vs_i16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t op1, uint16_t op2);
vint32m8_t vwmulsu[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmulsu[_vs_i16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t op1, uint16_t op2);
vint64m2_t vwmulsu[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmulsu[_vs_i32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t op1, uint32_t op2);
vint64m4_t vwmulsu[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmulsu[_vs_i32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t op1, uint32_t op2);
vint64m8_t vwmulsu[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmulsu[_vs_i32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t op1, uint32_t op2);
```
### Vector Single-Width Integer Multiply-Add Functions:

**Prototypes:**
``` C
vint8m1_t vmacc[_vv_i8m1] (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc[_sv_i8m1] (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc[_vv_i8m2] (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc[_sv_i8m2] (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc[_vv_i8m4] (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc[_sv_i8m4] (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc[_vv_i8m8] (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc[_sv_i8m8] (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc[_vv_i16m1] (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc[_sv_i16m1] (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc[_vv_i16m2] (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc[_sv_i16m2] (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc[_vv_i16m4] (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc[_sv_i16m4] (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc[_vv_i16m8] (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc[_sv_i16m8] (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc[_vv_i32m1] (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc[_sv_i32m1] (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc[_vv_i32m2] (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc[_sv_i32m2] (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc[_vv_i32m4] (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc[_sv_i32m4] (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc[_vv_i32m8] (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc[_sv_i32m8] (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc[_vv_i64m1] (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc[_sv_i64m1] (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc[_vv_i64m2] (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc[_sv_i64m2] (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc[_vv_i64m4] (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc[_sv_i64m4] (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc[_vv_i64m8] (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc[_sv_i64m8] (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc[_vv_u8m1] (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc[_sv_u8m1] (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc[_vv_u8m2] (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc[_sv_u8m2] (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc[_vv_u8m4] (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc[_sv_u8m4] (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc[_vv_u8m8] (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc[_sv_u8m8] (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc[_vv_u16m1] (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc[_sv_u16m1] (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc[_vv_u16m2] (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc[_sv_u16m2] (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc[_vv_u16m4] (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc[_sv_u16m4] (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc[_vv_u16m8] (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc[_sv_u16m8] (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc[_vv_u32m1] (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc[_sv_u32m1] (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc[_vv_u32m2] (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc[_sv_u32m2] (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc[_vv_u32m4] (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc[_sv_u32m4] (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc[_vv_u32m8] (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc[_sv_u32m8] (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc[_vv_u64m1] (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc[_sv_u64m1] (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc[_vv_u64m2] (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc[_sv_u64m2] (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc[_vv_u64m4] (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc[_sv_u64m4] (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc[_vv_u64m8] (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc[_sv_u64m8] (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac[_vv_i8m1] (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac[_sv_i8m1] (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac[_vv_i8m2] (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac[_sv_i8m2] (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac[_vv_i8m4] (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac[_sv_i8m4] (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac[_vv_i8m8] (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac[_sv_i8m8] (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac[_vv_i16m1] (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac[_sv_i16m1] (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac[_vv_i16m2] (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac[_sv_i16m2] (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac[_vv_i16m4] (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac[_sv_i16m4] (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac[_vv_i16m8] (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac[_sv_i16m8] (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac[_vv_i32m1] (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac[_sv_i32m1] (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac[_vv_i32m2] (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac[_sv_i32m2] (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac[_vv_i32m4] (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac[_sv_i32m4] (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac[_vv_i32m8] (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac[_sv_i32m8] (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac[_vv_i64m1] (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac[_sv_i64m1] (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac[_vv_i64m2] (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac[_sv_i64m2] (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac[_vv_i64m4] (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac[_sv_i64m4] (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac[_vv_i64m8] (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac[_sv_i64m8] (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac[_vv_u8m1] (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac[_sv_u8m1] (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac[_vv_u8m2] (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac[_sv_u8m2] (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac[_vv_u8m4] (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac[_sv_u8m4] (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac[_vv_u8m8] (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac[_sv_u8m8] (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac[_vv_u16m1] (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac[_sv_u16m1] (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac[_vv_u16m2] (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac[_sv_u16m2] (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac[_vv_u16m4] (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac[_sv_u16m4] (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac[_vv_u16m8] (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac[_sv_u16m8] (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac[_vv_u32m1] (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac[_sv_u32m1] (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac[_vv_u32m2] (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac[_sv_u32m2] (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac[_vv_u32m4] (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac[_sv_u32m4] (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac[_vv_u32m8] (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac[_sv_u32m8] (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac[_vv_u64m1] (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac[_sv_u64m1] (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac[_vv_u64m2] (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac[_sv_u64m2] (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac[_vv_u64m4] (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac[_sv_u64m4] (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac[_vv_u64m8] (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac[_sv_u64m8] (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd[_vv_i8m1] (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd[_sv_i8m1] (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd[_vv_i8m2] (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd[_sv_i8m2] (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd[_vv_i8m4] (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd[_sv_i8m4] (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd[_vv_i8m8] (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd[_sv_i8m8] (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd[_vv_i16m1] (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd[_sv_i16m1] (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd[_vv_i16m2] (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd[_sv_i16m2] (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd[_vv_i16m4] (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd[_sv_i16m4] (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd[_vv_i16m8] (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd[_sv_i16m8] (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd[_vv_i32m1] (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd[_sv_i32m1] (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd[_vv_i32m2] (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd[_sv_i32m2] (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd[_vv_i32m4] (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd[_sv_i32m4] (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd[_vv_i32m8] (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd[_sv_i32m8] (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd[_vv_i64m1] (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd[_sv_i64m1] (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd[_vv_i64m2] (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd[_sv_i64m2] (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd[_vv_i64m4] (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd[_sv_i64m4] (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd[_vv_i64m8] (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd[_sv_i64m8] (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd[_vv_u8m1] (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd[_sv_u8m1] (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd[_vv_u8m2] (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd[_sv_u8m2] (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd[_vv_u8m4] (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd[_sv_u8m4] (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd[_vv_u8m8] (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd[_sv_u8m8] (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd[_vv_u16m1] (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd[_sv_u16m1] (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd[_vv_u16m2] (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd[_sv_u16m2] (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd[_vv_u16m4] (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd[_sv_u16m4] (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd[_vv_u16m8] (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd[_sv_u16m8] (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd[_vv_u32m1] (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd[_sv_u32m1] (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd[_vv_u32m2] (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd[_sv_u32m2] (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd[_vv_u32m4] (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd[_sv_u32m4] (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd[_vv_u32m8] (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd[_sv_u32m8] (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd[_vv_u64m1] (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd[_sv_u64m1] (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd[_vv_u64m2] (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd[_sv_u64m2] (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd[_vv_u64m4] (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd[_sv_u64m4] (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd[_vv_u64m8] (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd[_sv_u64m8] (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub[_vv_i8m1] (vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub[_sv_i8m1] (vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub[_vv_i8m2] (vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub[_sv_i8m2] (vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub[_vv_i8m4] (vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub[_sv_i8m4] (vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub[_vv_i8m8] (vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub[_sv_i8m8] (vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub[_vv_i16m1] (vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub[_sv_i16m1] (vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub[_vv_i16m2] (vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub[_sv_i16m2] (vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub[_vv_i16m4] (vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub[_sv_i16m4] (vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub[_vv_i16m8] (vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub[_sv_i16m8] (vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub[_vv_i32m1] (vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub[_sv_i32m1] (vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub[_vv_i32m2] (vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub[_sv_i32m2] (vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub[_vv_i32m4] (vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub[_sv_i32m4] (vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub[_vv_i32m8] (vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub[_sv_i32m8] (vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub[_vv_i64m1] (vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub[_sv_i64m1] (vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub[_vv_i64m2] (vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub[_sv_i64m2] (vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub[_vv_i64m4] (vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub[_sv_i64m4] (vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub[_vv_i64m8] (vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub[_sv_i64m8] (vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub[_vv_u8m1] (vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub[_sv_u8m1] (vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub[_vv_u8m2] (vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub[_sv_u8m2] (vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub[_vv_u8m4] (vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub[_sv_u8m4] (vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub[_vv_u8m8] (vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub[_sv_u8m8] (vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub[_vv_u16m1] (vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub[_sv_u16m1] (vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub[_vv_u16m2] (vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub[_sv_u16m2] (vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub[_vv_u16m4] (vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub[_sv_u16m4] (vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub[_vv_u16m8] (vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub[_sv_u16m8] (vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub[_vv_u32m1] (vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub[_sv_u32m1] (vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub[_vv_u32m2] (vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub[_sv_u32m2] (vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub[_vv_u32m4] (vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub[_sv_u32m4] (vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub[_vv_u32m8] (vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub[_sv_u32m8] (vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub[_vv_u64m1] (vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub[_sv_u64m1] (vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub[_vv_u64m2] (vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub[_sv_u64m2] (vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub[_vv_u64m4] (vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub[_sv_u64m4] (vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub[_vv_u64m8] (vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub[_sv_u64m8] (vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
// masked functions
vint8m1_t vmacc[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmacc[_sv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmacc[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmacc[_sv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmacc[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmacc[_sv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmacc[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmacc[_sv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmacc[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmacc[_sv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmacc[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmacc[_sv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmacc[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmacc[_sv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmacc[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmacc[_sv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmacc[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmacc[_sv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmacc[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmacc[_sv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmacc[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmacc[_sv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmacc[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmacc[_sv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmacc[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmacc[_sv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmacc[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmacc[_sv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmacc[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmacc[_sv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmacc[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmacc[_sv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmacc[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmacc[_sv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmacc[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmacc[_sv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmacc[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmacc[_sv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmacc[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmacc[_sv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmacc[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmacc[_sv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmacc[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmacc[_sv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmacc[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmacc[_sv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmacc[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmacc[_sv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmacc[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmacc[_sv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmacc[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmacc[_sv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmacc[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmacc[_sv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmacc[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmacc[_sv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmacc[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmacc[_sv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmacc[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmacc[_sv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmacc[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmacc[_sv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmacc[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmacc[_sv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsac[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsac[_sv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsac[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsac[_sv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsac[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsac[_sv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsac[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsac[_sv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsac[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsac[_sv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsac[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsac[_sv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsac[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsac[_sv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsac[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsac[_sv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsac[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsac[_sv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsac[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsac[_sv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsac[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsac[_sv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsac[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsac[_sv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsac[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsac[_sv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsac[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsac[_sv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsac[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsac[_sv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsac[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsac[_sv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsac[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsac[_sv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsac[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsac[_sv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsac[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsac[_sv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsac[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsac[_sv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsac[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsac[_sv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsac[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsac[_sv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsac[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsac[_sv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsac[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsac[_sv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsac[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsac[_sv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsac[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsac[_sv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsac[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsac[_sv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsac[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsac[_sv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsac[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsac[_sv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsac[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsac[_sv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsac[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsac[_sv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsac[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsac[_sv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vmadd[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmadd[_sv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vmadd[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmadd[_sv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vmadd[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmadd[_sv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vmadd[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmadd[_sv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vmadd[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmadd[_sv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vmadd[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmadd[_sv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vmadd[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmadd[_sv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vmadd[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmadd[_sv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vmadd[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmadd[_sv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vmadd[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmadd[_sv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vmadd[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmadd[_sv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vmadd[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmadd[_sv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vmadd[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmadd[_sv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vmadd[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmadd[_sv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vmadd[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmadd[_sv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vmadd[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmadd[_sv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vmadd[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmadd[_sv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vmadd[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmadd[_sv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vmadd[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmadd[_sv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vmadd[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmadd[_sv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vmadd[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmadd[_sv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vmadd[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmadd[_sv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vmadd[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmadd[_sv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vmadd[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmadd[_sv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vmadd[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmadd[_sv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vmadd[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmadd[_sv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vmadd[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmadd[_sv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vmadd[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmadd[_sv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vmadd[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmadd[_sv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vmadd[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmadd[_sv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vmadd[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmadd[_sv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vmadd[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmadd[_sv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
vint8m1_t vnmsub[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vnmsub[_sv_i8m1]_mask (vbool8_t mask, vint8m1_t acc, int8_t op1, vint8m1_t op2);
vint8m2_t vnmsub[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vnmsub[_sv_i8m2]_mask (vbool4_t mask, vint8m2_t acc, int8_t op1, vint8m2_t op2);
vint8m4_t vnmsub[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vnmsub[_sv_i8m4]_mask (vbool2_t mask, vint8m4_t acc, int8_t op1, vint8m4_t op2);
vint8m8_t vnmsub[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vnmsub[_sv_i8m8]_mask (vbool1_t mask, vint8m8_t acc, int8_t op1, vint8m8_t op2);
vint16m1_t vnmsub[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vnmsub[_sv_i16m1]_mask (vbool16_t mask, vint16m1_t acc, int16_t op1, vint16m1_t op2);
vint16m2_t vnmsub[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vnmsub[_sv_i16m2]_mask (vbool8_t mask, vint16m2_t acc, int16_t op1, vint16m2_t op2);
vint16m4_t vnmsub[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vnmsub[_sv_i16m4]_mask (vbool4_t mask, vint16m4_t acc, int16_t op1, vint16m4_t op2);
vint16m8_t vnmsub[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vnmsub[_sv_i16m8]_mask (vbool2_t mask, vint16m8_t acc, int16_t op1, vint16m8_t op2);
vint32m1_t vnmsub[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vnmsub[_sv_i32m1]_mask (vbool32_t mask, vint32m1_t acc, int32_t op1, vint32m1_t op2);
vint32m2_t vnmsub[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vnmsub[_sv_i32m2]_mask (vbool16_t mask, vint32m2_t acc, int32_t op1, vint32m2_t op2);
vint32m4_t vnmsub[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vnmsub[_sv_i32m4]_mask (vbool8_t mask, vint32m4_t acc, int32_t op1, vint32m4_t op2);
vint32m8_t vnmsub[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vnmsub[_sv_i32m8]_mask (vbool4_t mask, vint32m8_t acc, int32_t op1, vint32m8_t op2);
vint64m1_t vnmsub[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vnmsub[_sv_i64m1]_mask (vbool64_t mask, vint64m1_t acc, int64_t op1, vint64m1_t op2);
vint64m2_t vnmsub[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vnmsub[_sv_i64m2]_mask (vbool32_t mask, vint64m2_t acc, int64_t op1, vint64m2_t op2);
vint64m4_t vnmsub[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vnmsub[_sv_i64m4]_mask (vbool16_t mask, vint64m4_t acc, int64_t op1, vint64m4_t op2);
vint64m8_t vnmsub[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vnmsub[_sv_i64m8]_mask (vbool8_t mask, vint64m8_t acc, int64_t op1, vint64m8_t op2);
vuint8m1_t vnmsub[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vnmsub[_sv_u8m1]_mask (vbool8_t mask, vuint8m1_t acc, uint8_t op1, vuint8m1_t op2);
vuint8m2_t vnmsub[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vnmsub[_sv_u8m2]_mask (vbool4_t mask, vuint8m2_t acc, uint8_t op1, vuint8m2_t op2);
vuint8m4_t vnmsub[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vnmsub[_sv_u8m4]_mask (vbool2_t mask, vuint8m4_t acc, uint8_t op1, vuint8m4_t op2);
vuint8m8_t vnmsub[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vnmsub[_sv_u8m8]_mask (vbool1_t mask, vuint8m8_t acc, uint8_t op1, vuint8m8_t op2);
vuint16m1_t vnmsub[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vnmsub[_sv_u16m1]_mask (vbool16_t mask, vuint16m1_t acc, uint16_t op1, vuint16m1_t op2);
vuint16m2_t vnmsub[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vnmsub[_sv_u16m2]_mask (vbool8_t mask, vuint16m2_t acc, uint16_t op1, vuint16m2_t op2);
vuint16m4_t vnmsub[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vnmsub[_sv_u16m4]_mask (vbool4_t mask, vuint16m4_t acc, uint16_t op1, vuint16m4_t op2);
vuint16m8_t vnmsub[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vnmsub[_sv_u16m8]_mask (vbool2_t mask, vuint16m8_t acc, uint16_t op1, vuint16m8_t op2);
vuint32m1_t vnmsub[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vnmsub[_sv_u32m1]_mask (vbool32_t mask, vuint32m1_t acc, uint32_t op1, vuint32m1_t op2);
vuint32m2_t vnmsub[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vnmsub[_sv_u32m2]_mask (vbool16_t mask, vuint32m2_t acc, uint32_t op1, vuint32m2_t op2);
vuint32m4_t vnmsub[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vnmsub[_sv_u32m4]_mask (vbool8_t mask, vuint32m4_t acc, uint32_t op1, vuint32m4_t op2);
vuint32m8_t vnmsub[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vnmsub[_sv_u32m8]_mask (vbool4_t mask, vuint32m8_t acc, uint32_t op1, vuint32m8_t op2);
vuint64m1_t vnmsub[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vnmsub[_sv_u64m1]_mask (vbool64_t mask, vuint64m1_t acc, uint64_t op1, vuint64m1_t op2);
vuint64m2_t vnmsub[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vnmsub[_sv_u64m2]_mask (vbool32_t mask, vuint64m2_t acc, uint64_t op1, vuint64m2_t op2);
vuint64m4_t vnmsub[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vnmsub[_sv_u64m4]_mask (vbool16_t mask, vuint64m4_t acc, uint64_t op1, vuint64m4_t op2);
vuint64m8_t vnmsub[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vnmsub[_sv_u64m8]_mask (vbool8_t mask, vuint64m8_t acc, uint64_t op1, vuint64m8_t op2);
```
### Vector Widening Integer Multiply-Add Functions:

**Prototypes:**
``` C
vint16m2_t vwmacc[_vv_i8m1] (vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc[_sv_i8m1] (vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc[_vv_i8m2] (vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc[_sv_i8m2] (vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc[_vv_i8m4] (vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc[_sv_i8m4] (vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc[_vv_i16m1] (vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc[_sv_i16m1] (vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc[_vv_i16m2] (vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc[_sv_i16m2] (vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc[_vv_i16m4] (vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc[_sv_i16m4] (vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc[_vv_i32m1] (vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc[_sv_i32m1] (vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc[_vv_i32m2] (vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc[_sv_i32m2] (vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc[_vv_i32m4] (vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc[_sv_i32m4] (vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc[_vv_u8m1] (vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc[_sv_u8m1] (vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc[_vv_u8m2] (vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc[_sv_u8m2] (vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc[_vv_u8m4] (vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc[_sv_u8m4] (vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc[_vv_u16m1] (vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc[_sv_u16m1] (vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc[_vv_u16m2] (vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc[_sv_u16m2] (vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc[_vv_u16m4] (vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc[_sv_u16m4] (vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc[_vv_u32m1] (vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc[_sv_u32m1] (vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc[_vv_u32m2] (vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc[_sv_u32m2] (vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc[_vv_u32m4] (vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc[_sv_u32m4] (vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu[_vv_i8m1] (vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu[_sv_i8m1] (vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu[_vv_i8m2] (vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu[_sv_i8m2] (vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu[_vv_i8m4] (vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu[_sv_i8m4] (vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu[_vv_i16m1] (vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu[_sv_i16m1] (vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu[_vv_i16m2] (vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu[_sv_i16m2] (vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu[_vv_i16m4] (vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu[_sv_i16m4] (vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu[_vv_i32m1] (vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu[_sv_i32m1] (vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu[_vv_i32m2] (vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu[_sv_i32m2] (vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu[_vv_i32m4] (vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu[_sv_i32m4] (vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus[_sv_i8m1] (vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus[_sv_i8m2] (vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus[_sv_i8m4] (vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus[_sv_i16m1] (vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus[_sv_i16m2] (vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus[_sv_i16m4] (vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus[_sv_i32m1] (vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus[_sv_i32m2] (vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus[_sv_i32m4] (vint64m8_t acc, uint32_t op1, vint32m4_t op2);
// masked functions
vint16m2_t vwmacc[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vint8m1_t op2);
vint16m2_t vwmacc[_sv_i8m1]_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vint8m1_t op2);
vint16m4_t vwmacc[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vint8m2_t op2);
vint16m4_t vwmacc[_sv_i8m2]_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vint8m2_t op2);
vint16m8_t vwmacc[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vint8m4_t op2);
vint16m8_t vwmacc[_sv_i8m4]_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vint8m4_t op2);
vint32m2_t vwmacc[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vint16m1_t op2);
vint32m2_t vwmacc[_sv_i16m1]_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vint16m1_t op2);
vint32m4_t vwmacc[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vint16m2_t op2);
vint32m4_t vwmacc[_sv_i16m2]_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vint16m2_t op2);
vint32m8_t vwmacc[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vint16m4_t op2);
vint32m8_t vwmacc[_sv_i16m4]_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vint16m4_t op2);
vint64m2_t vwmacc[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vint32m1_t op2);
vint64m2_t vwmacc[_sv_i32m1]_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vint32m1_t op2);
vint64m4_t vwmacc[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vint32m2_t op2);
vint64m4_t vwmacc[_sv_i32m2]_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vint32m2_t op2);
vint64m8_t vwmacc[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vint32m4_t op2);
vint64m8_t vwmacc[_sv_i32m4]_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vint32m4_t op2);
vuint16m2_t vwmacc[_vv_u8m1]_mask (vbool8_t mask, vuint16m2_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint16m2_t vwmacc[_sv_u8m1]_mask (vbool8_t mask, vuint16m2_t acc, uint8_t op1, vuint8m1_t op2);
vuint16m4_t vwmacc[_vv_u8m2]_mask (vbool4_t mask, vuint16m4_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint16m4_t vwmacc[_sv_u8m2]_mask (vbool4_t mask, vuint16m4_t acc, uint8_t op1, vuint8m2_t op2);
vuint16m8_t vwmacc[_vv_u8m4]_mask (vbool2_t mask, vuint16m8_t acc, vuint8m4_t op1, vuint8m4_t op2);
vuint16m8_t vwmacc[_sv_u8m4]_mask (vbool2_t mask, vuint16m8_t acc, uint8_t op1, vuint8m4_t op2);
vuint32m2_t vwmacc[_vv_u16m1]_mask (vbool16_t mask, vuint32m2_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint32m2_t vwmacc[_sv_u16m1]_mask (vbool16_t mask, vuint32m2_t acc, uint16_t op1, vuint16m1_t op2);
vuint32m4_t vwmacc[_vv_u16m2]_mask (vbool8_t mask, vuint32m4_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint32m4_t vwmacc[_sv_u16m2]_mask (vbool8_t mask, vuint32m4_t acc, uint16_t op1, vuint16m2_t op2);
vuint32m8_t vwmacc[_vv_u16m4]_mask (vbool4_t mask, vuint32m8_t acc, vuint16m4_t op1, vuint16m4_t op2);
vuint32m8_t vwmacc[_sv_u16m4]_mask (vbool4_t mask, vuint32m8_t acc, uint16_t op1, vuint16m4_t op2);
vuint64m2_t vwmacc[_vv_u32m1]_mask (vbool32_t mask, vuint64m2_t acc, vuint32m1_t op1, vuint32m1_t op2);
vuint64m2_t vwmacc[_sv_u32m1]_mask (vbool32_t mask, vuint64m2_t acc, uint32_t op1, vuint32m1_t op2);
vuint64m4_t vwmacc[_vv_u32m2]_mask (vbool16_t mask, vuint64m4_t acc, vuint32m2_t op1, vuint32m2_t op2);
vuint64m4_t vwmacc[_sv_u32m2]_mask (vbool16_t mask, vuint64m4_t acc, uint32_t op1, vuint32m2_t op2);
vuint64m8_t vwmacc[_vv_u32m4]_mask (vbool8_t mask, vuint64m8_t acc, vuint32m4_t op1, vuint32m4_t op2);
vuint64m8_t vwmacc[_sv_u32m4]_mask (vbool8_t mask, vuint64m8_t acc, uint32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccsu[_vv_i8m1]_mask (vbool8_t mask, vint16m2_t acc, vint8m1_t op1, vuint8m1_t op2);
vint16m2_t vwmaccsu[_sv_i8m1]_mask (vbool8_t mask, vint16m2_t acc, int8_t op1, vuint8m1_t op2);
vint16m4_t vwmaccsu[_vv_i8m2]_mask (vbool4_t mask, vint16m4_t acc, vint8m2_t op1, vuint8m2_t op2);
vint16m4_t vwmaccsu[_sv_i8m2]_mask (vbool4_t mask, vint16m4_t acc, int8_t op1, vuint8m2_t op2);
vint16m8_t vwmaccsu[_vv_i8m4]_mask (vbool2_t mask, vint16m8_t acc, vint8m4_t op1, vuint8m4_t op2);
vint16m8_t vwmaccsu[_sv_i8m4]_mask (vbool2_t mask, vint16m8_t acc, int8_t op1, vuint8m4_t op2);
vint32m2_t vwmaccsu[_vv_i16m1]_mask (vbool16_t mask, vint32m2_t acc, vint16m1_t op1, vuint16m1_t op2);
vint32m2_t vwmaccsu[_sv_i16m1]_mask (vbool16_t mask, vint32m2_t acc, int16_t op1, vuint16m1_t op2);
vint32m4_t vwmaccsu[_vv_i16m2]_mask (vbool8_t mask, vint32m4_t acc, vint16m2_t op1, vuint16m2_t op2);
vint32m4_t vwmaccsu[_sv_i16m2]_mask (vbool8_t mask, vint32m4_t acc, int16_t op1, vuint16m2_t op2);
vint32m8_t vwmaccsu[_vv_i16m4]_mask (vbool4_t mask, vint32m8_t acc, vint16m4_t op1, vuint16m4_t op2);
vint32m8_t vwmaccsu[_sv_i16m4]_mask (vbool4_t mask, vint32m8_t acc, int16_t op1, vuint16m4_t op2);
vint64m2_t vwmaccsu[_vv_i32m1]_mask (vbool32_t mask, vint64m2_t acc, vint32m1_t op1, vuint32m1_t op2);
vint64m2_t vwmaccsu[_sv_i32m1]_mask (vbool32_t mask, vint64m2_t acc, int32_t op1, vuint32m1_t op2);
vint64m4_t vwmaccsu[_vv_i32m2]_mask (vbool16_t mask, vint64m4_t acc, vint32m2_t op1, vuint32m2_t op2);
vint64m4_t vwmaccsu[_sv_i32m2]_mask (vbool16_t mask, vint64m4_t acc, int32_t op1, vuint32m2_t op2);
vint64m8_t vwmaccsu[_vv_i32m4]_mask (vbool8_t mask, vint64m8_t acc, vint32m4_t op1, vuint32m4_t op2);
vint64m8_t vwmaccsu[_sv_i32m4]_mask (vbool8_t mask, vint64m8_t acc, int32_t op1, vuint32m4_t op2);
vint16m2_t vwmaccus[_sv_i8m1]_mask (vbool8_t mask, vint16m2_t acc, uint8_t op1, vint8m1_t op2);
vint16m4_t vwmaccus[_sv_i8m2]_mask (vbool4_t mask, vint16m4_t acc, uint8_t op1, vint8m2_t op2);
vint16m8_t vwmaccus[_sv_i8m4]_mask (vbool2_t mask, vint16m8_t acc, uint8_t op1, vint8m4_t op2);
vint32m2_t vwmaccus[_sv_i16m1]_mask (vbool16_t mask, vint32m2_t acc, uint16_t op1, vint16m1_t op2);
vint32m4_t vwmaccus[_sv_i16m2]_mask (vbool8_t mask, vint32m4_t acc, uint16_t op1, vint16m2_t op2);
vint32m8_t vwmaccus[_sv_i16m4]_mask (vbool4_t mask, vint32m8_t acc, uint16_t op1, vint16m4_t op2);
vint64m2_t vwmaccus[_sv_i32m1]_mask (vbool32_t mask, vint64m2_t acc, uint32_t op1, vint32m1_t op2);
vint64m4_t vwmaccus[_sv_i32m2]_mask (vbool16_t mask, vint64m4_t acc, uint32_t op1, vint32m2_t op2);
vint64m8_t vwmaccus[_sv_i32m4]_mask (vbool8_t mask, vint64m8_t acc, uint32_t op1, vint32m4_t op2);
```
### Vector Quad-Widening Integer Multiply-Add Functions:

**Prototypes:**
``` C
vint32m4_t vqmacc[_vv_i8m1] (vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc[_sv_i8m1] (vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc[_vv_i8m2] (vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc[_sv_i8m2] (vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc[_vv_i16m1] (vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc[_sv_i16m1] (vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc[_vv_i16m2] (vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc[_sv_i16m2] (vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc[_vv_u8m1] (vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc[_sv_u8m1] (vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc[_vv_u8m2] (vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc[_sv_u8m2] (vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc[_vv_u16m1] (vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc[_sv_u16m1] (vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc[_vv_u16m2] (vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc[_sv_u16m2] (vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu[_vv_i8m1] (vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu[_sv_i8m1] (vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu[_vv_i8m2] (vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu[_sv_i8m2] (vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu[_vv_i16m1] (vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu[_sv_i16m1] (vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu[_vv_i16m2] (vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu[_sv_i16m2] (vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus[_sv_i8m1] (vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus[_sv_i8m2] (vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus[_sv_i16m1] (vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus[_sv_i16m2] (vint64m8_t acc, uint16_t op1, vint16m2_t op2);
// masked functions
vint32m4_t vqmacc[_vv_i8m1]_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vint8m1_t op2);
vint32m4_t vqmacc[_sv_i8m1]_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vint8m1_t op2);
vint32m8_t vqmacc[_vv_i8m2]_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vint8m2_t op2);
vint32m8_t vqmacc[_sv_i8m2]_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vint8m2_t op2);
vint64m4_t vqmacc[_vv_i16m1]_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vint16m1_t op2);
vint64m4_t vqmacc[_sv_i16m1]_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vint16m1_t op2);
vint64m8_t vqmacc[_vv_i16m2]_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vint16m2_t op2);
vint64m8_t vqmacc[_sv_i16m2]_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vint16m2_t op2);
vuint32m4_t vqmacc[_vv_u8m1]_mask (vbool8_t mask, vuint32m4_t acc, vuint8m1_t op1, vuint8m1_t op2);
vuint32m4_t vqmacc[_sv_u8m1]_mask (vbool8_t mask, vuint32m4_t acc, uint8_t op1, vuint8m1_t op2);
vuint32m8_t vqmacc[_vv_u8m2]_mask (vbool4_t mask, vuint32m8_t acc, vuint8m2_t op1, vuint8m2_t op2);
vuint32m8_t vqmacc[_sv_u8m2]_mask (vbool4_t mask, vuint32m8_t acc, uint8_t op1, vuint8m2_t op2);
vuint64m4_t vqmacc[_vv_u16m1]_mask (vbool16_t mask, vuint64m4_t acc, vuint16m1_t op1, vuint16m1_t op2);
vuint64m4_t vqmacc[_sv_u16m1]_mask (vbool16_t mask, vuint64m4_t acc, uint16_t op1, vuint16m1_t op2);
vuint64m8_t vqmacc[_vv_u16m2]_mask (vbool8_t mask, vuint64m8_t acc, vuint16m2_t op1, vuint16m2_t op2);
vuint64m8_t vqmacc[_sv_u16m2]_mask (vbool8_t mask, vuint64m8_t acc, uint16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccsu[_vv_i8m1]_mask (vbool8_t mask, vint32m4_t acc, vint8m1_t op1, vuint8m1_t op2);
vint32m4_t vqmaccsu[_sv_i8m1]_mask (vbool8_t mask, vint32m4_t acc, int8_t op1, vuint8m1_t op2);
vint32m8_t vqmaccsu[_vv_i8m2]_mask (vbool4_t mask, vint32m8_t acc, vint8m2_t op1, vuint8m2_t op2);
vint32m8_t vqmaccsu[_sv_i8m2]_mask (vbool4_t mask, vint32m8_t acc, int8_t op1, vuint8m2_t op2);
vint64m4_t vqmaccsu[_vv_i16m1]_mask (vbool16_t mask, vint64m4_t acc, vint16m1_t op1, vuint16m1_t op2);
vint64m4_t vqmaccsu[_sv_i16m1]_mask (vbool16_t mask, vint64m4_t acc, int16_t op1, vuint16m1_t op2);
vint64m8_t vqmaccsu[_vv_i16m2]_mask (vbool8_t mask, vint64m8_t acc, vint16m2_t op1, vuint16m2_t op2);
vint64m8_t vqmaccsu[_sv_i16m2]_mask (vbool8_t mask, vint64m8_t acc, int16_t op1, vuint16m2_t op2);
vint32m4_t vqmaccus[_sv_i8m1]_mask (vbool8_t mask, vint32m4_t acc, uint8_t op1, vint8m1_t op2);
vint32m8_t vqmaccus[_sv_i8m2]_mask (vbool4_t mask, vint32m8_t acc, uint8_t op1, vint8m2_t op2);
vint64m4_t vqmaccus[_sv_i16m1]_mask (vbool16_t mask, vint64m4_t acc, uint16_t op1, vint16m1_t op2);
vint64m8_t vqmaccus[_sv_i16m2]_mask (vbool8_t mask, vint64m8_t acc, uint16_t op1, vint16m2_t op2);
```
### Vector Integer Merge Functions:

**Prototypes:**
``` C
vint8m1_t vmerge[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vmerge[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t op1, int8_t op2);
vint8m2_t vmerge[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vmerge[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t op1, int8_t op2);
vint8m4_t vmerge[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vmerge[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t op1, int8_t op2);
vint8m8_t vmerge[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vmerge[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t op1, int8_t op2);
vint16m1_t vmerge[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vmerge[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t op1, int16_t op2);
vint16m2_t vmerge[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vmerge[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t op1, int16_t op2);
vint16m4_t vmerge[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vmerge[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t op1, int16_t op2);
vint16m8_t vmerge[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vmerge[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t op1, int16_t op2);
vint32m1_t vmerge[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vmerge[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t op1, int32_t op2);
vint32m2_t vmerge[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vmerge[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t op1, int32_t op2);
vint32m4_t vmerge[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vmerge[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t op1, int32_t op2);
vint32m8_t vmerge[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vmerge[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t op1, int32_t op2);
vint64m1_t vmerge[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vmerge[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t op1, int64_t op2);
vint64m2_t vmerge[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vmerge[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t op1, int64_t op2);
vint64m4_t vmerge[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vmerge[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t op1, int64_t op2);
vint64m8_t vmerge[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vmerge[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t op1, int64_t op2);
vuint8m1_t vmerge[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vmerge[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vmerge[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vmerge[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vmerge[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vmerge[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vmerge[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vmerge[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vmerge[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vmerge[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vmerge[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vmerge[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vmerge[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vmerge[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vmerge[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vmerge[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vmerge[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vmerge[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vmerge[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vmerge[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vmerge[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vmerge[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vmerge[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vmerge[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vmerge[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vmerge[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vmerge[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vmerge[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vmerge[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vmerge[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vmerge[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vmerge[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t op1, uint64_t op2);
```
### Vector Integer Move Functions:

**Prototypes:**
``` C
vint8m1_t vcopy[_v_i8m1] (vint8m1_t src);
vint8m1_t vsplat_s_i8m1 (int8_t src);
vint8m2_t vcopy[_v_i8m2] (vint8m2_t src);
vint8m2_t vsplat_s_i8m2 (int8_t src);
vint8m4_t vcopy[_v_i8m4] (vint8m4_t src);
vint8m4_t vsplat_s_i8m4 (int8_t src);
vint8m8_t vcopy[_v_i8m8] (vint8m8_t src);
vint8m8_t vsplat_s_i8m8 (int8_t src);
vint16m1_t vcopy[_v_i16m1] (vint16m1_t src);
vint16m1_t vsplat_s_i16m1 (int16_t src);
vint16m2_t vcopy[_v_i16m2] (vint16m2_t src);
vint16m2_t vsplat_s_i16m2 (int16_t src);
vint16m4_t vcopy[_v_i16m4] (vint16m4_t src);
vint16m4_t vsplat_s_i16m4 (int16_t src);
vint16m8_t vcopy[_v_i16m8] (vint16m8_t src);
vint16m8_t vsplat_s_i16m8 (int16_t src);
vint32m1_t vcopy[_v_i32m1] (vint32m1_t src);
vint32m1_t vsplat_s_i32m1 (int32_t src);
vint32m2_t vcopy[_v_i32m2] (vint32m2_t src);
vint32m2_t vsplat_s_i32m2 (int32_t src);
vint32m4_t vcopy[_v_i32m4] (vint32m4_t src);
vint32m4_t vsplat_s_i32m4 (int32_t src);
vint32m8_t vcopy[_v_i32m8] (vint32m8_t src);
vint32m8_t vsplat_s_i32m8 (int32_t src);
vint64m1_t vcopy[_v_i64m1] (vint64m1_t src);
vint64m1_t vsplat_s_i64m1 (int64_t src);
vint64m2_t vcopy[_v_i64m2] (vint64m2_t src);
vint64m2_t vsplat_s_i64m2 (int64_t src);
vint64m4_t vcopy[_v_i64m4] (vint64m4_t src);
vint64m4_t vsplat_s_i64m4 (int64_t src);
vint64m8_t vcopy[_v_i64m8] (vint64m8_t src);
vint64m8_t vsplat_s_i64m8 (int64_t src);
vuint8m1_t vcopy[_v_u8m1] (vuint8m1_t src);
vuint8m1_t vsplat_s_u8m1 (uint8_t src);
vuint8m2_t vcopy[_v_u8m2] (vuint8m2_t src);
vuint8m2_t vsplat_s_u8m2 (uint8_t src);
vuint8m4_t vcopy[_v_u8m4] (vuint8m4_t src);
vuint8m4_t vsplat_s_u8m4 (uint8_t src);
vuint8m8_t vcopy[_v_u8m8] (vuint8m8_t src);
vuint8m8_t vsplat_s_u8m8 (uint8_t src);
vuint16m1_t vcopy[_v_u16m1] (vuint16m1_t src);
vuint16m1_t vsplat_s_u16m1 (uint16_t src);
vuint16m2_t vcopy[_v_u16m2] (vuint16m2_t src);
vuint16m2_t vsplat_s_u16m2 (uint16_t src);
vuint16m4_t vcopy[_v_u16m4] (vuint16m4_t src);
vuint16m4_t vsplat_s_u16m4 (uint16_t src);
vuint16m8_t vcopy[_v_u16m8] (vuint16m8_t src);
vuint16m8_t vsplat_s_u16m8 (uint16_t src);
vuint32m1_t vcopy[_v_u32m1] (vuint32m1_t src);
vuint32m1_t vsplat_s_u32m1 (uint32_t src);
vuint32m2_t vcopy[_v_u32m2] (vuint32m2_t src);
vuint32m2_t vsplat_s_u32m2 (uint32_t src);
vuint32m4_t vcopy[_v_u32m4] (vuint32m4_t src);
vuint32m4_t vsplat_s_u32m4 (uint32_t src);
vuint32m8_t vcopy[_v_u32m8] (vuint32m8_t src);
vuint32m8_t vsplat_s_u32m8 (uint32_t src);
vuint64m1_t vcopy[_v_u64m1] (vuint64m1_t src);
vuint64m1_t vsplat_s_u64m1 (uint64_t src);
vuint64m2_t vcopy[_v_u64m2] (vuint64m2_t src);
vuint64m2_t vsplat_s_u64m2 (uint64_t src);
vuint64m4_t vcopy[_v_u64m4] (vuint64m4_t src);
vuint64m4_t vsplat_s_u64m4 (uint64_t src);
vuint64m8_t vcopy[_v_u64m8] (vuint64m8_t src);
vuint64m8_t vsplat_s_u64m8 (uint64_t src);
```
## Vector Fixed-Point Arithmetic Functions:

### Vector Single-Width Saturating Add and Subtract Functions:

**Prototypes:**
``` C
vint8m1_t vsadd[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsadd[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsadd[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsadd[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsadd[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsadd[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsadd[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsadd[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsadd[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsadd[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsadd[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsadd[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsadd[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsadd[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsadd[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsadd[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vssub[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vssub[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vssub[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vssub[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vssub[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vssub[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vssub[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vssub[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vssub[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vssub[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vssub[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vssub[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vssub[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vssub[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vssub[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vssub[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vsadd[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsadd[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsadd[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsadd[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsadd[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsadd[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsadd[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsadd[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsadd[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsadd[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsadd[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsadd[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsadd[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsadd[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsadd[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsadd[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsadd[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsadd[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsadd[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsadd[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsadd[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsadd[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsadd[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsadd[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsadd[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsadd[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsadd[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsadd[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsadd[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsadd[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsadd[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsadd[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vsadd[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vsadd[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vsadd[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vsadd[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vsadd[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vsadd[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vsadd[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vsadd[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vsadd[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vsadd[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vsadd[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vsadd[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vsadd[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vsadd[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vsadd[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vsadd[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vsadd[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vsadd[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vsadd[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vsadd[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vsadd[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vsadd[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vsadd[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vsadd[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vsadd[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vsadd[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vsadd[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vsadd[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vsadd[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vsadd[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vsadd[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vsadd[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssub[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssub[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssub[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssub[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssub[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssub[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssub[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssub[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssub[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssub[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssub[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssub[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssub[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssub[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssub[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssub[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssub[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssub[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssub[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssub[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssub[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssub[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssub[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssub[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssub[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssub[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssub[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssub[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssub[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssub[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssub[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssub[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vssub[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssub[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssub[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssub[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssub[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssub[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssub[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssub[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssub[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssub[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssub[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssub[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssub[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssub[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssub[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssub[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssub[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssub[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssub[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssub[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssub[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssub[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssub[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssub[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssub[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssub[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssub[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssub[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssub[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssub[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssub[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssub[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Single-Width Averaging Add and Subtract Functions:

**Prototypes:**
``` C
vint8m1_t vaadd[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vaadd[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vaadd[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vaadd[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vaadd[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vaadd[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vaadd[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vaadd[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vaadd[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vaadd[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vaadd[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vaadd[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vaadd[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vaadd[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vaadd[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vaadd[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vasub[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vasub[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vasub[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vasub[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vasub[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vasub[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vasub[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vasub[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vasub[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vasub[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vasub[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vasub[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vasub[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vasub[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vasub[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub[_vs_i64m8] (vint64m8_t op1, int64_t op2);
vuint8m1_t vasub[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vaadd[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vaadd[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vaadd[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vaadd[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vaadd[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vaadd[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vaadd[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vaadd[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vaadd[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vaadd[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vaadd[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vaadd[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vaadd[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vaadd[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vaadd[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vaadd[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vaadd[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vaadd[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vaadd[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vaadd[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vaadd[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vaadd[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vaadd[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vaadd[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vaadd[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vaadd[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vaadd[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vaadd[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vaadd[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vaadd[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vaadd[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vaadd[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vaadd[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vaadd[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vaadd[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vaadd[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vaadd[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vaadd[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vaadd[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vaadd[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vaadd[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vaadd[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vaadd[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vaadd[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vaadd[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vaadd[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vaadd[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vaadd[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vaadd[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vaadd[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vaadd[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vaadd[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vaadd[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vaadd[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vaadd[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vaadd[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vaadd[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vaadd[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vaadd[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vaadd[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vaadd[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vaadd[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vaadd[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vaadd[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vasub[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vasub[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vasub[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vasub[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vasub[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vasub[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vasub[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vasub[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vasub[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vasub[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vasub[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vasub[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vasub[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vasub[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vasub[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vasub[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vasub[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vasub[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vasub[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vasub[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vasub[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vasub[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vasub[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vasub[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vasub[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vasub[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vasub[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vasub[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vasub[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vasub[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vasub[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vasub[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
vuint8m1_t vasub[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vasub[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vasub[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vasub[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vasub[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vasub[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vasub[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vasub[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vasub[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vasub[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vasub[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vasub[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vasub[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vasub[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vasub[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vasub[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vasub[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vasub[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vasub[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vasub[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vasub[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vasub[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vasub[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vasub[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vasub[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vasub[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vasub[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vasub[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vasub[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vasub[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vasub[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vasub[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
```
### Vector Single-Width Fractional Multiply with Rounding and Saturation Functions:

**Prototypes:**
``` C
vint8m1_t vsmul[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vsmul[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vsmul[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vsmul[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vsmul[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vsmul[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vsmul[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vsmul[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vsmul[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vsmul[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vsmul[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vsmul[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vsmul[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vsmul[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vsmul[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vsmul[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul[_vs_i64m8] (vint64m8_t op1, int64_t op2);
// masked functions
vint8m1_t vsmul[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vsmul[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vsmul[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vsmul[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vsmul[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vsmul[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vsmul[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vsmul[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vsmul[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vsmul[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vsmul[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vsmul[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vsmul[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vsmul[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vsmul[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vsmul[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vsmul[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vsmul[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vsmul[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vsmul[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vsmul[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vsmul[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vsmul[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vsmul[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vsmul[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vsmul[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vsmul[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vsmul[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vsmul[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vsmul[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vsmul[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vsmul[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### Vector Single-Width Scaling Shift Functions:

**Prototypes:**
``` C
vuint8m1_t vssrl[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra[_vv_i8m1] (vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra[_vs_i8m1] (vint8m1_t op1, int8_t op2);
vint8m2_t vssra[_vv_i8m2] (vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra[_vs_i8m2] (vint8m2_t op1, int8_t op2);
vint8m4_t vssra[_vv_i8m4] (vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra[_vs_i8m4] (vint8m4_t op1, int8_t op2);
vint8m8_t vssra[_vv_i8m8] (vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra[_vs_i8m8] (vint8m8_t op1, int8_t op2);
vint16m1_t vssra[_vv_i16m1] (vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra[_vs_i16m1] (vint16m1_t op1, int16_t op2);
vint16m2_t vssra[_vv_i16m2] (vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra[_vs_i16m2] (vint16m2_t op1, int16_t op2);
vint16m4_t vssra[_vv_i16m4] (vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra[_vs_i16m4] (vint16m4_t op1, int16_t op2);
vint16m8_t vssra[_vv_i16m8] (vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra[_vs_i16m8] (vint16m8_t op1, int16_t op2);
vint32m1_t vssra[_vv_i32m1] (vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra[_vs_i32m1] (vint32m1_t op1, int32_t op2);
vint32m2_t vssra[_vv_i32m2] (vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra[_vs_i32m2] (vint32m2_t op1, int32_t op2);
vint32m4_t vssra[_vv_i32m4] (vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra[_vs_i32m4] (vint32m4_t op1, int32_t op2);
vint32m8_t vssra[_vv_i32m8] (vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra[_vs_i32m8] (vint32m8_t op1, int32_t op2);
vint64m1_t vssra[_vv_i64m1] (vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra[_vs_i64m1] (vint64m1_t op1, int64_t op2);
vint64m2_t vssra[_vv_i64m2] (vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra[_vs_i64m2] (vint64m2_t op1, int64_t op2);
vint64m4_t vssra[_vv_i64m4] (vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra[_vs_i64m4] (vint64m4_t op1, int64_t op2);
vint64m8_t vssra[_vv_i64m8] (vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra[_vs_i64m8] (vint64m8_t op1, int64_t op2);
// masked functions
vuint8m1_t vssrl[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vssrl[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vssrl[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vssrl[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vssrl[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vssrl[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vssrl[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vssrl[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vssrl[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vssrl[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vssrl[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vssrl[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vssrl[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vssrl[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vssrl[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vssrl[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vssrl[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vssrl[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vssrl[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vssrl[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vssrl[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vssrl[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vssrl[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vssrl[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vssrl[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vssrl[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vssrl[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vssrl[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vssrl[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vssrl[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vssrl[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vssrl[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vint8m1_t vssra[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vint8m1_t op2);
vint8m1_t vssra[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, int8_t op2);
vint8m2_t vssra[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vint8m2_t op2);
vint8m2_t vssra[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, int8_t op2);
vint8m4_t vssra[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vint8m4_t op2);
vint8m4_t vssra[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, int8_t op2);
vint8m8_t vssra[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vint8m8_t op2);
vint8m8_t vssra[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, int8_t op2);
vint16m1_t vssra[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vint16m1_t op2);
vint16m1_t vssra[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, int16_t op2);
vint16m2_t vssra[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vint16m2_t op2);
vint16m2_t vssra[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, int16_t op2);
vint16m4_t vssra[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vint16m4_t op2);
vint16m4_t vssra[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, int16_t op2);
vint16m8_t vssra[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vint16m8_t op2);
vint16m8_t vssra[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, int16_t op2);
vint32m1_t vssra[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vint32m1_t op2);
vint32m1_t vssra[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, int32_t op2);
vint32m2_t vssra[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vint32m2_t op2);
vint32m2_t vssra[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, int32_t op2);
vint32m4_t vssra[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vint32m4_t op2);
vint32m4_t vssra[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, int32_t op2);
vint32m8_t vssra[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vint32m8_t op2);
vint32m8_t vssra[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, int32_t op2);
vint64m1_t vssra[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vint64m1_t op2);
vint64m1_t vssra[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, int64_t op2);
vint64m2_t vssra[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vint64m2_t op2);
vint64m2_t vssra[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, int64_t op2);
vint64m4_t vssra[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vint64m4_t op2);
vint64m4_t vssra[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, int64_t op2);
vint64m8_t vssra[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vint64m8_t op2);
vint64m8_t vssra[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, int64_t op2);
```
### Vector Narrowing Fixed-Point Clip Functions:

**Prototypes:**
``` C
vint8m1_t vnclip[_wv_i16m2] (vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip[_ws_i16m2] (vint16m2_t op1, int8_t op2);
vint8m2_t vnclip[_wv_i16m4] (vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip[_ws_i16m4] (vint16m4_t op1, int8_t op2);
vint8m4_t vnclip[_wv_i16m8] (vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip[_ws_i16m8] (vint16m8_t op1, int8_t op2);
vint16m1_t vnclip[_wv_i32m2] (vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip[_ws_i32m2] (vint32m2_t op1, int16_t op2);
vint16m2_t vnclip[_wv_i32m4] (vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip[_ws_i32m4] (vint32m4_t op1, int16_t op2);
vint16m4_t vnclip[_wv_i32m8] (vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip[_ws_i32m8] (vint32m8_t op1, int16_t op2);
vint32m1_t vnclip[_wv_i64m2] (vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip[_ws_i64m2] (vint64m2_t op1, int32_t op2);
vint32m2_t vnclip[_wv_i64m4] (vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip[_ws_i64m4] (vint64m4_t op1, int32_t op2);
vint32m4_t vnclip[_wv_i64m8] (vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip[_ws_i64m8] (vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip[_wv_u16m2] (vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip[_ws_u16m2] (vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip[_wv_u16m4] (vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip[_ws_u16m4] (vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip[_wv_u16m8] (vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip[_ws_u16m8] (vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip[_wv_u32m2] (vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip[_ws_u32m2] (vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip[_wv_u32m4] (vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip[_ws_u32m4] (vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip[_wv_u32m8] (vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip[_ws_u32m8] (vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip[_wv_u64m2] (vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip[_ws_u64m2] (vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip[_wv_u64m4] (vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip[_ws_u64m4] (vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip[_wv_u64m8] (vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip[_ws_u64m8] (vuint64m8_t op1, uint32_t op2);
// masked functions
vint8m1_t vnclip[_wv_i16m2]_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, vint8m1_t op2);
vint8m1_t vnclip[_ws_i16m2]_mask (vbool8_t mask, vint8m1_t maskedoff, vint16m2_t op1, int8_t op2);
vint8m2_t vnclip[_wv_i16m4]_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, vint8m2_t op2);
vint8m2_t vnclip[_ws_i16m4]_mask (vbool4_t mask, vint8m2_t maskedoff, vint16m4_t op1, int8_t op2);
vint8m4_t vnclip[_wv_i16m8]_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, vint8m4_t op2);
vint8m4_t vnclip[_ws_i16m8]_mask (vbool2_t mask, vint8m4_t maskedoff, vint16m8_t op1, int8_t op2);
vint16m1_t vnclip[_wv_i32m2]_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, vint16m1_t op2);
vint16m1_t vnclip[_ws_i32m2]_mask (vbool16_t mask, vint16m1_t maskedoff, vint32m2_t op1, int16_t op2);
vint16m2_t vnclip[_wv_i32m4]_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, vint16m2_t op2);
vint16m2_t vnclip[_ws_i32m4]_mask (vbool8_t mask, vint16m2_t maskedoff, vint32m4_t op1, int16_t op2);
vint16m4_t vnclip[_wv_i32m8]_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, vint16m4_t op2);
vint16m4_t vnclip[_ws_i32m8]_mask (vbool4_t mask, vint16m4_t maskedoff, vint32m8_t op1, int16_t op2);
vint32m1_t vnclip[_wv_i64m2]_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, vint32m1_t op2);
vint32m1_t vnclip[_ws_i64m2]_mask (vbool32_t mask, vint32m1_t maskedoff, vint64m2_t op1, int32_t op2);
vint32m2_t vnclip[_wv_i64m4]_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, vint32m2_t op2);
vint32m2_t vnclip[_ws_i64m4]_mask (vbool16_t mask, vint32m2_t maskedoff, vint64m4_t op1, int32_t op2);
vint32m4_t vnclip[_wv_i64m8]_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, vint32m4_t op2);
vint32m4_t vnclip[_ws_i64m8]_mask (vbool8_t mask, vint32m4_t maskedoff, vint64m8_t op1, int32_t op2);
vuint8m1_t vnclip[_wv_u16m2]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, vuint8m1_t op2);
vuint8m1_t vnclip[_ws_u16m2]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint16m2_t op1, uint8_t op2);
vuint8m2_t vnclip[_wv_u16m4]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, vuint8m2_t op2);
vuint8m2_t vnclip[_ws_u16m4]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint16m4_t op1, uint8_t op2);
vuint8m4_t vnclip[_wv_u16m8]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, vuint8m4_t op2);
vuint8m4_t vnclip[_ws_u16m8]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint16m8_t op1, uint8_t op2);
vuint16m1_t vnclip[_wv_u32m2]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, vuint16m1_t op2);
vuint16m1_t vnclip[_ws_u32m2]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint32m2_t op1, uint16_t op2);
vuint16m2_t vnclip[_wv_u32m4]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, vuint16m2_t op2);
vuint16m2_t vnclip[_ws_u32m4]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint32m4_t op1, uint16_t op2);
vuint16m4_t vnclip[_wv_u32m8]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, vuint16m4_t op2);
vuint16m4_t vnclip[_ws_u32m8]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint32m8_t op1, uint16_t op2);
vuint32m1_t vnclip[_wv_u64m2]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, vuint32m1_t op2);
vuint32m1_t vnclip[_ws_u64m2]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint64m2_t op1, uint32_t op2);
vuint32m2_t vnclip[_wv_u64m4]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, vuint32m2_t op2);
vuint32m2_t vnclip[_ws_u64m4]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint64m4_t op1, uint32_t op2);
vuint32m4_t vnclip[_wv_u64m8]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, vuint32m4_t op2);
vuint32m4_t vnclip[_ws_u64m8]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint64m8_t op1, uint32_t op2);
```
## Vector floating-Point Functions:

### Vector Single-Width Floating-Point Add/Subtract Functions:

**Prototypes:**
``` C
vfloat16m1_t vadd[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vadd[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vadd[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vadd[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vadd[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vadd[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vadd[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vadd[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vadd[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vadd[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vadd[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vadd[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vadd[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vadd[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vadd[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vadd[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vadd[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vadd[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vadd[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vadd[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vadd[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vadd[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vadd[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vadd[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vadd[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsub[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsub[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsub[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsub[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsub[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsub[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsub[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsub[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsub[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsub[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsub[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsub[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsub[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsub[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsub[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsub[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsub[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsub[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsub[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsub[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsub[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsub[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsub[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsub[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrsub[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrsub[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrsub[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrsub[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrsub[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrsub[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrsub[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrsub[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrsub[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrsub[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrsub[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrsub[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### Vector Widening Floating-Point Add/Subtract Functions:

**Prototypes:**
``` C
vfloat32m2_t vwadd[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd[_wv_f16m1] (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd[_ws_f16m1] (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd[_wv_f16m2] (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd[_ws_f16m2] (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd[_wv_f16m4] (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd[_ws_f16m4] (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd[_wv_f32m1] (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd[_ws_f32m1] (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd[_wv_f32m2] (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd[_ws_f32m2] (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd[_wv_f32m4] (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd[_ws_f32m4] (vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub[_wv_f16m1] (vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub[_ws_f16m1] (vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub[_wv_f16m2] (vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub[_ws_f16m2] (vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub[_wv_f16m4] (vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub[_ws_f16m4] (vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub[_wv_f32m1] (vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub[_ws_f32m1] (vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub[_wv_f32m2] (vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub[_ws_f32m2] (vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub[_wv_f32m4] (vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub[_ws_f32m4] (vfloat64m8_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwadd[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd[_vs_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwadd[_wv_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwadd[_ws_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwadd[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd[_vs_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwadd[_wv_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwadd[_ws_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwadd[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd[_vs_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwadd[_wv_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwadd[_ws_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwadd[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd[_vs_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwadd[_wv_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwadd[_ws_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwadd[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd[_vs_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwadd[_wv_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwadd[_ws_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwadd[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd[_vs_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwadd[_wv_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwadd[_ws_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
vfloat32m2_t vwsub[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub[_vs_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m2_t vwsub[_wv_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat16m1_t op2);
vfloat32m2_t vwsub[_ws_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float16_t op2);
vfloat32m4_t vwsub[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub[_vs_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m4_t vwsub[_wv_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat16m2_t op2);
vfloat32m4_t vwsub[_ws_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float16_t op2);
vfloat32m8_t vwsub[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub[_vs_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat32m8_t vwsub[_wv_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat16m4_t op2);
vfloat32m8_t vwsub[_ws_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float16_t op2);
vfloat64m2_t vwsub[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub[_vs_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m2_t vwsub[_wv_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat32m1_t op2);
vfloat64m2_t vwsub[_ws_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float32_t op2);
vfloat64m4_t vwsub[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub[_vs_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m4_t vwsub[_wv_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat32m2_t op2);
vfloat64m4_t vwsub[_ws_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float32_t op2);
vfloat64m8_t vwsub[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub[_vs_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat64m8_t vwsub[_wv_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat32m4_t op2);
vfloat64m8_t vwsub[_ws_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float32_t op2);
```
### Vector Single-Width Floating-Point Multiply/Divide Functions:

**Prototypes:**
``` C
vfloat16m1_t vmul[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmul[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmul[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmul[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmul[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmul[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmul[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmul[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmul[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmul[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmul[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmul[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmul[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmul[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmul[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmul[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmul[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmul[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmul[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmul[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmul[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmul[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmul[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmul[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmul[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vdiv[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vdiv[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vdiv[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vdiv[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vdiv[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vdiv[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vdiv[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vdiv[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vdiv[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vdiv[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vdiv[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vdiv[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vdiv[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vdiv[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vdiv[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vdiv[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vdiv[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vdiv[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vdiv[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vdiv[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vdiv[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vdiv[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vdiv[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vdiv[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vrdiv[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vrdiv[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vrdiv[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vrdiv[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vrdiv[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vrdiv[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vrdiv[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vrdiv[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vrdiv[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vrdiv[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vrdiv[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vrdiv[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### Vector Widening Floating-Point Multiply Functions:

**Prototypes:**
``` C
vfloat32m2_t vwmul[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
// masked functions
vfloat32m2_t vwmul[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmul[_vs_f16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat32m4_t vwmul[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmul[_vs_f16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat32m8_t vwmul[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmul[_vs_f16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat64m2_t vwmul[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmul[_vs_f32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat64m4_t vwmul[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmul[_vs_f32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat64m8_t vwmul[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmul[_vs_f32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t op1, float32_t op2);
```
### Vector Single-Width Floating-Point Fused Multiply-Add Functions:

**Prototypes:**
``` C
vfloat16m1_t vmacc[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub[_vv_f16m1] (vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub[_sv_f16m1] (vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub[_vv_f16m2] (vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub[_sv_f16m2] (vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub[_vv_f16m4] (vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub[_sv_f16m4] (vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub[_vv_f16m8] (vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub[_sv_f16m8] (vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub[_vv_f32m1] (vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub[_sv_f32m1] (vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub[_vv_f32m2] (vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub[_sv_f32m2] (vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub[_vv_f32m4] (vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub[_sv_f32m4] (vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub[_vv_f32m8] (vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub[_sv_f32m8] (vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub[_vv_f64m1] (vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub[_sv_f64m1] (vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub[_vv_f64m2] (vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub[_sv_f64m2] (vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub[_vv_f64m4] (vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub[_sv_f64m4] (vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub[_vv_f64m8] (vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub[_sv_f64m8] (vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
// masked functions
vfloat16m1_t vmacc[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmacc[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmacc[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmacc[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmacc[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmacc[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmacc[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmacc[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmacc[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmacc[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmacc[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmacc[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmacc[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmacc[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmacc[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmacc[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmacc[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmacc[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmacc[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmacc[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmacc[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmacc[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmacc[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmacc[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmacc[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmacc[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmacc[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmacc[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmacc[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmacc[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmacc[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmacc[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmacc[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmacc[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmacc[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmacc[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmacc[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmacc[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmacc[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmacc[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmacc[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmacc[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmacc[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmacc[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmacc[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmacc[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmacc[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmacc[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsac[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsac[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsac[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsac[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsac[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsac[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsac[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsac[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsac[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsac[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsac[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsac[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsac[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsac[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsac[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsac[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsac[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsac[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsac[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsac[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsac[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsac[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsac[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsac[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsac[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsac[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsac[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsac[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsac[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsac[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsac[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsac[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsac[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsac[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsac[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsac[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsac[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsac[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsac[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsac[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsac[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsac[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsac[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsac[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsac[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsac[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsac[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsac[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmadd[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmadd[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmadd[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmadd[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmadd[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmadd[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmadd[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmadd[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmadd[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmadd[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmadd[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmadd[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmadd[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmadd[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmadd[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmadd[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmadd[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmadd[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmadd[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmadd[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmadd[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmadd[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmadd[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmadd[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmadd[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmadd[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmadd[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmadd[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmadd[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmadd[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmadd[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmadd[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmadd[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmadd[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmadd[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmadd[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmadd[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmadd[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmadd[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmadd[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmadd[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmadd[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmadd[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmadd[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmadd[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmadd[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmadd[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmadd[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vmsub[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmsub[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vmsub[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmsub[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vmsub[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmsub[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vmsub[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmsub[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vmsub[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmsub[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vmsub[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmsub[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vmsub[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmsub[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vmsub[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmsub[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vmsub[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmsub[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vmsub[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmsub[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vmsub[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmsub[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vmsub[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmsub[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
vfloat16m1_t vnmsub[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vnmsub[_sv_f16m1]_mask (vbool16_t mask, vfloat16m1_t acc, float16_t op1, vfloat16m1_t op2);
vfloat16m2_t vnmsub[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vnmsub[_sv_f16m2]_mask (vbool8_t mask, vfloat16m2_t acc, float16_t op1, vfloat16m2_t op2);
vfloat16m4_t vnmsub[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vnmsub[_sv_f16m4]_mask (vbool4_t mask, vfloat16m4_t acc, float16_t op1, vfloat16m4_t op2);
vfloat16m8_t vnmsub[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vnmsub[_sv_f16m8]_mask (vbool2_t mask, vfloat16m8_t acc, float16_t op1, vfloat16m8_t op2);
vfloat32m1_t vnmsub[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vnmsub[_sv_f32m1]_mask (vbool32_t mask, vfloat32m1_t acc, float32_t op1, vfloat32m1_t op2);
vfloat32m2_t vnmsub[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vnmsub[_sv_f32m2]_mask (vbool16_t mask, vfloat32m2_t acc, float32_t op1, vfloat32m2_t op2);
vfloat32m4_t vnmsub[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vnmsub[_sv_f32m4]_mask (vbool8_t mask, vfloat32m4_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m8_t vnmsub[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vnmsub[_sv_f32m8]_mask (vbool4_t mask, vfloat32m8_t acc, float32_t op1, vfloat32m8_t op2);
vfloat64m1_t vnmsub[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vnmsub[_sv_f64m1]_mask (vbool64_t mask, vfloat64m1_t acc, float64_t op1, vfloat64m1_t op2);
vfloat64m2_t vnmsub[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vnmsub[_sv_f64m2]_mask (vbool32_t mask, vfloat64m2_t acc, float64_t op1, vfloat64m2_t op2);
vfloat64m4_t vnmsub[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vnmsub[_sv_f64m4]_mask (vbool16_t mask, vfloat64m4_t acc, float64_t op1, vfloat64m4_t op2);
vfloat64m8_t vnmsub[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vnmsub[_sv_f64m8]_mask (vbool8_t mask, vfloat64m8_t acc, float64_t op1, vfloat64m8_t op2);
```
### Vector Widening Floating-Point Fused Multiply-Add Functions:

**Prototypes:**
``` C
vfloat32m2_t vwmacc[_vv_f16m1] (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc[_sv_f16m1] (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc[_vv_f16m2] (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc[_sv_f16m2] (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc[_vv_f16m4] (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc[_sv_f16m4] (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc[_vv_f32m1] (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc[_sv_f32m1] (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc[_vv_f32m2] (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc[_sv_f32m2] (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc[_vv_f32m4] (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc[_sv_f32m4] (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc[_vv_f16m1] (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc[_sv_f16m1] (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc[_vv_f16m2] (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc[_sv_f16m2] (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc[_vv_f16m4] (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc[_sv_f16m4] (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc[_vv_f32m1] (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc[_sv_f32m1] (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc[_vv_f32m2] (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc[_sv_f32m2] (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc[_vv_f32m4] (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc[_sv_f32m4] (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac[_vv_f16m1] (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac[_sv_f16m1] (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac[_vv_f16m2] (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac[_sv_f16m2] (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac[_vv_f16m4] (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac[_sv_f16m4] (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac[_vv_f32m1] (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac[_sv_f32m1] (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac[_vv_f32m2] (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac[_sv_f32m2] (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac[_vv_f32m4] (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac[_sv_f32m4] (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac[_vv_f16m1] (vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac[_sv_f16m1] (vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac[_vv_f16m2] (vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac[_sv_f16m2] (vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac[_vv_f16m4] (vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac[_sv_f16m4] (vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac[_vv_f32m1] (vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac[_sv_f32m1] (vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac[_vv_f32m2] (vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac[_sv_f32m2] (vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac[_vv_f32m4] (vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac[_sv_f32m4] (vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
// masked functions
vfloat32m2_t vwmacc[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmacc[_sv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmacc[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmacc[_sv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmacc[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmacc[_sv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmacc[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmacc[_sv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmacc[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmacc[_sv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmacc[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmacc[_sv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmacc[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmacc[_sv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmacc[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmacc[_sv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmacc[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmacc[_sv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmacc[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmacc[_sv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmacc[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmacc[_sv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmacc[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmacc[_sv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwmsac[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwmsac[_sv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwmsac[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwmsac[_sv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwmsac[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwmsac[_sv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwmsac[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwmsac[_sv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwmsac[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwmsac[_sv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwmsac[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwmsac[_sv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
vfloat32m2_t vwnmsac[_vv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat32m2_t vwnmsac[_sv_f16m1]_mask (vbool16_t mask, vfloat32m2_t acc, float16_t op1, vfloat16m1_t op2);
vfloat32m4_t vwnmsac[_vv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat32m4_t vwnmsac[_sv_f16m2]_mask (vbool8_t mask, vfloat32m4_t acc, float16_t op1, vfloat16m2_t op2);
vfloat32m8_t vwnmsac[_vv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat32m8_t vwnmsac[_sv_f16m4]_mask (vbool4_t mask, vfloat32m8_t acc, float16_t op1, vfloat16m4_t op2);
vfloat64m2_t vwnmsac[_vv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat64m2_t vwnmsac[_sv_f32m1]_mask (vbool32_t mask, vfloat64m2_t acc, float32_t op1, vfloat32m1_t op2);
vfloat64m4_t vwnmsac[_vv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat64m4_t vwnmsac[_sv_f32m2]_mask (vbool16_t mask, vfloat64m4_t acc, float32_t op1, vfloat32m2_t op2);
vfloat64m8_t vwnmsac[_vv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat64m8_t vwnmsac[_sv_f32m4]_mask (vbool8_t mask, vfloat64m8_t acc, float32_t op1, vfloat32m4_t op2);
```
### Vector Floating-Point Square-Root Functions:

**Prototypes:**
``` C
vfloat16m1_t vsqrt[_v_f16m1] (vfloat16m1_t op1);
vfloat16m2_t vsqrt[_v_f16m2] (vfloat16m2_t op1);
vfloat16m4_t vsqrt[_v_f16m4] (vfloat16m4_t op1);
vfloat16m8_t vsqrt[_v_f16m8] (vfloat16m8_t op1);
vfloat32m1_t vsqrt[_v_f32m1] (vfloat32m1_t op1);
vfloat32m2_t vsqrt[_v_f32m2] (vfloat32m2_t op1);
vfloat32m4_t vsqrt[_v_f32m4] (vfloat32m4_t op1);
vfloat32m8_t vsqrt[_v_f32m8] (vfloat32m8_t op1);
vfloat64m1_t vsqrt[_v_f64m1] (vfloat64m1_t op1);
vfloat64m2_t vsqrt[_v_f64m2] (vfloat64m2_t op1);
vfloat64m4_t vsqrt[_v_f64m4] (vfloat64m4_t op1);
vfloat64m8_t vsqrt[_v_f64m8] (vfloat64m8_t op1);
// masked functions
vfloat16m1_t vsqrt[_v_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1);
vfloat16m2_t vsqrt[_v_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1);
vfloat16m4_t vsqrt[_v_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1);
vfloat16m8_t vsqrt[_v_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1);
vfloat32m1_t vsqrt[_v_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1);
vfloat32m2_t vsqrt[_v_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1);
vfloat32m4_t vsqrt[_v_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1);
vfloat32m8_t vsqrt[_v_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1);
vfloat64m1_t vsqrt[_v_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1);
vfloat64m2_t vsqrt[_v_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1);
vfloat64m4_t vsqrt[_v_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1);
vfloat64m8_t vsqrt[_v_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1);
```
### Vector Floating-Point MIN/MAX Functions:

**Prototypes:**
``` C
vfloat16m1_t vmin[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vmin[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmin[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmin[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmin[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmin[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmin[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmin[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmin[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmin[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmin[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmin[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmin[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmin[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmin[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmin[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmin[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmin[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmin[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmin[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmin[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmin[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmin[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmin[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmin[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vmax[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vmax[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmax[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vmax[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmax[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vmax[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmax[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vmax[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmax[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vmax[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmax[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vmax[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmax[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vmax[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmax[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vmax[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmax[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vmax[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmax[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vmax[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmax[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vmax[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmax[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vmax[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### Vector Floating-Point Sign-Injection Functions:

**Prototypes:**
``` C
vfloat16m1_t vsgnj[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
// masked functions
vfloat16m1_t vsgnj[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnj[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnj[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnj[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnj[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnj[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnj[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnj[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnj[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnj[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnj[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnj[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnj[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnj[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnj[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnj[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnj[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnj[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnj[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnj[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnj[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnj[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnj[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnj[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjn[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjn[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjn[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjn[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjn[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjn[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjn[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjn[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjn[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjn[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjn[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjn[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjn[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjn[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjn[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjn[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjn[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjn[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjn[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjn[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjn[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjn[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjn[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjn[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vfloat16m1_t vsgnjx[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vfloat16m1_t vsgnjx[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vsgnjx[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vfloat16m2_t vsgnjx[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vsgnjx[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vfloat16m4_t vsgnjx[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vsgnjx[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vfloat16m8_t vsgnjx[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vsgnjx[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vfloat32m1_t vsgnjx[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vsgnjx[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vfloat32m2_t vsgnjx[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vsgnjx[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vfloat32m4_t vsgnjx[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vsgnjx[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vfloat32m8_t vsgnjx[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vsgnjx[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vfloat64m1_t vsgnjx[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vsgnjx[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vfloat64m2_t vsgnjx[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vsgnjx[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vfloat64m4_t vsgnjx[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vsgnjx[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vfloat64m8_t vsgnjx[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### Vector Floating-Point Compare Functions:

**Prototypes:**
``` C
vbool16_t vseteq[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge[_vv_f16m1] (vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge[_vs_f16m1] (vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge[_vv_f16m2] (vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge[_vs_f16m2] (vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge[_vv_f16m4] (vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge[_vs_f16m4] (vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge[_vv_f16m8] (vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge[_vs_f16m8] (vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge[_vv_f32m1] (vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge[_vs_f32m1] (vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge[_vv_f32m2] (vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge[_vs_f32m2] (vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge[_vv_f32m4] (vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge[_vs_f32m4] (vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge[_vv_f32m8] (vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge[_vs_f32m8] (vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge[_vv_f64m1] (vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge[_vs_f64m1] (vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge[_vv_f64m2] (vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge[_vs_f64m2] (vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge[_vv_f64m4] (vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge[_vs_f64m4] (vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge[_vv_f64m8] (vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge[_vs_f64m8] (vfloat64m8_t op1, float64_t op2);
// masked functions
vbool16_t vseteq[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vseteq[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vseteq[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vseteq[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vseteq[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vseteq[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vseteq[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vseteq[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vseteq[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vseteq[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vseteq[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vseteq[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vseteq[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vseteq[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vseteq[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vseteq[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vseteq[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vseteq[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vseteq[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vseteq[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vseteq[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vseteq[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vseteq[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vseteq[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetne[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetne[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetne[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetne[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetne[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetne[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetne[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetne[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetne[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetne[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetne[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetne[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetne[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetne[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetne[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetne[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetne[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetne[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetne[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetne[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetne[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetne[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetne[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetne[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetlt[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetlt[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetlt[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetlt[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetlt[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetlt[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetlt[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetlt[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetlt[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetlt[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetlt[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetlt[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetlt[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetlt[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetlt[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetlt[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetlt[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetlt[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetlt[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetlt[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetlt[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetlt[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetlt[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetlt[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetle[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetle[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetle[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetle[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetle[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetle[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetle[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetle[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetle[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetle[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetle[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetle[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetle[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetle[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetle[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetle[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetle[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetle[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetle[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetle[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetle[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetle[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetle[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetle[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetgt[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetgt[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetgt[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetgt[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetgt[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetgt[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetgt[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetgt[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetgt[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetgt[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetgt[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetgt[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetgt[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetgt[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetgt[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetgt[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetgt[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetgt[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetgt[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetgt[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetgt[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetgt[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetgt[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetgt[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
vbool16_t vsetge[_vv_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, vfloat16m1_t op2);
vbool16_t vsetge[_vs_f16m1]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat16m1_t op1, float16_t op2);
vbool8_t vsetge[_vv_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, vfloat16m2_t op2);
vbool8_t vsetge[_vs_f16m2]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat16m2_t op1, float16_t op2);
vbool4_t vsetge[_vv_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, vfloat16m4_t op2);
vbool4_t vsetge[_vs_f16m4]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat16m4_t op1, float16_t op2);
vbool2_t vsetge[_vv_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, vfloat16m8_t op2);
vbool2_t vsetge[_vs_f16m8]_mask (vbool2_t mask, vbool2_t maskedoff, vfloat16m8_t op1, float16_t op2);
vbool32_t vsetge[_vv_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, vfloat32m1_t op2);
vbool32_t vsetge[_vs_f32m1]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat32m1_t op1, float32_t op2);
vbool16_t vsetge[_vv_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, vfloat32m2_t op2);
vbool16_t vsetge[_vs_f32m2]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat32m2_t op1, float32_t op2);
vbool8_t vsetge[_vv_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, vfloat32m4_t op2);
vbool8_t vsetge[_vs_f32m4]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat32m4_t op1, float32_t op2);
vbool4_t vsetge[_vv_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, vfloat32m8_t op2);
vbool4_t vsetge[_vs_f32m8]_mask (vbool4_t mask, vbool4_t maskedoff, vfloat32m8_t op1, float32_t op2);
vbool64_t vsetge[_vv_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, vfloat64m1_t op2);
vbool64_t vsetge[_vs_f64m1]_mask (vbool64_t mask, vbool64_t maskedoff, vfloat64m1_t op1, float64_t op2);
vbool32_t vsetge[_vv_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, vfloat64m2_t op2);
vbool32_t vsetge[_vs_f64m2]_mask (vbool32_t mask, vbool32_t maskedoff, vfloat64m2_t op1, float64_t op2);
vbool16_t vsetge[_vv_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, vfloat64m4_t op2);
vbool16_t vsetge[_vs_f64m4]_mask (vbool16_t mask, vbool16_t maskedoff, vfloat64m4_t op1, float64_t op2);
vbool8_t vsetge[_vv_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, vfloat64m8_t op2);
vbool8_t vsetge[_vs_f64m8]_mask (vbool8_t mask, vbool8_t maskedoff, vfloat64m8_t op1, float64_t op2);
```
### Vector Floating-Point Classify Functions:

**Prototypes:**
``` C
vuint16m1_t vclass[_v_f16m1] (vfloat16m1_t op1);
vuint16m2_t vclass[_v_f16m2] (vfloat16m2_t op1);
vuint16m4_t vclass[_v_f16m4] (vfloat16m4_t op1);
vuint16m8_t vclass[_v_f16m8] (vfloat16m8_t op1);
vuint32m1_t vclass[_v_f32m1] (vfloat32m1_t op1);
vuint32m2_t vclass[_v_f32m2] (vfloat32m2_t op1);
vuint32m4_t vclass[_v_f32m4] (vfloat32m4_t op1);
vuint32m8_t vclass[_v_f32m8] (vfloat32m8_t op1);
vuint64m1_t vclass[_v_f64m1] (vfloat64m1_t op1);
vuint64m2_t vclass[_v_f64m2] (vfloat64m2_t op1);
vuint64m4_t vclass[_v_f64m4] (vfloat64m4_t op1);
vuint64m8_t vclass[_v_f64m8] (vfloat64m8_t op1);
// masked functions
vuint16m1_t vclass[_v_f16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t op1);
vuint16m2_t vclass[_v_f16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t op1);
vuint16m4_t vclass[_v_f16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t op1);
vuint16m8_t vclass[_v_f16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t op1);
vuint32m1_t vclass[_v_f32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t op1);
vuint32m2_t vclass[_v_f32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t op1);
vuint32m4_t vclass[_v_f32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t op1);
vuint32m8_t vclass[_v_f32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t op1);
vuint64m1_t vclass[_v_f64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t op1);
vuint64m2_t vclass[_v_f64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t op1);
vuint64m4_t vclass[_v_f64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t op1);
vuint64m8_t vclass[_v_f64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t op1);
```
### Vector Floating-Point Merge Functions:

**Prototypes:**
``` C
vfloat16m1_t vmerge[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t op1, float16_t op2);
vfloat16m2_t vmerge[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t op1, float16_t op2);
vfloat16m4_t vmerge[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t op1, float16_t op2);
vfloat16m8_t vmerge[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t op1, float16_t op2);
vfloat32m1_t vmerge[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t op1, float32_t op2);
vfloat32m2_t vmerge[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t op1, float32_t op2);
vfloat32m4_t vmerge[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t op1, float32_t op2);
vfloat32m8_t vmerge[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t op1, float32_t op2);
vfloat64m1_t vmerge[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t op1, float64_t op2);
vfloat64m2_t vmerge[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t op1, float64_t op2);
vfloat64m4_t vmerge[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t op1, float64_t op2);
vfloat64m8_t vmerge[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t op1, float64_t op2);
```
### Vector Floating-Point Move Functions:

**Prototypes:**
``` C
vfloat16m1_t vsplat_s_f16m1 (float16_t src);
vfloat16m2_t vsplat_s_f16m2 (float16_t src);
vfloat16m4_t vsplat_s_f16m4 (float16_t src);
vfloat16m8_t vsplat_s_f16m8 (float16_t src);
vfloat32m1_t vsplat_s_f32m1 (float32_t src);
vfloat32m2_t vsplat_s_f32m2 (float32_t src);
vfloat32m4_t vsplat_s_f32m4 (float32_t src);
vfloat32m8_t vsplat_s_f32m8 (float32_t src);
vfloat64m1_t vsplat_s_f64m1 (float64_t src);
vfloat64m2_t vsplat_s_f64m2 (float64_t src);
vfloat64m4_t vsplat_s_f64m4 (float64_t src);
vfloat64m8_t vsplat_s_f64m8 (float64_t src);
```
### Single-Width Floating-Point/Integer Type-Convert Functions:

**Prototypes:**
``` C
vint16m1_t vcvt_i16[_f16_v_16m1] (vfloat16m1_t src);
vint16m2_t vcvt_i16[_f16_v_16m2] (vfloat16m2_t src);
vint16m4_t vcvt_i16[_f16_v_16m4] (vfloat16m4_t src);
vint16m8_t vcvt_i16[_f16_v_16m8] (vfloat16m8_t src);
vuint16m1_t vcvt_u16[_f16_v_16m1] (vfloat16m1_t src);
vuint16m2_t vcvt_u16[_f16_v_16m2] (vfloat16m2_t src);
vuint16m4_t vcvt_u16[_f16_v_16m4] (vfloat16m4_t src);
vuint16m8_t vcvt_u16[_f16_v_16m8] (vfloat16m8_t src);
vfloat16m1_t vcvt_f16[_i16_v_16m1] (vint16m1_t src);
vfloat16m2_t vcvt_f16[_i16_v_16m2] (vint16m2_t src);
vfloat16m4_t vcvt_f16[_i16_v_16m4] (vint16m4_t src);
vfloat16m8_t vcvt_f16[_i16_v_16m8] (vint16m8_t src);
vfloat16m1_t vcvt_f16[_u16_v_16m1] (vuint16m1_t src);
vfloat16m2_t vcvt_f16[_u16_v_16m2] (vuint16m2_t src);
vfloat16m4_t vcvt_f16[_u16_v_16m4] (vuint16m4_t src);
vfloat16m8_t vcvt_f16[_u16_v_16m8] (vuint16m8_t src);
vint32m1_t vcvt_i32[_f32_v_32m1] (vfloat32m1_t src);
vint32m2_t vcvt_i32[_f32_v_32m2] (vfloat32m2_t src);
vint32m4_t vcvt_i32[_f32_v_32m4] (vfloat32m4_t src);
vint32m8_t vcvt_i32[_f32_v_32m8] (vfloat32m8_t src);
vuint32m1_t vcvt_u32[_f32_v_32m1] (vfloat32m1_t src);
vuint32m2_t vcvt_u32[_f32_v_32m2] (vfloat32m2_t src);
vuint32m4_t vcvt_u32[_f32_v_32m4] (vfloat32m4_t src);
vuint32m8_t vcvt_u32[_f32_v_32m8] (vfloat32m8_t src);
vfloat32m1_t vcvt_f32[_i32_v_32m1] (vint32m1_t src);
vfloat32m2_t vcvt_f32[_i32_v_32m2] (vint32m2_t src);
vfloat32m4_t vcvt_f32[_i32_v_32m4] (vint32m4_t src);
vfloat32m8_t vcvt_f32[_i32_v_32m8] (vint32m8_t src);
vfloat32m1_t vcvt_f32[_u32_v_32m1] (vuint32m1_t src);
vfloat32m2_t vcvt_f32[_u32_v_32m2] (vuint32m2_t src);
vfloat32m4_t vcvt_f32[_u32_v_32m4] (vuint32m4_t src);
vfloat32m8_t vcvt_f32[_u32_v_32m8] (vuint32m8_t src);
vint64m1_t vcvt_i64[_f64_v_64m1] (vfloat64m1_t src);
vint64m2_t vcvt_i64[_f64_v_64m2] (vfloat64m2_t src);
vint64m4_t vcvt_i64[_f64_v_64m4] (vfloat64m4_t src);
vint64m8_t vcvt_i64[_f64_v_64m8] (vfloat64m8_t src);
vuint64m1_t vcvt_u64[_f64_v_64m1] (vfloat64m1_t src);
vuint64m2_t vcvt_u64[_f64_v_64m2] (vfloat64m2_t src);
vuint64m4_t vcvt_u64[_f64_v_64m4] (vfloat64m4_t src);
vuint64m8_t vcvt_u64[_f64_v_64m8] (vfloat64m8_t src);
vfloat64m1_t vcvt_f64[_i64_v_64m1] (vint64m1_t src);
vfloat64m2_t vcvt_f64[_i64_v_64m2] (vint64m2_t src);
vfloat64m4_t vcvt_f64[_i64_v_64m4] (vint64m4_t src);
vfloat64m8_t vcvt_f64[_i64_v_64m8] (vint64m8_t src);
vfloat64m1_t vcvt_f64[_u64_v_64m1] (vuint64m1_t src);
vfloat64m2_t vcvt_f64[_u64_v_64m2] (vuint64m2_t src);
vfloat64m4_t vcvt_f64[_u64_v_64m4] (vuint64m4_t src);
vfloat64m8_t vcvt_f64[_u64_v_64m8] (vuint64m8_t src);
// masked functions
vint16m1_t vcvt_i16[_f16_v_16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat16m1_t src);
vint16m2_t vcvt_i16[_f16_v_16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat16m2_t src);
vint16m4_t vcvt_i16[_f16_v_16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat16m4_t src);
vint16m8_t vcvt_i16[_f16_v_16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vfloat16m8_t src);
vuint16m1_t vcvt_u16[_f16_v_16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat16m1_t src);
vuint16m2_t vcvt_u16[_f16_v_16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat16m2_t src);
vuint16m4_t vcvt_u16[_f16_v_16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat16m4_t src);
vuint16m8_t vcvt_u16[_f16_v_16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vfloat16m8_t src);
vfloat16m1_t vcvt_f16[_i16_v_16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint16m1_t src);
vfloat16m2_t vcvt_f16[_i16_v_16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint16m2_t src);
vfloat16m4_t vcvt_f16[_i16_v_16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint16m4_t src);
vfloat16m8_t vcvt_f16[_i16_v_16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vint16m8_t src);
vfloat16m1_t vcvt_f16[_u16_v_16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint16m1_t src);
vfloat16m2_t vcvt_f16[_u16_v_16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint16m2_t src);
vfloat16m4_t vcvt_f16[_u16_v_16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint16m4_t src);
vfloat16m8_t vcvt_f16[_u16_v_16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vuint16m8_t src);
vint32m1_t vcvt_i32[_f32_v_32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat32m1_t src);
vint32m2_t vcvt_i32[_f32_v_32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat32m2_t src);
vint32m4_t vcvt_i32[_f32_v_32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat32m4_t src);
vint32m8_t vcvt_i32[_f32_v_32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat32m8_t src);
vuint32m1_t vcvt_u32[_f32_v_32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat32m1_t src);
vuint32m2_t vcvt_u32[_f32_v_32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat32m2_t src);
vuint32m4_t vcvt_u32[_f32_v_32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat32m4_t src);
vuint32m8_t vcvt_u32[_f32_v_32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat32m8_t src);
vfloat32m1_t vcvt_f32[_i32_v_32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint32m1_t src);
vfloat32m2_t vcvt_f32[_i32_v_32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint32m2_t src);
vfloat32m4_t vcvt_f32[_i32_v_32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint32m4_t src);
vfloat32m8_t vcvt_f32[_i32_v_32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint32m8_t src);
vfloat32m1_t vcvt_f32[_u32_v_32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint32m1_t src);
vfloat32m2_t vcvt_f32[_u32_v_32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint32m2_t src);
vfloat32m4_t vcvt_f32[_u32_v_32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint32m4_t src);
vfloat32m8_t vcvt_f32[_u32_v_32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint32m8_t src);
vint64m1_t vcvt_i64[_f64_v_64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vfloat64m1_t src);
vint64m2_t vcvt_i64[_f64_v_64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat64m2_t src);
vint64m4_t vcvt_i64[_f64_v_64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat64m4_t src);
vint64m8_t vcvt_i64[_f64_v_64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat64m8_t src);
vuint64m1_t vcvt_u64[_f64_v_64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vfloat64m1_t src);
vuint64m2_t vcvt_u64[_f64_v_64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat64m2_t src);
vuint64m4_t vcvt_u64[_f64_v_64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat64m4_t src);
vuint64m8_t vcvt_u64[_f64_v_64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat64m8_t src);
vfloat64m1_t vcvt_f64[_i64_v_64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vint64m1_t src);
vfloat64m2_t vcvt_f64[_i64_v_64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint64m2_t src);
vfloat64m4_t vcvt_f64[_i64_v_64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint64m4_t src);
vfloat64m8_t vcvt_f64[_i64_v_64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint64m8_t src);
vfloat64m1_t vcvt_f64[_u64_v_64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vuint64m1_t src);
vfloat64m2_t vcvt_f64[_u64_v_64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint64m2_t src);
vfloat64m4_t vcvt_f64[_u64_v_64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint64m4_t src);
vfloat64m8_t vcvt_f64[_u64_v_64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint64m8_t src);
```
### Widening Floating-Point/Integer Type-Convert Functions:

**Prototypes:**
``` C
vint32m2_t vcvt_i32[_f16_v_16m1] (vfloat16m1_t src);
vint32m4_t vcvt_i32[_f16_v_16m2] (vfloat16m2_t src);
vint32m8_t vcvt_i32[_f16_v_16m4] (vfloat16m4_t src);
vint32m2_t vcvt_i32[_i16_v_16m1] (vint16m1_t src);
vint32m4_t vcvt_i32[_i16_v_16m2] (vint16m2_t src);
vint32m8_t vcvt_i32[_i16_v_16m4] (vint16m4_t src);
vuint32m2_t vcvt_u32[_u16_v_16m1] (vuint16m1_t src);
vuint32m4_t vcvt_u32[_u16_v_16m2] (vuint16m2_t src);
vuint32m8_t vcvt_u32[_u16_v_16m4] (vuint16m4_t src);
vuint32m2_t vcvt_u32[_f16_v_16m1] (vfloat16m1_t src);
vuint32m4_t vcvt_u32[_f16_v_16m2] (vfloat16m2_t src);
vuint32m8_t vcvt_u32[_f16_v_16m4] (vfloat16m4_t src);
vfloat32m2_t vcvt_f32[_i16_v_16m1] (vint16m1_t src);
vfloat32m4_t vcvt_f32[_i16_v_16m2] (vint16m2_t src);
vfloat32m8_t vcvt_f32[_i16_v_16m4] (vint16m4_t src);
vfloat32m2_t vcvt_f32[_u16_v_16m1] (vuint16m1_t src);
vfloat32m4_t vcvt_f32[_u16_v_16m2] (vuint16m2_t src);
vfloat32m8_t vcvt_f32[_u16_v_16m4] (vuint16m4_t src);
vfloat32m2_t vcvt_f32[_f16_v_16m1] (vfloat16m1_t src);
vfloat32m4_t vcvt_f32[_f16_v_16m2] (vfloat16m2_t src);
vfloat32m8_t vcvt_f32[_f16_v_16m4] (vfloat16m4_t src);
vint64m2_t vcvt_i64[_f32_v_32m1] (vfloat32m1_t src);
vint64m4_t vcvt_i64[_f32_v_32m2] (vfloat32m2_t src);
vint64m8_t vcvt_i64[_f32_v_32m4] (vfloat32m4_t src);
vint64m2_t vcvt_i64[_i32_v_32m1] (vint32m1_t src);
vint64m4_t vcvt_i64[_i32_v_32m2] (vint32m2_t src);
vint64m8_t vcvt_i64[_i32_v_32m4] (vint32m4_t src);
vuint64m2_t vcvt_u64[_u32_v_32m1] (vuint32m1_t src);
vuint64m4_t vcvt_u64[_u32_v_32m2] (vuint32m2_t src);
vuint64m8_t vcvt_u64[_u32_v_32m4] (vuint32m4_t src);
vuint64m2_t vcvt_u64[_f32_v_32m1] (vfloat32m1_t src);
vuint64m4_t vcvt_u64[_f32_v_32m2] (vfloat32m2_t src);
vuint64m8_t vcvt_u64[_f32_v_32m4] (vfloat32m4_t src);
vfloat64m2_t vcvt_f64[_i32_v_32m1] (vint32m1_t src);
vfloat64m4_t vcvt_f64[_i32_v_32m2] (vint32m2_t src);
vfloat64m8_t vcvt_f64[_i32_v_32m4] (vint32m4_t src);
vfloat64m2_t vcvt_f64[_u32_v_32m1] (vuint32m1_t src);
vfloat64m4_t vcvt_f64[_u32_v_32m2] (vuint32m2_t src);
vfloat64m8_t vcvt_f64[_u32_v_32m4] (vuint32m4_t src);
vfloat64m2_t vcvt_f64[_f32_v_32m1] (vfloat32m1_t src);
vfloat64m4_t vcvt_f64[_f32_v_32m2] (vfloat32m2_t src);
vfloat64m8_t vcvt_f64[_f32_v_32m4] (vfloat32m4_t src);
// masked functions
vint32m2_t vcvt_i32[_f16_v_16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat16m1_t src);
vint32m4_t vcvt_i32[_f16_v_16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat16m2_t src);
vint32m8_t vcvt_i32[_f16_v_16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vfloat16m4_t src);
vint32m2_t vcvt_i32[_i16_v_16m1]_mask (vbool16_t mask, vint32m2_t maskedoff, vint16m1_t src);
vint32m4_t vcvt_i32[_i16_v_16m2]_mask (vbool8_t mask, vint32m4_t maskedoff, vint16m2_t src);
vint32m8_t vcvt_i32[_i16_v_16m4]_mask (vbool4_t mask, vint32m8_t maskedoff, vint16m4_t src);
vuint32m2_t vcvt_u32[_u16_v_16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint16m1_t src);
vuint32m4_t vcvt_u32[_u16_v_16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint16m2_t src);
vuint32m8_t vcvt_u32[_u16_v_16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint16m4_t src);
vuint32m2_t vcvt_u32[_f16_v_16m1]_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat16m1_t src);
vuint32m4_t vcvt_u32[_f16_v_16m2]_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat16m2_t src);
vuint32m8_t vcvt_u32[_f16_v_16m4]_mask (vbool4_t mask, vuint32m8_t maskedoff, vfloat16m4_t src);
vfloat32m2_t vcvt_f32[_i16_v_16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint16m1_t src);
vfloat32m4_t vcvt_f32[_i16_v_16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint16m2_t src);
vfloat32m8_t vcvt_f32[_i16_v_16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vint16m4_t src);
vfloat32m2_t vcvt_f32[_u16_v_16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint16m1_t src);
vfloat32m4_t vcvt_f32[_u16_v_16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint16m2_t src);
vfloat32m8_t vcvt_f32[_u16_v_16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vuint16m4_t src);
vfloat32m2_t vcvt_f32[_f16_v_16m1]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat16m1_t src);
vfloat32m4_t vcvt_f32[_f16_v_16m2]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat16m2_t src);
vfloat32m8_t vcvt_f32[_f16_v_16m4]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat16m4_t src);
vint64m2_t vcvt_i64[_f32_v_32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vfloat32m1_t src);
vint64m4_t vcvt_i64[_f32_v_32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vfloat32m2_t src);
vint64m8_t vcvt_i64[_f32_v_32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vfloat32m4_t src);
vint64m2_t vcvt_i64[_i32_v_32m1]_mask (vbool32_t mask, vint64m2_t maskedoff, vint32m1_t src);
vint64m4_t vcvt_i64[_i32_v_32m2]_mask (vbool16_t mask, vint64m4_t maskedoff, vint32m2_t src);
vint64m8_t vcvt_i64[_i32_v_32m4]_mask (vbool8_t mask, vint64m8_t maskedoff, vint32m4_t src);
vuint64m2_t vcvt_u64[_u32_v_32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint32m1_t src);
vuint64m4_t vcvt_u64[_u32_v_32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint32m2_t src);
vuint64m8_t vcvt_u64[_u32_v_32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint32m4_t src);
vuint64m2_t vcvt_u64[_f32_v_32m1]_mask (vbool32_t mask, vuint64m2_t maskedoff, vfloat32m1_t src);
vuint64m4_t vcvt_u64[_f32_v_32m2]_mask (vbool16_t mask, vuint64m4_t maskedoff, vfloat32m2_t src);
vuint64m8_t vcvt_u64[_f32_v_32m4]_mask (vbool8_t mask, vuint64m8_t maskedoff, vfloat32m4_t src);
vfloat64m2_t vcvt_f64[_i32_v_32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vint32m1_t src);
vfloat64m4_t vcvt_f64[_i32_v_32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vint32m2_t src);
vfloat64m8_t vcvt_f64[_i32_v_32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vint32m4_t src);
vfloat64m2_t vcvt_f64[_u32_v_32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vuint32m1_t src);
vfloat64m4_t vcvt_f64[_u32_v_32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vuint32m2_t src);
vfloat64m8_t vcvt_f64[_u32_v_32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vuint32m4_t src);
vfloat64m2_t vcvt_f64[_f32_v_32m1]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat32m1_t src);
vfloat64m4_t vcvt_f64[_f32_v_32m2]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat32m2_t src);
vfloat64m8_t vcvt_f64[_f32_v_32m4]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat32m4_t src);
```
### Narrowing Floating-Point/Integer Type-Convert Functions:

**Prototypes:**
``` C
vint16m1_t vcvt_i16[_f32_v_32m2] (vfloat32m2_t src);
vint16m2_t vcvt_i16[_f32_v_32m4] (vfloat32m4_t src);
vint16m4_t vcvt_i16[_f32_v_32m8] (vfloat32m8_t src);
vuint16m1_t vcvt_u16[_f32_v_32m2] (vfloat32m2_t src);
vuint16m2_t vcvt_u16[_f32_v_32m4] (vfloat32m4_t src);
vuint16m4_t vcvt_u16[_f32_v_32m8] (vfloat32m8_t src);
vfloat16m1_t vcvt_f16[_i32_v_32m2] (vint32m2_t src);
vfloat16m2_t vcvt_f16[_i32_v_32m4] (vint32m4_t src);
vfloat16m4_t vcvt_f16[_i32_v_32m8] (vint32m8_t src);
vfloat16m1_t vcvt_f16[_u32_v_32m2] (vuint32m2_t src);
vfloat16m2_t vcvt_f16[_u32_v_32m4] (vuint32m4_t src);
vfloat16m4_t vcvt_f16[_u32_v_32m8] (vuint32m8_t src);
vfloat16m1_t vcvt_f16[_f32_v_32m2] (vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16[_f32_v_32m2] (vfloat32m2_t src);
vfloat16m2_t vcvt_f16[_f32_v_32m4] (vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16[_f32_v_32m4] (vfloat32m4_t src);
vfloat16m4_t vcvt_f16[_f32_v_32m8] (vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16[_f32_v_32m8] (vfloat32m8_t src);
vint32m1_t vcvt_i32[_f64_v_64m2] (vfloat64m2_t src);
vint32m2_t vcvt_i32[_f64_v_64m4] (vfloat64m4_t src);
vint32m4_t vcvt_i32[_f64_v_64m8] (vfloat64m8_t src);
vuint32m1_t vcvt_u32[_f64_v_64m2] (vfloat64m2_t src);
vuint32m2_t vcvt_u32[_f64_v_64m4] (vfloat64m4_t src);
vuint32m4_t vcvt_u32[_f64_v_64m8] (vfloat64m8_t src);
vfloat32m1_t vcvt_f32[_i64_v_64m2] (vint64m2_t src);
vfloat32m2_t vcvt_f32[_i64_v_64m4] (vint64m4_t src);
vfloat32m4_t vcvt_f32[_i64_v_64m8] (vint64m8_t src);
vfloat32m1_t vcvt_f32[_u64_v_64m2] (vuint64m2_t src);
vfloat32m2_t vcvt_f32[_u64_v_64m4] (vuint64m4_t src);
vfloat32m4_t vcvt_f32[_u64_v_64m8] (vuint64m8_t src);
vfloat32m1_t vcvt_f32[_f64_v_64m2] (vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32[_f64_v_64m2] (vfloat64m2_t src);
vfloat32m2_t vcvt_f32[_f64_v_64m4] (vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32[_f64_v_64m4] (vfloat64m4_t src);
vfloat32m4_t vcvt_f32[_f64_v_64m8] (vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32[_f64_v_64m8] (vfloat64m8_t src);
// masked functions
vint16m1_t vcvt_i16[_f32_v_32m2]_mask (vbool16_t mask, vint16m1_t maskedoff, vfloat32m2_t src);
vint16m2_t vcvt_i16[_f32_v_32m4]_mask (vbool8_t mask, vint16m2_t maskedoff, vfloat32m4_t src);
vint16m4_t vcvt_i16[_f32_v_32m8]_mask (vbool4_t mask, vint16m4_t maskedoff, vfloat32m8_t src);
vuint16m1_t vcvt_u16[_f32_v_32m2]_mask (vbool16_t mask, vuint16m1_t maskedoff, vfloat32m2_t src);
vuint16m2_t vcvt_u16[_f32_v_32m4]_mask (vbool8_t mask, vuint16m2_t maskedoff, vfloat32m4_t src);
vuint16m4_t vcvt_u16[_f32_v_32m8]_mask (vbool4_t mask, vuint16m4_t maskedoff, vfloat32m8_t src);
vfloat16m1_t vcvt_f16[_i32_v_32m2]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vint32m2_t src);
vfloat16m2_t vcvt_f16[_i32_v_32m4]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vint32m4_t src);
vfloat16m4_t vcvt_f16[_i32_v_32m8]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vint32m8_t src);
vfloat16m1_t vcvt_f16[_u32_v_32m2]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vuint32m2_t src);
vfloat16m2_t vcvt_f16[_u32_v_32m4]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vuint32m4_t src);
vfloat16m4_t vcvt_f16[_u32_v_32m8]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vuint32m8_t src);
vfloat16m1_t vcvt_f16[_f32_v_32m2]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m1_t vcvt_rod_f16[_f32_v_32m2]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat32m2_t src);
vfloat16m2_t vcvt_f16[_f32_v_32m4]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m2_t vcvt_rod_f16[_f32_v_32m4]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat32m4_t src);
vfloat16m4_t vcvt_f16[_f32_v_32m8]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vfloat16m4_t vcvt_rod_f16[_f32_v_32m8]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat32m8_t src);
vint32m1_t vcvt_i32[_f64_v_64m2]_mask (vbool32_t mask, vint32m1_t maskedoff, vfloat64m2_t src);
vint32m2_t vcvt_i32[_f64_v_64m4]_mask (vbool16_t mask, vint32m2_t maskedoff, vfloat64m4_t src);
vint32m4_t vcvt_i32[_f64_v_64m8]_mask (vbool8_t mask, vint32m4_t maskedoff, vfloat64m8_t src);
vuint32m1_t vcvt_u32[_f64_v_64m2]_mask (vbool32_t mask, vuint32m1_t maskedoff, vfloat64m2_t src);
vuint32m2_t vcvt_u32[_f64_v_64m4]_mask (vbool16_t mask, vuint32m2_t maskedoff, vfloat64m4_t src);
vuint32m4_t vcvt_u32[_f64_v_64m8]_mask (vbool8_t mask, vuint32m4_t maskedoff, vfloat64m8_t src);
vfloat32m1_t vcvt_f32[_i64_v_64m2]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vint64m2_t src);
vfloat32m2_t vcvt_f32[_i64_v_64m4]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vint64m4_t src);
vfloat32m4_t vcvt_f32[_i64_v_64m8]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vint64m8_t src);
vfloat32m1_t vcvt_f32[_u64_v_64m2]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vuint64m2_t src);
vfloat32m2_t vcvt_f32[_u64_v_64m4]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vuint64m4_t src);
vfloat32m4_t vcvt_f32[_u64_v_64m8]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vuint64m8_t src);
vfloat32m1_t vcvt_f32[_f64_v_64m2]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m1_t vcvt_rod_f32[_f64_v_64m2]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat64m2_t src);
vfloat32m2_t vcvt_f32[_f64_v_64m4]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m2_t vcvt_rod_f32[_f64_v_64m4]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat64m4_t src);
vfloat32m4_t vcvt_f32[_f64_v_64m8]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
vfloat32m4_t vcvt_rod_f32[_f64_v_64m8]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat64m8_t src);
```
## Vector Reduction Functions:

### Vector Single-Width Integer Reduction Functions:

**Prototypes:**
``` C
vint8m1_t vredsum[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor[_vs_i8m1] (vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m2] (vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m4] (vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m8] (vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor[_vs_i16m1] (vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m2] (vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m4] (vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m8] (vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor[_vs_i32m1] (vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m2] (vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m4] (vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m8] (vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor[_vs_i64m1] (vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m2] (vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m4] (vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m8] (vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor[_vs_u8m1] (vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m2] (vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m4] (vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m8] (vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor[_vs_u16m1] (vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m2] (vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m4] (vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m8] (vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor[_vs_u32m1] (vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m2] (vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m4] (vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m8] (vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor[_vs_u64m1] (vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m2] (vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m4] (vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m8] (vuint64m8_t vector, vuint64m1_t scalar);
// masked functions
vint8m1_t vredsum[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredsum[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredsum[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredsum[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredsum[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredsum[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredsum[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredsum[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredsum[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredsum[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredsum[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredsum[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredsum[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredsum[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredsum[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredsum[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmax[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmax[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmax[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmax[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmax[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmax[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmax[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmax[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmax[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmax[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmax[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmax[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmax[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmax[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmax[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmax[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredmin[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredmin[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredmin[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredmin[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredmin[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredmin[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredmin[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredmin[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredmin[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredmin[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredmin[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredmin[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredmin[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredmin[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredmin[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredmin[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredand[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredand[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredand[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredand[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredand[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredand[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredand[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredand[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredand[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredand[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredand[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredand[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredand[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredand[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredand[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredand[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredor[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredor[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredor[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredor[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredor[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredor[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredor[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredor[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredor[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredor[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredor[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredor[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredor[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredor[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredor[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredor[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
vint8m1_t vredxor[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint8m1_t scalar);
vint8m1_t vredxor[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t vector, vint8m1_t scalar);
vint16m1_t vredxor[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint16m1_t scalar);
vint16m1_t vredxor[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t vector, vint16m1_t scalar);
vint32m1_t vredxor[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint32m1_t scalar);
vint32m1_t vredxor[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t vector, vint32m1_t scalar);
vint64m1_t vredxor[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t vector, vint64m1_t scalar);
vint64m1_t vredxor[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t vector, vint64m1_t scalar);
vuint8m1_t vredxor[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint8m1_t scalar);
vuint8m1_t vredxor[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t vector, vuint8m1_t scalar);
vuint16m1_t vredxor[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint16m1_t scalar);
vuint16m1_t vredxor[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t vector, vuint16m1_t scalar);
vuint32m1_t vredxor[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint32m1_t scalar);
vuint32m1_t vredxor[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t vector, vuint32m1_t scalar);
vuint64m1_t vredxor[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t vector, vuint64m1_t scalar);
vuint64m1_t vredxor[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t vector, vuint64m1_t scalar);
```
### Vector Widening Integer Reduction Functions:

**Prototypes:**
``` C
vint16m1_t vwredsum[_vs_i8m1] (vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum[_vs_i8m2] (vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum[_vs_i8m4] (vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum[_vs_i16m1] (vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum[_vs_i16m2] (vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum[_vs_i16m4] (vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum[_vs_i32m1] (vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum[_vs_i32m2] (vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum[_vs_i32m4] (vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m1] (vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m2] (vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m4] (vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m1] (vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m2] (vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m4] (vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m1] (vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m2] (vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m4] (vuint32m4_t vector, vuint64m1_t scalar);
// masked functions
vint16m1_t vwredsum[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t vector, vint16m1_t scalar);
vint16m1_t vwredsum[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t vector, vint16m1_t scalar);
vint16m1_t vwredsum[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t vector, vint16m1_t scalar);
vint32m1_t vwredsum[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t vector, vint32m1_t scalar);
vint32m1_t vwredsum[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t vector, vint32m1_t scalar);
vint32m1_t vwredsum[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t vector, vint32m1_t scalar);
vint64m1_t vwredsum[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t vector, vint64m1_t scalar);
vint64m1_t vwredsum[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t vector, vint64m1_t scalar);
vint64m1_t vwredsum[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t vector, vint64m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t vector, vuint16m1_t scalar);
vuint16m1_t vwredsum[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t vector, vuint16m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t vector, vuint32m1_t scalar);
vuint32m1_t vwredsum[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t vector, vuint32m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t vector, vuint64m1_t scalar);
vuint64m1_t vwredsum[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t vector, vuint64m1_t scalar);
```
### Vector Single-Width Floating-Point Reduction Functions:

**Prototypes:**
``` C
vfloat16m1_t vredosum[_vs_f16m1] (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m2] (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m4] (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m8] (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m1] (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m2] (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m4] (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m8] (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m1] (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m2] (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m4] (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m8] (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m1] (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m2] (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m4] (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m8] (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m1] (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m2] (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m4] (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m8] (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m1] (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m2] (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m4] (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m8] (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m1] (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m2] (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m4] (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m8] (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m1] (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m2] (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m4] (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m8] (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m1] (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m2] (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m4] (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m8] (vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m1] (vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m2] (vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m4] (vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m8] (vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m1] (vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m2] (vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m4] (vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m8] (vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m1] (vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m2] (vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m4] (vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m8] (vfloat64m8_t vector, vfloat64m1_t scalar);
// masked functions
vfloat16m1_t vredosum[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredosum[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredosum[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredosum[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredsum[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredsum[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredsum[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmax[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmax[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmax[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat16m1_t scalar);
vfloat16m1_t vredmin[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t vector, vfloat16m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat32m1_t scalar);
vfloat32m1_t vredmin[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t vector, vfloat32m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t vector, vfloat64m1_t scalar);
vfloat64m1_t vredmin[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t vector, vfloat64m1_t scalar);
```
### Vector Widening Floating-Point Reduction Functions:

**Prototypes:**
``` C
vfloat32m1_t vwredosum[_vs_f16m1] (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum[_vs_f16m2] (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum[_vs_f16m4] (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m1] (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m2] (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m4] (vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m1] (vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m2] (vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m4] (vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m1] (vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m2] (vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m4] (vfloat32m4_t vector, vfloat64m1_t scalar);
// masked functions
vfloat32m1_t vwredosum[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredosum[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredosum[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t vector, vfloat32m1_t scalar);
vfloat32m1_t vwredsum[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t vector, vfloat32m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t vector, vfloat64m1_t scalar);
vfloat64m1_t vwredsum[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t vector, vfloat64m1_t scalar);
```
## Vector Mask Functions:

### Vector Mask-Register Logical Functions:

**Prototypes:**
``` C
vbool1_t vand[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vand[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vand[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vand[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vand[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vand[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vand[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vnand[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vnand[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vnand[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vnand[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vnand[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vnand[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vnand[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vandnot[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vandnot[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vandnot[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vandnot[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vandnot[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vandnot[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vandnot[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vxor[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vxor[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vxor[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vxor[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vxor[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vxor[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vxor[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vor[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vor[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vor[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vor[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vor[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vor[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vor[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vnor[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vnor[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vnor[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vnor[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vnor[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vnor[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vnor[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vornot[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vornot[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vornot[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vornot[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vornot[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vornot[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vornot[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vxnor[_mm_b1] (vbool1_t op1, vbool1_t op2);
vbool2_t vxnor[_mm_b2] (vbool2_t op1, vbool2_t op2);
vbool4_t vxnor[_mm_b4] (vbool4_t op1, vbool4_t op2);
vbool8_t vxnor[_mm_b8] (vbool8_t op1, vbool8_t op2);
vbool16_t vxnor[_mm_b16] (vbool16_t op1, vbool16_t op2);
vbool32_t vxnor[_mm_b32] (vbool32_t op1, vbool32_t op2);
vbool64_t vxnor[_mm_b64] (vbool64_t op1, vbool64_t op2);
vbool1_t vcpy[_m_b1] (vbool1_t op1);
vbool2_t vcpy[_m_b2] (vbool2_t op1);
vbool4_t vcpy[_m_b4] (vbool4_t op1);
vbool8_t vcpy[_m_b8] (vbool8_t op1);
vbool16_t vcpy[_m_b16] (vbool16_t op1);
vbool32_t vcpy[_m_b32] (vbool32_t op1);
vbool64_t vcpy[_m_b64] (vbool64_t op1);
vbool1_t vclr_b1 ();
vbool2_t vclr_b2 ();
vbool4_t vclr_b4 ();
vbool8_t vclr_b8 ();
vbool16_t vclr_b16 ();
vbool32_t vclr_b32 ();
vbool64_t vclr_b64 ();
vbool1_t vset_b1 ();
vbool2_t vset_b2 ();
vbool4_t vset_b4 ();
vbool8_t vset_b8 ();
vbool16_t vset_b16 ();
vbool32_t vset_b32 ();
vbool64_t vset_b64 ();
vbool1_t vnot[_m_b1] (vbool1_t op1);
vbool2_t vnot[_m_b2] (vbool2_t op1);
vbool4_t vnot[_m_b4] (vbool4_t op1);
vbool8_t vnot[_m_b8] (vbool8_t op1);
vbool16_t vnot[_m_b16] (vbool16_t op1);
vbool32_t vnot[_m_b32] (vbool32_t op1);
vbool64_t vnot[_m_b64] (vbool64_t op1);
```
### Vector mask population count Functions:

**Prototypes:**
``` C
unsigned long vpopc[_m_b1] (vbool1_t op1);
unsigned long vpopc[_m_b2] (vbool2_t op1);
unsigned long vpopc[_m_b4] (vbool4_t op1);
unsigned long vpopc[_m_b8] (vbool8_t op1);
unsigned long vpopc[_m_b16] (vbool16_t op1);
unsigned long vpopc[_m_b32] (vbool32_t op1);
unsigned long vpopc[_m_b64] (vbool64_t op1);
// masked functions
unsigned long vpopc[_m_b1]_mask (vbool1_t mask, vbool1_t op1);
unsigned long vpopc[_m_b2]_mask (vbool2_t mask, vbool2_t op1);
unsigned long vpopc[_m_b4]_mask (vbool4_t mask, vbool4_t op1);
unsigned long vpopc[_m_b8]_mask (vbool8_t mask, vbool8_t op1);
unsigned long vpopc[_m_b16]_mask (vbool16_t mask, vbool16_t op1);
unsigned long vpopc[_m_b32]_mask (vbool32_t mask, vbool32_t op1);
unsigned long vpopc[_m_b64]_mask (vbool64_t mask, vbool64_t op1);
```
### Find-first-set mask bit Functions:

**Prototypes:**
``` C
long vfirst[_m_b1] (vbool1_t op1);
long vfirst[_m_b2] (vbool2_t op1);
long vfirst[_m_b4] (vbool4_t op1);
long vfirst[_m_b8] (vbool8_t op1);
long vfirst[_m_b16] (vbool16_t op1);
long vfirst[_m_b32] (vbool32_t op1);
long vfirst[_m_b64] (vbool64_t op1);
// masked functions
long vfirst[_m_b1]_mask (vbool1_t mask, vbool1_t op1);
long vfirst[_m_b2]_mask (vbool2_t mask, vbool2_t op1);
long vfirst[_m_b4]_mask (vbool4_t mask, vbool4_t op1);
long vfirst[_m_b8]_mask (vbool8_t mask, vbool8_t op1);
long vfirst[_m_b16]_mask (vbool16_t mask, vbool16_t op1);
long vfirst[_m_b32]_mask (vbool32_t mask, vbool32_t op1);
long vfirst[_m_b64]_mask (vbool64_t mask, vbool64_t op1);
```
### Set-before-first mask bit Functions:

**Prototypes:**
``` C
vbool1_t vsbf[_m_b1] (vbool1_t op1);
vbool2_t vsbf[_m_b2] (vbool2_t op1);
vbool4_t vsbf[_m_b4] (vbool4_t op1);
vbool8_t vsbf[_m_b8] (vbool8_t op1);
vbool16_t vsbf[_m_b16] (vbool16_t op1);
vbool32_t vsbf[_m_b32] (vbool32_t op1);
vbool64_t vsbf[_m_b64] (vbool64_t op1);
// masked functions
vbool1_t vsbf[_m_b1]_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsbf[_m_b2]_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsbf[_m_b4]_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsbf[_m_b8]_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsbf[_m_b16]_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsbf[_m_b32]_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsbf[_m_b64]_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### Set-including-first mask bit Functions:

**Prototypes:**
``` C
vbool1_t vsif[_m_b1] (vbool1_t op1);
vbool2_t vsif[_m_b2] (vbool2_t op1);
vbool4_t vsif[_m_b4] (vbool4_t op1);
vbool8_t vsif[_m_b8] (vbool8_t op1);
vbool16_t vsif[_m_b16] (vbool16_t op1);
vbool32_t vsif[_m_b32] (vbool32_t op1);
vbool64_t vsif[_m_b64] (vbool64_t op1);
// masked functions
vbool1_t vsif[_m_b1]_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsif[_m_b2]_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsif[_m_b4]_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsif[_m_b8]_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsif[_m_b16]_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsif[_m_b32]_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsif[_m_b64]_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### Set-only-first mask bit Functions:

**Prototypes:**
``` C
vbool1_t vsof[_m_b1] (vbool1_t op1);
vbool2_t vsof[_m_b2] (vbool2_t op1);
vbool4_t vsof[_m_b4] (vbool4_t op1);
vbool8_t vsof[_m_b8] (vbool8_t op1);
vbool16_t vsof[_m_b16] (vbool16_t op1);
vbool32_t vsof[_m_b32] (vbool32_t op1);
vbool64_t vsof[_m_b64] (vbool64_t op1);
// masked functions
vbool1_t vsof[_m_b1]_mask (vbool1_t mask, vbool1_t maskedoff, vbool1_t op1);
vbool2_t vsof[_m_b2]_mask (vbool2_t mask, vbool2_t maskedoff, vbool2_t op1);
vbool4_t vsof[_m_b4]_mask (vbool4_t mask, vbool4_t maskedoff, vbool4_t op1);
vbool8_t vsof[_m_b8]_mask (vbool8_t mask, vbool8_t maskedoff, vbool8_t op1);
vbool16_t vsof[_m_b16]_mask (vbool16_t mask, vbool16_t maskedoff, vbool16_t op1);
vbool32_t vsof[_m_b32]_mask (vbool32_t mask, vbool32_t maskedoff, vbool32_t op1);
vbool64_t vsof[_m_b64]_mask (vbool64_t mask, vbool64_t maskedoff, vbool64_t op1);
```
### Vector Iota Functions:

**Prototypes:**
``` C
vuint8m1_t viota_m_8m1 (vbool8_t op1);
vuint8m2_t viota_m_8m2 (vbool4_t op1);
vuint8m4_t viota_m_8m4 (vbool2_t op1);
vuint8m8_t viota_m_8m8 (vbool1_t op1);
vuint16m1_t viota_m_16m1 (vbool16_t op1);
vuint16m2_t viota_m_16m2 (vbool8_t op1);
vuint16m4_t viota_m_16m4 (vbool4_t op1);
vuint16m8_t viota_m_16m8 (vbool2_t op1);
vuint32m1_t viota_m_32m1 (vbool32_t op1);
vuint32m2_t viota_m_32m2 (vbool16_t op1);
vuint32m4_t viota_m_32m4 (vbool8_t op1);
vuint32m8_t viota_m_32m8 (vbool4_t op1);
vuint64m1_t viota_m_64m1 (vbool64_t op1);
vuint64m2_t viota_m_64m2 (vbool32_t op1);
vuint64m4_t viota_m_64m4 (vbool16_t op1);
vuint64m8_t viota_m_64m8 (vbool8_t op1);
// masked functions
vuint8m1_t viota_m_8m1_mask (vbool8_t mask, vbool8_t op1);
vuint8m2_t viota_m_8m2_mask (vbool4_t mask, vbool4_t op1);
vuint8m4_t viota_m_8m4_mask (vbool2_t mask, vbool2_t op1);
vuint8m8_t viota_m_8m8_mask (vbool1_t mask, vbool1_t op1);
vuint16m1_t viota_m_16m1_mask (vbool16_t mask, vbool16_t op1);
vuint16m2_t viota_m_16m2_mask (vbool8_t mask, vbool8_t op1);
vuint16m4_t viota_m_16m4_mask (vbool4_t mask, vbool4_t op1);
vuint16m8_t viota_m_16m8_mask (vbool2_t mask, vbool2_t op1);
vuint32m1_t viota_m_32m1_mask (vbool32_t mask, vbool32_t op1);
vuint32m2_t viota_m_32m2_mask (vbool16_t mask, vbool16_t op1);
vuint32m4_t viota_m_32m4_mask (vbool8_t mask, vbool8_t op1);
vuint32m8_t viota_m_32m8_mask (vbool4_t mask, vbool4_t op1);
vuint64m1_t viota_m_64m1_mask (vbool64_t mask, vbool64_t op1);
vuint64m2_t viota_m_64m2_mask (vbool32_t mask, vbool32_t op1);
vuint64m4_t viota_m_64m4_mask (vbool16_t mask, vbool16_t op1);
vuint64m8_t viota_m_64m8_mask (vbool8_t mask, vbool8_t op1);
```
### Vector Element Index Functions:

**Prototypes:**
``` C
vuint8m1_t vid_8m1 ();
vuint8m2_t vid_8m2 ();
vuint8m4_t vid_8m4 ();
vuint8m8_t vid_8m8 ();
vuint16m1_t vid_16m1 ();
vuint16m2_t vid_16m2 ();
vuint16m4_t vid_16m4 ();
vuint16m8_t vid_16m8 ();
vuint32m1_t vid_32m1 ();
vuint32m2_t vid_32m2 ();
vuint32m4_t vid_32m4 ();
vuint32m8_t vid_32m8 ();
vuint64m1_t vid_64m1 ();
vuint64m2_t vid_64m2 ();
vuint64m4_t vid_64m4 ();
vuint64m8_t vid_64m8 ();
// masked functions
vuint8m1_t vid_8m1_mask (vbool8_t mask, vuint8m1_t maskedoff);
vuint8m2_t vid_8m2_mask (vbool4_t mask, vuint8m2_t maskedoff);
vuint8m4_t vid_8m4_mask (vbool2_t mask, vuint8m4_t maskedoff);
vuint8m8_t vid_8m8_mask (vbool1_t mask, vuint8m8_t maskedoff);
vuint16m1_t vid_16m1_mask (vbool16_t mask, vuint16m1_t maskedoff);
vuint16m2_t vid_16m2_mask (vbool8_t mask, vuint16m2_t maskedoff);
vuint16m4_t vid_16m4_mask (vbool4_t mask, vuint16m4_t maskedoff);
vuint16m8_t vid_16m8_mask (vbool2_t mask, vuint16m8_t maskedoff);
vuint32m1_t vid_32m1_mask (vbool32_t mask, vuint32m1_t maskedoff);
vuint32m2_t vid_32m2_mask (vbool16_t mask, vuint32m2_t maskedoff);
vuint32m4_t vid_32m4_mask (vbool8_t mask, vuint32m4_t maskedoff);
vuint32m8_t vid_32m8_mask (vbool4_t mask, vuint32m8_t maskedoff);
vuint64m1_t vid_64m1_mask (vbool64_t mask, vuint64m1_t maskedoff);
vuint64m2_t vid_64m2_mask (vbool32_t mask, vuint64m2_t maskedoff);
vuint64m4_t vid_64m4_mask (vbool16_t mask, vuint64m4_t maskedoff);
vuint64m8_t vid_64m8_mask (vbool8_t mask, vuint64m8_t maskedoff);
```
## Vector Permutation Functions:

### Integer and Floating-Point Scalar Move Functions:

**Prototypes:**
``` C
int8_t vmv_v[_i8m1] (vint8m1_t src);
vint8m1_t vmv_s[_i8m1] (vint8m1_t dst, int8_t src);
int8_t vmv_v[_i8m2] (vint8m2_t src);
vint8m2_t vmv_s[_i8m2] (vint8m2_t dst, int8_t src);
int8_t vmv_v[_i8m4] (vint8m4_t src);
vint8m4_t vmv_s[_i8m4] (vint8m4_t dst, int8_t src);
int8_t vmv_v[_i8m8] (vint8m8_t src);
vint8m8_t vmv_s[_i8m8] (vint8m8_t dst, int8_t src);
int16_t vmv_v[_i16m1] (vint16m1_t src);
vint16m1_t vmv_s[_i16m1] (vint16m1_t dst, int16_t src);
int16_t vmv_v[_i16m2] (vint16m2_t src);
vint16m2_t vmv_s[_i16m2] (vint16m2_t dst, int16_t src);
int16_t vmv_v[_i16m4] (vint16m4_t src);
vint16m4_t vmv_s[_i16m4] (vint16m4_t dst, int16_t src);
int16_t vmv_v[_i16m8] (vint16m8_t src);
vint16m8_t vmv_s[_i16m8] (vint16m8_t dst, int16_t src);
int32_t vmv_v[_i32m1] (vint32m1_t src);
vint32m1_t vmv_s[_i32m1] (vint32m1_t dst, int32_t src);
int32_t vmv_v[_i32m2] (vint32m2_t src);
vint32m2_t vmv_s[_i32m2] (vint32m2_t dst, int32_t src);
int32_t vmv_v[_i32m4] (vint32m4_t src);
vint32m4_t vmv_s[_i32m4] (vint32m4_t dst, int32_t src);
int32_t vmv_v[_i32m8] (vint32m8_t src);
vint32m8_t vmv_s[_i32m8] (vint32m8_t dst, int32_t src);
int64_t vmv_v[_i64m1] (vint64m1_t src);
vint64m1_t vmv_s[_i64m1] (vint64m1_t dst, int64_t src);
int64_t vmv_v[_i64m2] (vint64m2_t src);
vint64m2_t vmv_s[_i64m2] (vint64m2_t dst, int64_t src);
int64_t vmv_v[_i64m4] (vint64m4_t src);
vint64m4_t vmv_s[_i64m4] (vint64m4_t dst, int64_t src);
int64_t vmv_v[_i64m8] (vint64m8_t src);
vint64m8_t vmv_s[_i64m8] (vint64m8_t dst, int64_t src);
uint8_t vmv_v[_u8m1] (vuint8m1_t src);
vuint8m1_t vmv_s[_u8m1] (vuint8m1_t dst, uint8_t src);
uint8_t vmv_v[_u8m2] (vuint8m2_t src);
vuint8m2_t vmv_s[_u8m2] (vuint8m2_t dst, uint8_t src);
uint8_t vmv_v[_u8m4] (vuint8m4_t src);
vuint8m4_t vmv_s[_u8m4] (vuint8m4_t dst, uint8_t src);
uint8_t vmv_v[_u8m8] (vuint8m8_t src);
vuint8m8_t vmv_s[_u8m8] (vuint8m8_t dst, uint8_t src);
uint16_t vmv_v[_u16m1] (vuint16m1_t src);
vuint16m1_t vmv_s[_u16m1] (vuint16m1_t dst, uint16_t src);
uint16_t vmv_v[_u16m2] (vuint16m2_t src);
vuint16m2_t vmv_s[_u16m2] (vuint16m2_t dst, uint16_t src);
uint16_t vmv_v[_u16m4] (vuint16m4_t src);
vuint16m4_t vmv_s[_u16m4] (vuint16m4_t dst, uint16_t src);
uint16_t vmv_v[_u16m8] (vuint16m8_t src);
vuint16m8_t vmv_s[_u16m8] (vuint16m8_t dst, uint16_t src);
uint32_t vmv_v[_u32m1] (vuint32m1_t src);
vuint32m1_t vmv_s[_u32m1] (vuint32m1_t dst, uint32_t src);
uint32_t vmv_v[_u32m2] (vuint32m2_t src);
vuint32m2_t vmv_s[_u32m2] (vuint32m2_t dst, uint32_t src);
uint32_t vmv_v[_u32m4] (vuint32m4_t src);
vuint32m4_t vmv_s[_u32m4] (vuint32m4_t dst, uint32_t src);
uint32_t vmv_v[_u32m8] (vuint32m8_t src);
vuint32m8_t vmv_s[_u32m8] (vuint32m8_t dst, uint32_t src);
uint64_t vmv_v[_u64m1] (vuint64m1_t src);
vuint64m1_t vmv_s[_u64m1] (vuint64m1_t dst, uint64_t src);
uint64_t vmv_v[_u64m2] (vuint64m2_t src);
vuint64m2_t vmv_s[_u64m2] (vuint64m2_t dst, uint64_t src);
uint64_t vmv_v[_u64m4] (vuint64m4_t src);
vuint64m4_t vmv_s[_u64m4] (vuint64m4_t dst, uint64_t src);
uint64_t vmv_v[_u64m8] (vuint64m8_t src);
vuint64m8_t vmv_s[_u64m8] (vuint64m8_t dst, uint64_t src);
float16_t vmv_v[_f16m1] (vfloat16m1_t src);
vfloat16m1_t vmv_s[_f16m1] (vfloat16m1_t dst, float16_t src);
float16_t vmv_v[_f16m2] (vfloat16m2_t src);
vfloat16m2_t vmv_s[_f16m2] (vfloat16m2_t dst, float16_t src);
float16_t vmv_v[_f16m4] (vfloat16m4_t src);
vfloat16m4_t vmv_s[_f16m4] (vfloat16m4_t dst, float16_t src);
float16_t vmv_v[_f16m8] (vfloat16m8_t src);
vfloat16m8_t vmv_s[_f16m8] (vfloat16m8_t dst, float16_t src);
float32_t vmv_v[_f32m1] (vfloat32m1_t src);
vfloat32m1_t vmv_s[_f32m1] (vfloat32m1_t dst, float32_t src);
float32_t vmv_v[_f32m2] (vfloat32m2_t src);
vfloat32m2_t vmv_s[_f32m2] (vfloat32m2_t dst, float32_t src);
float32_t vmv_v[_f32m4] (vfloat32m4_t src);
vfloat32m4_t vmv_s[_f32m4] (vfloat32m4_t dst, float32_t src);
float32_t vmv_v[_f32m8] (vfloat32m8_t src);
vfloat32m8_t vmv_s[_f32m8] (vfloat32m8_t dst, float32_t src);
float64_t vmv_v[_f64m1] (vfloat64m1_t src);
vfloat64m1_t vmv_s[_f64m1] (vfloat64m1_t dst, float64_t src);
float64_t vmv_v[_f64m2] (vfloat64m2_t src);
vfloat64m2_t vmv_s[_f64m2] (vfloat64m2_t dst, float64_t src);
float64_t vmv_v[_f64m4] (vfloat64m4_t src);
vfloat64m4_t vmv_s[_f64m4] (vfloat64m4_t dst, float64_t src);
float64_t vmv_v[_f64m8] (vfloat64m8_t src);
vfloat64m8_t vmv_s[_f64m8] (vfloat64m8_t dst, float64_t src);
```
### Vector Slideup and Slidedown Functions:

**Prototypes:**
``` C
vint8m1_t vslideup[_vs_i8m1] (vint8m1_t src, size_t offset);
vint8m2_t vslideup[_vs_i8m2] (vint8m2_t src, size_t offset);
vint8m4_t vslideup[_vs_i8m4] (vint8m4_t src, size_t offset);
vint8m8_t vslideup[_vs_i8m8] (vint8m8_t src, size_t offset);
vint16m1_t vslideup[_vs_i16m1] (vint16m1_t src, size_t offset);
vint16m2_t vslideup[_vs_i16m2] (vint16m2_t src, size_t offset);
vint16m4_t vslideup[_vs_i16m4] (vint16m4_t src, size_t offset);
vint16m8_t vslideup[_vs_i16m8] (vint16m8_t src, size_t offset);
vint32m1_t vslideup[_vs_i32m1] (vint32m1_t src, size_t offset);
vint32m2_t vslideup[_vs_i32m2] (vint32m2_t src, size_t offset);
vint32m4_t vslideup[_vs_i32m4] (vint32m4_t src, size_t offset);
vint32m8_t vslideup[_vs_i32m8] (vint32m8_t src, size_t offset);
vint64m1_t vslideup[_vs_i64m1] (vint64m1_t src, size_t offset);
vint64m2_t vslideup[_vs_i64m2] (vint64m2_t src, size_t offset);
vint64m4_t vslideup[_vs_i64m4] (vint64m4_t src, size_t offset);
vint64m8_t vslideup[_vs_i64m8] (vint64m8_t src, size_t offset);
vuint8m1_t vslideup[_vs_u8m1] (vuint8m1_t src, size_t offset);
vuint8m2_t vslideup[_vs_u8m2] (vuint8m2_t src, size_t offset);
vuint8m4_t vslideup[_vs_u8m4] (vuint8m4_t src, size_t offset);
vuint8m8_t vslideup[_vs_u8m8] (vuint8m8_t src, size_t offset);
vuint16m1_t vslideup[_vs_u16m1] (vuint16m1_t src, size_t offset);
vuint16m2_t vslideup[_vs_u16m2] (vuint16m2_t src, size_t offset);
vuint16m4_t vslideup[_vs_u16m4] (vuint16m4_t src, size_t offset);
vuint16m8_t vslideup[_vs_u16m8] (vuint16m8_t src, size_t offset);
vuint32m1_t vslideup[_vs_u32m1] (vuint32m1_t src, size_t offset);
vuint32m2_t vslideup[_vs_u32m2] (vuint32m2_t src, size_t offset);
vuint32m4_t vslideup[_vs_u32m4] (vuint32m4_t src, size_t offset);
vuint32m8_t vslideup[_vs_u32m8] (vuint32m8_t src, size_t offset);
vuint64m1_t vslideup[_vs_u64m1] (vuint64m1_t src, size_t offset);
vuint64m2_t vslideup[_vs_u64m2] (vuint64m2_t src, size_t offset);
vuint64m4_t vslideup[_vs_u64m4] (vuint64m4_t src, size_t offset);
vuint64m8_t vslideup[_vs_u64m8] (vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup[_vs_f16m1] (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup[_vs_f16m2] (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup[_vs_f16m4] (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup[_vs_f16m8] (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup[_vs_f32m1] (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup[_vs_f32m2] (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup[_vs_f32m4] (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup[_vs_f32m8] (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup[_vs_f64m1] (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup[_vs_f64m2] (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup[_vs_f64m4] (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup[_vs_f64m8] (vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown[_vs_i8m1] (vint8m1_t src, size_t offset);
vint8m2_t vslidedown[_vs_i8m2] (vint8m2_t src, size_t offset);
vint8m4_t vslidedown[_vs_i8m4] (vint8m4_t src, size_t offset);
vint8m8_t vslidedown[_vs_i8m8] (vint8m8_t src, size_t offset);
vint16m1_t vslidedown[_vs_i16m1] (vint16m1_t src, size_t offset);
vint16m2_t vslidedown[_vs_i16m2] (vint16m2_t src, size_t offset);
vint16m4_t vslidedown[_vs_i16m4] (vint16m4_t src, size_t offset);
vint16m8_t vslidedown[_vs_i16m8] (vint16m8_t src, size_t offset);
vint32m1_t vslidedown[_vs_i32m1] (vint32m1_t src, size_t offset);
vint32m2_t vslidedown[_vs_i32m2] (vint32m2_t src, size_t offset);
vint32m4_t vslidedown[_vs_i32m4] (vint32m4_t src, size_t offset);
vint32m8_t vslidedown[_vs_i32m8] (vint32m8_t src, size_t offset);
vint64m1_t vslidedown[_vs_i64m1] (vint64m1_t src, size_t offset);
vint64m2_t vslidedown[_vs_i64m2] (vint64m2_t src, size_t offset);
vint64m4_t vslidedown[_vs_i64m4] (vint64m4_t src, size_t offset);
vint64m8_t vslidedown[_vs_i64m8] (vint64m8_t src, size_t offset);
vuint8m1_t vslidedown[_vs_u8m1] (vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown[_vs_u8m2] (vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown[_vs_u8m4] (vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown[_vs_u8m8] (vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown[_vs_u16m1] (vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown[_vs_u16m2] (vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown[_vs_u16m4] (vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown[_vs_u16m8] (vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown[_vs_u32m1] (vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown[_vs_u32m2] (vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown[_vs_u32m4] (vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown[_vs_u32m8] (vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown[_vs_u64m1] (vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown[_vs_u64m2] (vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown[_vs_u64m4] (vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown[_vs_u64m8] (vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown[_vs_f16m1] (vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown[_vs_f16m2] (vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown[_vs_f16m4] (vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown[_vs_f16m8] (vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown[_vs_f32m1] (vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown[_vs_f32m2] (vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown[_vs_f32m4] (vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown[_vs_f32m8] (vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown[_vs_f64m1] (vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown[_vs_f64m2] (vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown[_vs_f64m4] (vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown[_vs_f64m8] (vfloat64m8_t src, size_t offset);
// masked functions
vint8m1_t vslideup[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslideup[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslideup[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslideup[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslideup[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslideup[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslideup[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslideup[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslideup[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslideup[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslideup[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslideup[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslideup[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslideup[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslideup[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslideup[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslideup[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslideup[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslideup[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslideup[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslideup[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslideup[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslideup[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslideup[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslideup[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslideup[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslideup[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslideup[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslideup[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslideup[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslideup[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslideup[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslideup[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslideup[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslideup[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslideup[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslideup[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslideup[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslideup[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslideup[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslideup[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslideup[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslideup[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslideup[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
vint8m1_t vslidedown[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, size_t offset);
vint8m2_t vslidedown[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, size_t offset);
vint8m4_t vslidedown[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, size_t offset);
vint8m8_t vslidedown[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, size_t offset);
vint16m1_t vslidedown[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, size_t offset);
vint16m2_t vslidedown[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, size_t offset);
vint16m4_t vslidedown[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, size_t offset);
vint16m8_t vslidedown[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, size_t offset);
vint32m1_t vslidedown[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, size_t offset);
vint32m2_t vslidedown[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, size_t offset);
vint32m4_t vslidedown[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, size_t offset);
vint32m8_t vslidedown[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, size_t offset);
vint64m1_t vslidedown[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, size_t offset);
vint64m2_t vslidedown[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, size_t offset);
vint64m4_t vslidedown[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, size_t offset);
vint64m8_t vslidedown[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, size_t offset);
vuint8m1_t vslidedown[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, size_t offset);
vuint8m2_t vslidedown[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, size_t offset);
vuint8m4_t vslidedown[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, size_t offset);
vuint8m8_t vslidedown[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, size_t offset);
vuint16m1_t vslidedown[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, size_t offset);
vuint16m2_t vslidedown[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, size_t offset);
vuint16m4_t vslidedown[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, size_t offset);
vuint16m8_t vslidedown[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, size_t offset);
vuint32m1_t vslidedown[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, size_t offset);
vuint32m2_t vslidedown[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, size_t offset);
vuint32m4_t vslidedown[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, size_t offset);
vuint32m8_t vslidedown[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, size_t offset);
vuint64m1_t vslidedown[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, size_t offset);
vuint64m2_t vslidedown[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, size_t offset);
vuint64m4_t vslidedown[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, size_t offset);
vuint64m8_t vslidedown[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, size_t offset);
vfloat16m1_t vslidedown[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t src, size_t offset);
vfloat16m2_t vslidedown[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t src, size_t offset);
vfloat16m4_t vslidedown[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t src, size_t offset);
vfloat16m8_t vslidedown[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t src, size_t offset);
vfloat32m1_t vslidedown[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t src, size_t offset);
vfloat32m2_t vslidedown[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t src, size_t offset);
vfloat32m4_t vslidedown[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t src, size_t offset);
vfloat32m8_t vslidedown[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t src, size_t offset);
vfloat64m1_t vslidedown[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t src, size_t offset);
vfloat64m2_t vslidedown[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t src, size_t offset);
vfloat64m4_t vslidedown[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t src, size_t offset);
vfloat64m8_t vslidedown[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t src, size_t offset);
```
### Vector Slide1up and Slide1down Functions:

**Prototypes:**
``` C
vint8m1_t vslide1up[_vs_i8m1] (vint8m1_t src, long value);
vint8m2_t vslide1up[_vs_i8m2] (vint8m2_t src, long value);
vint8m4_t vslide1up[_vs_i8m4] (vint8m4_t src, long value);
vint8m8_t vslide1up[_vs_i8m8] (vint8m8_t src, long value);
vint16m1_t vslide1up[_vs_i16m1] (vint16m1_t src, long value);
vint16m2_t vslide1up[_vs_i16m2] (vint16m2_t src, long value);
vint16m4_t vslide1up[_vs_i16m4] (vint16m4_t src, long value);
vint16m8_t vslide1up[_vs_i16m8] (vint16m8_t src, long value);
vint32m1_t vslide1up[_vs_i32m1] (vint32m1_t src, long value);
vint32m2_t vslide1up[_vs_i32m2] (vint32m2_t src, long value);
vint32m4_t vslide1up[_vs_i32m4] (vint32m4_t src, long value);
vint32m8_t vslide1up[_vs_i32m8] (vint32m8_t src, long value);
vint64m1_t vslide1up[_vs_i64m1] (vint64m1_t src, long value);
vint64m2_t vslide1up[_vs_i64m2] (vint64m2_t src, long value);
vint64m4_t vslide1up[_vs_i64m4] (vint64m4_t src, long value);
vint64m8_t vslide1up[_vs_i64m8] (vint64m8_t src, long value);
vuint8m1_t vslide1up[_vs_u8m1] (vuint8m1_t src, long value);
vuint8m2_t vslide1up[_vs_u8m2] (vuint8m2_t src, long value);
vuint8m4_t vslide1up[_vs_u8m4] (vuint8m4_t src, long value);
vuint8m8_t vslide1up[_vs_u8m8] (vuint8m8_t src, long value);
vuint16m1_t vslide1up[_vs_u16m1] (vuint16m1_t src, long value);
vuint16m2_t vslide1up[_vs_u16m2] (vuint16m2_t src, long value);
vuint16m4_t vslide1up[_vs_u16m4] (vuint16m4_t src, long value);
vuint16m8_t vslide1up[_vs_u16m8] (vuint16m8_t src, long value);
vuint32m1_t vslide1up[_vs_u32m1] (vuint32m1_t src, long value);
vuint32m2_t vslide1up[_vs_u32m2] (vuint32m2_t src, long value);
vuint32m4_t vslide1up[_vs_u32m4] (vuint32m4_t src, long value);
vuint32m8_t vslide1up[_vs_u32m8] (vuint32m8_t src, long value);
vuint64m1_t vslide1up[_vs_u64m1] (vuint64m1_t src, long value);
vuint64m2_t vslide1up[_vs_u64m2] (vuint64m2_t src, long value);
vuint64m4_t vslide1up[_vs_u64m4] (vuint64m4_t src, long value);
vuint64m8_t vslide1up[_vs_u64m8] (vuint64m8_t src, long value);
vint8m1_t vslide1down[_vs_i8m1] (vint8m1_t src, long value);
vint8m2_t vslide1down[_vs_i8m2] (vint8m2_t src, long value);
vint8m4_t vslide1down[_vs_i8m4] (vint8m4_t src, long value);
vint8m8_t vslide1down[_vs_i8m8] (vint8m8_t src, long value);
vint16m1_t vslide1down[_vs_i16m1] (vint16m1_t src, long value);
vint16m2_t vslide1down[_vs_i16m2] (vint16m2_t src, long value);
vint16m4_t vslide1down[_vs_i16m4] (vint16m4_t src, long value);
vint16m8_t vslide1down[_vs_i16m8] (vint16m8_t src, long value);
vint32m1_t vslide1down[_vs_i32m1] (vint32m1_t src, long value);
vint32m2_t vslide1down[_vs_i32m2] (vint32m2_t src, long value);
vint32m4_t vslide1down[_vs_i32m4] (vint32m4_t src, long value);
vint32m8_t vslide1down[_vs_i32m8] (vint32m8_t src, long value);
vint64m1_t vslide1down[_vs_i64m1] (vint64m1_t src, long value);
vint64m2_t vslide1down[_vs_i64m2] (vint64m2_t src, long value);
vint64m4_t vslide1down[_vs_i64m4] (vint64m4_t src, long value);
vint64m8_t vslide1down[_vs_i64m8] (vint64m8_t src, long value);
vuint8m1_t vslide1down[_vs_u8m1] (vuint8m1_t src, long value);
vuint8m2_t vslide1down[_vs_u8m2] (vuint8m2_t src, long value);
vuint8m4_t vslide1down[_vs_u8m4] (vuint8m4_t src, long value);
vuint8m8_t vslide1down[_vs_u8m8] (vuint8m8_t src, long value);
vuint16m1_t vslide1down[_vs_u16m1] (vuint16m1_t src, long value);
vuint16m2_t vslide1down[_vs_u16m2] (vuint16m2_t src, long value);
vuint16m4_t vslide1down[_vs_u16m4] (vuint16m4_t src, long value);
vuint16m8_t vslide1down[_vs_u16m8] (vuint16m8_t src, long value);
vuint32m1_t vslide1down[_vs_u32m1] (vuint32m1_t src, long value);
vuint32m2_t vslide1down[_vs_u32m2] (vuint32m2_t src, long value);
vuint32m4_t vslide1down[_vs_u32m4] (vuint32m4_t src, long value);
vuint32m8_t vslide1down[_vs_u32m8] (vuint32m8_t src, long value);
vuint64m1_t vslide1down[_vs_u64m1] (vuint64m1_t src, long value);
vuint64m2_t vslide1down[_vs_u64m2] (vuint64m2_t src, long value);
vuint64m4_t vslide1down[_vs_u64m4] (vuint64m4_t src, long value);
vuint64m8_t vslide1down[_vs_u64m8] (vuint64m8_t src, long value);
// masked functions
vint8m1_t vslide1up[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1up[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1up[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1up[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1up[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1up[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1up[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1up[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1up[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1up[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1up[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1up[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1up[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1up[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1up[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1up[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1up[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1up[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1up[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1up[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1up[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1up[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1up[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1up[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1up[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1up[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1up[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1up[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1up[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1up[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1up[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1up[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
vint8m1_t vslide1down[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t src, long value);
vint8m2_t vslide1down[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t src, long value);
vint8m4_t vslide1down[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t src, long value);
vint8m8_t vslide1down[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t src, long value);
vint16m1_t vslide1down[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t src, long value);
vint16m2_t vslide1down[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t src, long value);
vint16m4_t vslide1down[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t src, long value);
vint16m8_t vslide1down[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t src, long value);
vint32m1_t vslide1down[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t src, long value);
vint32m2_t vslide1down[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t src, long value);
vint32m4_t vslide1down[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t src, long value);
vint32m8_t vslide1down[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t src, long value);
vint64m1_t vslide1down[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t src, long value);
vint64m2_t vslide1down[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t src, long value);
vint64m4_t vslide1down[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t src, long value);
vint64m8_t vslide1down[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t src, long value);
vuint8m1_t vslide1down[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t src, long value);
vuint8m2_t vslide1down[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t src, long value);
vuint8m4_t vslide1down[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t src, long value);
vuint8m8_t vslide1down[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t src, long value);
vuint16m1_t vslide1down[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t src, long value);
vuint16m2_t vslide1down[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t src, long value);
vuint16m4_t vslide1down[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t src, long value);
vuint16m8_t vslide1down[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t src, long value);
vuint32m1_t vslide1down[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t src, long value);
vuint32m2_t vslide1down[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t src, long value);
vuint32m4_t vslide1down[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t src, long value);
vuint32m8_t vslide1down[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t src, long value);
vuint64m1_t vslide1down[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t src, long value);
vuint64m2_t vslide1down[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t src, long value);
vuint64m4_t vslide1down[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t src, long value);
vuint64m8_t vslide1down[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t src, long value);
```
### Vector Register Gather Functions:

**Prototypes:**
``` C
vint8m1_t vrgather[_vv_i8m1] (vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather[_vs_i8m1] (vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather[_vv_i8m2] (vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather[_vs_i8m2] (vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather[_vv_i8m4] (vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather[_vs_i8m4] (vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather[_vv_i8m8] (vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather[_vs_i8m8] (vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather[_vv_i16m1] (vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather[_vs_i16m1] (vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather[_vv_i16m2] (vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather[_vs_i16m2] (vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather[_vv_i16m4] (vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather[_vs_i16m4] (vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather[_vv_i16m8] (vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather[_vs_i16m8] (vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather[_vv_i32m1] (vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather[_vs_i32m1] (vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather[_vv_i32m2] (vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather[_vs_i32m2] (vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather[_vv_i32m4] (vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather[_vs_i32m4] (vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather[_vv_i32m8] (vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather[_vs_i32m8] (vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather[_vv_i64m1] (vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather[_vs_i64m1] (vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather[_vv_i64m2] (vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather[_vs_i64m2] (vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather[_vv_i64m4] (vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather[_vs_i64m4] (vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather[_vv_i64m8] (vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather[_vs_i64m8] (vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather[_vv_u8m1] (vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather[_vs_u8m1] (vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather[_vv_u8m2] (vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather[_vs_u8m2] (vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather[_vv_u8m4] (vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather[_vs_u8m4] (vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather[_vv_u8m8] (vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather[_vs_u8m8] (vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather[_vv_u16m1] (vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather[_vs_u16m1] (vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather[_vv_u16m2] (vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather[_vs_u16m2] (vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather[_vv_u16m4] (vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather[_vs_u16m4] (vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather[_vv_u16m8] (vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather[_vs_u16m8] (vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather[_vv_u32m1] (vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather[_vs_u32m1] (vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather[_vv_u32m2] (vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather[_vs_u32m2] (vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather[_vv_u32m4] (vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather[_vs_u32m4] (vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather[_vv_u32m8] (vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather[_vs_u32m8] (vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather[_vv_u64m1] (vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather[_vs_u64m1] (vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather[_vv_u64m2] (vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather[_vs_u64m2] (vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather[_vv_u64m4] (vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather[_vs_u64m4] (vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather[_vv_u64m8] (vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather[_vs_u64m8] (vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather[_vv_f16m1] (vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather[_vs_f16m1] (vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather[_vv_f16m2] (vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather[_vs_f16m2] (vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather[_vv_f16m4] (vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather[_vs_f16m4] (vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather[_vv_f16m8] (vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather[_vs_f16m8] (vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather[_vv_f32m1] (vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather[_vs_f32m1] (vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather[_vv_f32m2] (vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather[_vs_f32m2] (vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather[_vv_f32m4] (vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather[_vs_f32m4] (vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather[_vv_f32m8] (vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather[_vs_f32m8] (vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather[_vv_f64m1] (vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather[_vs_f64m1] (vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather[_vv_f64m2] (vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather[_vs_f64m2] (vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather[_vv_f64m4] (vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather[_vs_f64m4] (vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather[_vv_f64m8] (vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather[_vs_f64m8] (vfloat64m8_t op1, uint64_t op2);
// masked functions
vint8m1_t vrgather[_vv_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, vuint8m1_t op2);
vint8m1_t vrgather[_vs_i8m1]_mask (vbool8_t mask, vint8m1_t maskedoff, vint8m1_t op1, uint8_t op2);
vint8m2_t vrgather[_vv_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, vuint8m2_t op2);
vint8m2_t vrgather[_vs_i8m2]_mask (vbool4_t mask, vint8m2_t maskedoff, vint8m2_t op1, uint8_t op2);
vint8m4_t vrgather[_vv_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, vuint8m4_t op2);
vint8m4_t vrgather[_vs_i8m4]_mask (vbool2_t mask, vint8m4_t maskedoff, vint8m4_t op1, uint8_t op2);
vint8m8_t vrgather[_vv_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, vuint8m8_t op2);
vint8m8_t vrgather[_vs_i8m8]_mask (vbool1_t mask, vint8m8_t maskedoff, vint8m8_t op1, uint8_t op2);
vint16m1_t vrgather[_vv_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, vuint16m1_t op2);
vint16m1_t vrgather[_vs_i16m1]_mask (vbool16_t mask, vint16m1_t maskedoff, vint16m1_t op1, uint16_t op2);
vint16m2_t vrgather[_vv_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, vuint16m2_t op2);
vint16m2_t vrgather[_vs_i16m2]_mask (vbool8_t mask, vint16m2_t maskedoff, vint16m2_t op1, uint16_t op2);
vint16m4_t vrgather[_vv_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, vuint16m4_t op2);
vint16m4_t vrgather[_vs_i16m4]_mask (vbool4_t mask, vint16m4_t maskedoff, vint16m4_t op1, uint16_t op2);
vint16m8_t vrgather[_vv_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, vuint16m8_t op2);
vint16m8_t vrgather[_vs_i16m8]_mask (vbool2_t mask, vint16m8_t maskedoff, vint16m8_t op1, uint16_t op2);
vint32m1_t vrgather[_vv_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, vuint32m1_t op2);
vint32m1_t vrgather[_vs_i32m1]_mask (vbool32_t mask, vint32m1_t maskedoff, vint32m1_t op1, uint32_t op2);
vint32m2_t vrgather[_vv_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, vuint32m2_t op2);
vint32m2_t vrgather[_vs_i32m2]_mask (vbool16_t mask, vint32m2_t maskedoff, vint32m2_t op1, uint32_t op2);
vint32m4_t vrgather[_vv_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, vuint32m4_t op2);
vint32m4_t vrgather[_vs_i32m4]_mask (vbool8_t mask, vint32m4_t maskedoff, vint32m4_t op1, uint32_t op2);
vint32m8_t vrgather[_vv_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, vuint32m8_t op2);
vint32m8_t vrgather[_vs_i32m8]_mask (vbool4_t mask, vint32m8_t maskedoff, vint32m8_t op1, uint32_t op2);
vint64m1_t vrgather[_vv_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, vuint64m1_t op2);
vint64m1_t vrgather[_vs_i64m1]_mask (vbool64_t mask, vint64m1_t maskedoff, vint64m1_t op1, uint64_t op2);
vint64m2_t vrgather[_vv_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, vuint64m2_t op2);
vint64m2_t vrgather[_vs_i64m2]_mask (vbool32_t mask, vint64m2_t maskedoff, vint64m2_t op1, uint64_t op2);
vint64m4_t vrgather[_vv_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, vuint64m4_t op2);
vint64m4_t vrgather[_vs_i64m4]_mask (vbool16_t mask, vint64m4_t maskedoff, vint64m4_t op1, uint64_t op2);
vint64m8_t vrgather[_vv_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, vuint64m8_t op2);
vint64m8_t vrgather[_vs_i64m8]_mask (vbool8_t mask, vint64m8_t maskedoff, vint64m8_t op1, uint64_t op2);
vuint8m1_t vrgather[_vv_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, vuint8m1_t op2);
vuint8m1_t vrgather[_vs_u8m1]_mask (vbool8_t mask, vuint8m1_t maskedoff, vuint8m1_t op1, uint8_t op2);
vuint8m2_t vrgather[_vv_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, vuint8m2_t op2);
vuint8m2_t vrgather[_vs_u8m2]_mask (vbool4_t mask, vuint8m2_t maskedoff, vuint8m2_t op1, uint8_t op2);
vuint8m4_t vrgather[_vv_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, vuint8m4_t op2);
vuint8m4_t vrgather[_vs_u8m4]_mask (vbool2_t mask, vuint8m4_t maskedoff, vuint8m4_t op1, uint8_t op2);
vuint8m8_t vrgather[_vv_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, vuint8m8_t op2);
vuint8m8_t vrgather[_vs_u8m8]_mask (vbool1_t mask, vuint8m8_t maskedoff, vuint8m8_t op1, uint8_t op2);
vuint16m1_t vrgather[_vv_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, vuint16m1_t op2);
vuint16m1_t vrgather[_vs_u16m1]_mask (vbool16_t mask, vuint16m1_t maskedoff, vuint16m1_t op1, uint16_t op2);
vuint16m2_t vrgather[_vv_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, vuint16m2_t op2);
vuint16m2_t vrgather[_vs_u16m2]_mask (vbool8_t mask, vuint16m2_t maskedoff, vuint16m2_t op1, uint16_t op2);
vuint16m4_t vrgather[_vv_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, vuint16m4_t op2);
vuint16m4_t vrgather[_vs_u16m4]_mask (vbool4_t mask, vuint16m4_t maskedoff, vuint16m4_t op1, uint16_t op2);
vuint16m8_t vrgather[_vv_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, vuint16m8_t op2);
vuint16m8_t vrgather[_vs_u16m8]_mask (vbool2_t mask, vuint16m8_t maskedoff, vuint16m8_t op1, uint16_t op2);
vuint32m1_t vrgather[_vv_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, vuint32m1_t op2);
vuint32m1_t vrgather[_vs_u32m1]_mask (vbool32_t mask, vuint32m1_t maskedoff, vuint32m1_t op1, uint32_t op2);
vuint32m2_t vrgather[_vv_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, vuint32m2_t op2);
vuint32m2_t vrgather[_vs_u32m2]_mask (vbool16_t mask, vuint32m2_t maskedoff, vuint32m2_t op1, uint32_t op2);
vuint32m4_t vrgather[_vv_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, vuint32m4_t op2);
vuint32m4_t vrgather[_vs_u32m4]_mask (vbool8_t mask, vuint32m4_t maskedoff, vuint32m4_t op1, uint32_t op2);
vuint32m8_t vrgather[_vv_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, vuint32m8_t op2);
vuint32m8_t vrgather[_vs_u32m8]_mask (vbool4_t mask, vuint32m8_t maskedoff, vuint32m8_t op1, uint32_t op2);
vuint64m1_t vrgather[_vv_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, vuint64m1_t op2);
vuint64m1_t vrgather[_vs_u64m1]_mask (vbool64_t mask, vuint64m1_t maskedoff, vuint64m1_t op1, uint64_t op2);
vuint64m2_t vrgather[_vv_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, vuint64m2_t op2);
vuint64m2_t vrgather[_vs_u64m2]_mask (vbool32_t mask, vuint64m2_t maskedoff, vuint64m2_t op1, uint64_t op2);
vuint64m4_t vrgather[_vv_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, vuint64m4_t op2);
vuint64m4_t vrgather[_vs_u64m4]_mask (vbool16_t mask, vuint64m4_t maskedoff, vuint64m4_t op1, uint64_t op2);
vuint64m8_t vrgather[_vv_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, vuint64m8_t op2);
vuint64m8_t vrgather[_vs_u64m8]_mask (vbool8_t mask, vuint64m8_t maskedoff, vuint64m8_t op1, uint64_t op2);
vfloat16m1_t vrgather[_vv_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, vuint16m1_t op2);
vfloat16m1_t vrgather[_vs_f16m1]_mask (vbool16_t mask, vfloat16m1_t maskedoff, vfloat16m1_t op1, uint16_t op2);
vfloat16m2_t vrgather[_vv_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, vuint16m2_t op2);
vfloat16m2_t vrgather[_vs_f16m2]_mask (vbool8_t mask, vfloat16m2_t maskedoff, vfloat16m2_t op1, uint16_t op2);
vfloat16m4_t vrgather[_vv_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, vuint16m4_t op2);
vfloat16m4_t vrgather[_vs_f16m4]_mask (vbool4_t mask, vfloat16m4_t maskedoff, vfloat16m4_t op1, uint16_t op2);
vfloat16m8_t vrgather[_vv_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, vuint16m8_t op2);
vfloat16m8_t vrgather[_vs_f16m8]_mask (vbool2_t mask, vfloat16m8_t maskedoff, vfloat16m8_t op1, uint16_t op2);
vfloat32m1_t vrgather[_vv_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, vuint32m1_t op2);
vfloat32m1_t vrgather[_vs_f32m1]_mask (vbool32_t mask, vfloat32m1_t maskedoff, vfloat32m1_t op1, uint32_t op2);
vfloat32m2_t vrgather[_vv_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, vuint32m2_t op2);
vfloat32m2_t vrgather[_vs_f32m2]_mask (vbool16_t mask, vfloat32m2_t maskedoff, vfloat32m2_t op1, uint32_t op2);
vfloat32m4_t vrgather[_vv_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, vuint32m4_t op2);
vfloat32m4_t vrgather[_vs_f32m4]_mask (vbool8_t mask, vfloat32m4_t maskedoff, vfloat32m4_t op1, uint32_t op2);
vfloat32m8_t vrgather[_vv_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, vuint32m8_t op2);
vfloat32m8_t vrgather[_vs_f32m8]_mask (vbool4_t mask, vfloat32m8_t maskedoff, vfloat32m8_t op1, uint32_t op2);
vfloat64m1_t vrgather[_vv_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, vuint64m1_t op2);
vfloat64m1_t vrgather[_vs_f64m1]_mask (vbool64_t mask, vfloat64m1_t maskedoff, vfloat64m1_t op1, uint64_t op2);
vfloat64m2_t vrgather[_vv_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, vuint64m2_t op2);
vfloat64m2_t vrgather[_vs_f64m2]_mask (vbool32_t mask, vfloat64m2_t maskedoff, vfloat64m2_t op1, uint64_t op2);
vfloat64m4_t vrgather[_vv_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, vuint64m4_t op2);
vfloat64m4_t vrgather[_vs_f64m4]_mask (vbool16_t mask, vfloat64m4_t maskedoff, vfloat64m4_t op1, uint64_t op2);
vfloat64m8_t vrgather[_vv_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, vuint64m8_t op2);
vfloat64m8_t vrgather[_vs_f64m8]_mask (vbool8_t mask, vfloat64m8_t maskedoff, vfloat64m8_t op1, uint64_t op2);
```
### Vector Compress Functions:

**Prototypes:**
``` C
vint8m1_t vcompress[_vm_i8m1] (vint8m1_t src, vbool8_t mask);
vint8m2_t vcompress[_vm_i8m2] (vint8m2_t src, vbool4_t mask);
vint8m4_t vcompress[_vm_i8m4] (vint8m4_t src, vbool2_t mask);
vint8m8_t vcompress[_vm_i8m8] (vint8m8_t src, vbool1_t mask);
vint16m1_t vcompress[_vm_i16m1] (vint16m1_t src, vbool16_t mask);
vint16m2_t vcompress[_vm_i16m2] (vint16m2_t src, vbool8_t mask);
vint16m4_t vcompress[_vm_i16m4] (vint16m4_t src, vbool4_t mask);
vint16m8_t vcompress[_vm_i16m8] (vint16m8_t src, vbool2_t mask);
vint32m1_t vcompress[_vm_i32m1] (vint32m1_t src, vbool32_t mask);
vint32m2_t vcompress[_vm_i32m2] (vint32m2_t src, vbool16_t mask);
vint32m4_t vcompress[_vm_i32m4] (vint32m4_t src, vbool8_t mask);
vint32m8_t vcompress[_vm_i32m8] (vint32m8_t src, vbool4_t mask);
vint64m1_t vcompress[_vm_i64m1] (vint64m1_t src, vbool64_t mask);
vint64m2_t vcompress[_vm_i64m2] (vint64m2_t src, vbool32_t mask);
vint64m4_t vcompress[_vm_i64m4] (vint64m4_t src, vbool16_t mask);
vint64m8_t vcompress[_vm_i64m8] (vint64m8_t src, vbool8_t mask);
vuint8m1_t vcompress[_vm_u8m1] (vuint8m1_t src, vbool8_t mask);
vuint8m2_t vcompress[_vm_u8m2] (vuint8m2_t src, vbool4_t mask);
vuint8m4_t vcompress[_vm_u8m4] (vuint8m4_t src, vbool2_t mask);
vuint8m8_t vcompress[_vm_u8m8] (vuint8m8_t src, vbool1_t mask);
vuint16m1_t vcompress[_vm_u16m1] (vuint16m1_t src, vbool16_t mask);
vuint16m2_t vcompress[_vm_u16m2] (vuint16m2_t src, vbool8_t mask);
vuint16m4_t vcompress[_vm_u16m4] (vuint16m4_t src, vbool4_t mask);
vuint16m8_t vcompress[_vm_u16m8] (vuint16m8_t src, vbool2_t mask);
vuint32m1_t vcompress[_vm_u32m1] (vuint32m1_t src, vbool32_t mask);
vuint32m2_t vcompress[_vm_u32m2] (vuint32m2_t src, vbool16_t mask);
vuint32m4_t vcompress[_vm_u32m4] (vuint32m4_t src, vbool8_t mask);
vuint32m8_t vcompress[_vm_u32m8] (vuint32m8_t src, vbool4_t mask);
vuint64m1_t vcompress[_vm_u64m1] (vuint64m1_t src, vbool64_t mask);
vuint64m2_t vcompress[_vm_u64m2] (vuint64m2_t src, vbool32_t mask);
vuint64m4_t vcompress[_vm_u64m4] (vuint64m4_t src, vbool16_t mask);
vuint64m8_t vcompress[_vm_u64m8] (vuint64m8_t src, vbool8_t mask);
vfloat16m1_t vcompress[_vm_f16m1] (vfloat16m1_t src, vbool16_t mask);
vfloat16m2_t vcompress[_vm_f16m2] (vfloat16m2_t src, vbool8_t mask);
vfloat16m4_t vcompress[_vm_f16m4] (vfloat16m4_t src, vbool4_t mask);
vfloat16m8_t vcompress[_vm_f16m8] (vfloat16m8_t src, vbool2_t mask);
vfloat32m1_t vcompress[_vm_f32m1] (vfloat32m1_t src, vbool32_t mask);
vfloat32m2_t vcompress[_vm_f32m2] (vfloat32m2_t src, vbool16_t mask);
vfloat32m4_t vcompress[_vm_f32m4] (vfloat32m4_t src, vbool8_t mask);
vfloat32m8_t vcompress[_vm_f32m8] (vfloat32m8_t src, vbool4_t mask);
vfloat64m1_t vcompress[_vm_f64m1] (vfloat64m1_t src, vbool64_t mask);
vfloat64m2_t vcompress[_vm_f64m2] (vfloat64m2_t src, vbool32_t mask);
vfloat64m4_t vcompress[_vm_f64m4] (vfloat64m4_t src, vbool16_t mask);
vfloat64m8_t vcompress[_vm_f64m8] (vfloat64m8_t src, vbool8_t mask);
```
## Miscellaneous Vector Functions:

### Reinterpret Cast Conversion Functions:

**Prototypes:**
``` C
vuint8m1_t vreinterpret_u8[_i8_v_8m1] (vint8m1_t src);
vuint8m2_t vreinterpret_u8[_i8_v_8m2] (vint8m2_t src);
vuint8m4_t vreinterpret_u8[_i8_v_8m4] (vint8m4_t src);
vuint8m8_t vreinterpret_u8[_i8_v_8m8] (vint8m8_t src);
vint8m1_t vreinterpret_i8[_u8_v_8m1] (vuint8m1_t src);
vint8m2_t vreinterpret_i8[_u8_v_8m2] (vuint8m2_t src);
vint8m4_t vreinterpret_i8[_u8_v_8m4] (vuint8m4_t src);
vint8m8_t vreinterpret_i8[_u8_v_8m8] (vuint8m8_t src);
vuint16m1_t vreinterpret_u16[_i16_v_16m1] (vint16m1_t src);
vuint16m2_t vreinterpret_u16[_i16_v_16m2] (vint16m2_t src);
vuint16m4_t vreinterpret_u16[_i16_v_16m4] (vint16m4_t src);
vuint16m8_t vreinterpret_u16[_i16_v_16m8] (vint16m8_t src);
vint16m1_t vreinterpret_i16[_u16_v_16m1] (vuint16m1_t src);
vint16m2_t vreinterpret_i16[_u16_v_16m2] (vuint16m2_t src);
vint16m4_t vreinterpret_i16[_u16_v_16m4] (vuint16m4_t src);
vint16m8_t vreinterpret_i16[_u16_v_16m8] (vuint16m8_t src);
vint16m1_t vreinterpret_i16[_f16_v_16m1] (vfloat16m1_t src);
vint16m2_t vreinterpret_i16[_f16_v_16m2] (vfloat16m2_t src);
vint16m4_t vreinterpret_i16[_f16_v_16m4] (vfloat16m4_t src);
vint16m8_t vreinterpret_i16[_f16_v_16m8] (vfloat16m8_t src);
vuint16m1_t vreinterpret_u16[_f16_v_16m1] (vfloat16m1_t src);
vuint16m2_t vreinterpret_u16[_f16_v_16m2] (vfloat16m2_t src);
vuint16m4_t vreinterpret_u16[_f16_v_16m4] (vfloat16m4_t src);
vuint16m8_t vreinterpret_u16[_f16_v_16m8] (vfloat16m8_t src);
vfloat16m1_t vreinterpret_f16[_i16_v_16m1] (vint16m1_t src);
vfloat16m2_t vreinterpret_f16[_i16_v_16m2] (vint16m2_t src);
vfloat16m4_t vreinterpret_f16[_i16_v_16m4] (vint16m4_t src);
vfloat16m8_t vreinterpret_f16[_i16_v_16m8] (vint16m8_t src);
vfloat16m1_t vreinterpret_f16[_u16_v_16m1] (vuint16m1_t src);
vfloat16m2_t vreinterpret_f16[_u16_v_16m2] (vuint16m2_t src);
vfloat16m4_t vreinterpret_f16[_u16_v_16m4] (vuint16m4_t src);
vfloat16m8_t vreinterpret_f16[_u16_v_16m8] (vuint16m8_t src);
vuint32m1_t vreinterpret_u32[_i32_v_32m1] (vint32m1_t src);
vuint32m2_t vreinterpret_u32[_i32_v_32m2] (vint32m2_t src);
vuint32m4_t vreinterpret_u32[_i32_v_32m4] (vint32m4_t src);
vuint32m8_t vreinterpret_u32[_i32_v_32m8] (vint32m8_t src);
vint32m1_t vreinterpret_i32[_u32_v_32m1] (vuint32m1_t src);
vint32m2_t vreinterpret_i32[_u32_v_32m2] (vuint32m2_t src);
vint32m4_t vreinterpret_i32[_u32_v_32m4] (vuint32m4_t src);
vint32m8_t vreinterpret_i32[_u32_v_32m8] (vuint32m8_t src);
vint32m1_t vreinterpret_i32[_f32_v_32m1] (vfloat32m1_t src);
vint32m2_t vreinterpret_i32[_f32_v_32m2] (vfloat32m2_t src);
vint32m4_t vreinterpret_i32[_f32_v_32m4] (vfloat32m4_t src);
vint32m8_t vreinterpret_i32[_f32_v_32m8] (vfloat32m8_t src);
vuint32m1_t vreinterpret_u32[_f32_v_32m1] (vfloat32m1_t src);
vuint32m2_t vreinterpret_u32[_f32_v_32m2] (vfloat32m2_t src);
vuint32m4_t vreinterpret_u32[_f32_v_32m4] (vfloat32m4_t src);
vuint32m8_t vreinterpret_u32[_f32_v_32m8] (vfloat32m8_t src);
vfloat32m1_t vreinterpret_f32[_i32_v_32m1] (vint32m1_t src);
vfloat32m2_t vreinterpret_f32[_i32_v_32m2] (vint32m2_t src);
vfloat32m4_t vreinterpret_f32[_i32_v_32m4] (vint32m4_t src);
vfloat32m8_t vreinterpret_f32[_i32_v_32m8] (vint32m8_t src);
vfloat32m1_t vreinterpret_f32[_u32_v_32m1] (vuint32m1_t src);
vfloat32m2_t vreinterpret_f32[_u32_v_32m2] (vuint32m2_t src);
vfloat32m4_t vreinterpret_f32[_u32_v_32m4] (vuint32m4_t src);
vfloat32m8_t vreinterpret_f32[_u32_v_32m8] (vuint32m8_t src);
vuint64m1_t vreinterpret_u64[_i64_v_64m1] (vint64m1_t src);
vuint64m2_t vreinterpret_u64[_i64_v_64m2] (vint64m2_t src);
vuint64m4_t vreinterpret_u64[_i64_v_64m4] (vint64m4_t src);
vuint64m8_t vreinterpret_u64[_i64_v_64m8] (vint64m8_t src);
vint64m1_t vreinterpret_i64[_u64_v_64m1] (vuint64m1_t src);
vint64m2_t vreinterpret_i64[_u64_v_64m2] (vuint64m2_t src);
vint64m4_t vreinterpret_i64[_u64_v_64m4] (vuint64m4_t src);
vint64m8_t vreinterpret_i64[_u64_v_64m8] (vuint64m8_t src);
vint64m1_t vreinterpret_i64[_f64_v_64m1] (vfloat64m1_t src);
vint64m2_t vreinterpret_i64[_f64_v_64m2] (vfloat64m2_t src);
vint64m4_t vreinterpret_i64[_f64_v_64m4] (vfloat64m4_t src);
vint64m8_t vreinterpret_i64[_f64_v_64m8] (vfloat64m8_t src);
vuint64m1_t vreinterpret_u64[_f64_v_64m1] (vfloat64m1_t src);
vuint64m2_t vreinterpret_u64[_f64_v_64m2] (vfloat64m2_t src);
vuint64m4_t vreinterpret_u64[_f64_v_64m4] (vfloat64m4_t src);
vuint64m8_t vreinterpret_u64[_f64_v_64m8] (vfloat64m8_t src);
vfloat64m1_t vreinterpret_f64[_i64_v_64m1] (vint64m1_t src);
vfloat64m2_t vreinterpret_f64[_i64_v_64m2] (vint64m2_t src);
vfloat64m4_t vreinterpret_f64[_i64_v_64m4] (vint64m4_t src);
vfloat64m8_t vreinterpret_f64[_i64_v_64m8] (vint64m8_t src);
vfloat64m1_t vreinterpret_f64[_u64_v_64m1] (vuint64m1_t src);
vfloat64m2_t vreinterpret_f64[_u64_v_64m2] (vuint64m2_t src);
vfloat64m4_t vreinterpret_f64[_u64_v_64m4] (vuint64m4_t src);
vfloat64m8_t vreinterpret_f64[_u64_v_64m8] (vuint64m8_t src);
```